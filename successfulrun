{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pcToqFSzWmQouulXuOYK5qMwytndWDKo",
      "authorship_tag": "ABX9TyMXwB7Wm1isV5DZ+a6ls6bd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earltreloar/logosfield-cddr-analysis/blob/main/successfulrun\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mechanism 1 (Auto-Flip) • One-Paste Cell --------------------------------\n",
        "# Works with:\n",
        "#   • CSV on disk:               SOURCE = {\"path\": \"/content/data.csv\", \"member\": None}\n",
        "#   • CSV inside a ZIP archive:  SOURCE = {\"path\": \"/content/drive/MyDrive/repro_bundle.zip\",\n",
        "#                                          \"member\": \"sdss/SDSS_STANDARDIZED.csv\"}\n",
        "#\n",
        "# What it does:\n",
        "#   1) Loads source table (ZIP member or plain CSV).\n",
        "#   2) Finds/derives a spin column:\n",
        "#        - direct \"spin\" or \"spin_num\" or \"spin_sign\" etc.\n",
        "#        - or derive from probabilities (p_cw vs p_ccw) if present.\n",
        "#   3) Auto-flips convention so aligned fraction ≥ 0.5.\n",
        "#   4) Computes Wilson CI, z vs 0.5, one-sided p.\n",
        "#   5) Saves tidy CSVs under ./Mechanism1_repro_out/\n",
        "#\n",
        "# Outputs:\n",
        "#   ./Mechanism1_repro_out/Mechanism1_summary_auto.csv\n",
        "#   ./Mechanism1_repro_out/Mechanism1_significance_auto.csv\n",
        "#\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import os, io, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import erf, sqrt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# ============= USER CONFIG =============\n",
        "SOURCE = {\n",
        "    # Path to either a CSV, or a ZIP that contains your CSV\n",
        "    \"path\": \"/content/drive/MyDrive/repro_bundle.zip\",\n",
        "    # If 'path' is a ZIP, set the member path inside the ZIP; else use None\n",
        "    \"member\": \"sdss/SDSS_STANDARDIZED.csv\",  # e.g. \"sdss/SDSS_STANDARDIZED.csv\"\n",
        "}\n",
        "DATASET_LABEL = \"MECH1\"\n",
        "OUT_DIR = \"./Mechanism1_repro_out\"\n",
        "# =======================================\n",
        "\n",
        "\n",
        "# -------------------- helpers --------------------\n",
        "def load_csv(path: str, member: str | None) -> pd.DataFrame:\n",
        "    \"\"\"Load a CSV either directly or from a ZIP member.\"\"\"\n",
        "    if member is None:\n",
        "        return pd.read_csv(path)\n",
        "    with zipfile.ZipFile(path) as zf:\n",
        "        with zf.open(member) as f:\n",
        "            return pd.read_csv(f)\n",
        "\n",
        "def find_col(candidates, cols):\n",
        "    \"\"\"Return the first matching column name (case-insensitive), else None.\"\"\"\n",
        "    lc = {c.lower(): c for c in cols}\n",
        "    for name in candidates:\n",
        "        if name.lower() in lc:\n",
        "            return lc[name.lower()]\n",
        "    return None\n",
        "\n",
        "def ensure_spin(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Return a numeric spin series with values in {-1, +1} if possible.\n",
        "    Accepts:\n",
        "      • direct spin columns: [\"spin\", \"spin_num\", \"spin_sign\", \"spinlabel\"]\n",
        "      • or derives from probs: [\"p_cw\",\"p_ccw\"] or [\"p_cwp\",\"p_ccwp\"] etc.\n",
        "    \"\"\"\n",
        "    cols = df.columns\n",
        "\n",
        "    # 1) direct spin?\n",
        "    direct_candidates = [\"spin\",\"spin_num\",\"spin_sign\",\"spinlabel\"]\n",
        "    scol = find_col(direct_candidates, cols)\n",
        "    if scol is not None:\n",
        "        s = pd.to_numeric(df[scol], errors=\"coerce\")\n",
        "        # Clip to {-1, +1} where possible\n",
        "        s = s.where(s.isin([-1, 1]), s)\n",
        "        return s\n",
        "\n",
        "    # 2) derive from probabilities\n",
        "    # common prob names across runs\n",
        "    cw_candidates  = [\"p_cw\", \"p_cwp\", \"p_cw_p\", \"p_cw_prob\", \"p_cw_p_ccw\"]\n",
        "    ccw_candidates = [\"p_ccw\",\"p_ccwp\",\"p_ccw_p\",\"p_ccw_prob\"]\n",
        "    cw  = find_col(cw_candidates, cols)\n",
        "    ccw = find_col(ccw_candidates, cols)\n",
        "\n",
        "    if cw is not None and ccw is not None:\n",
        "        cwv  = pd.to_numeric(df[cw],  errors=\"coerce\")\n",
        "        ccwv = pd.to_numeric(df[ccw], errors=\"coerce\")\n",
        "        # sign: +1 if cw > ccw, else -1\n",
        "        s = np.sign((cwv - ccwv).values)\n",
        "        # map zeros (ties/NaN) to NaN\n",
        "        s = pd.Series(s, index=df.index).replace(0, np.nan)\n",
        "        return s\n",
        "\n",
        "    raise ValueError(\n",
        "        \"Could not locate a spin column or probability columns to derive spin.\\n\"\n",
        "        f\"Available columns: {list(cols)[:25]}{' ...' if len(cols)>25 else ''}\"\n",
        "    )\n",
        "\n",
        "def wilson_ci(k: int, n: int, conf: float = 0.95):\n",
        "    \"\"\"Wilson score interval.\"\"\"\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    z = norm.ppf(1 - (1 - conf) / 2.0)\n",
        "    phat = k / n\n",
        "    denom = 1 + z*z/n\n",
        "    centre = (phat + z*z/(2*n)) / denom\n",
        "    margin = z * sqrt((phat*(1 - phat)/n) + (z*z/(4*n*n))) / denom\n",
        "    return (centre - margin, centre + margin)\n",
        "\n",
        "def z_vs_half(frac: float, n: int):\n",
        "    \"\"\"z against 0.5 using normal approximation.\"\"\"\n",
        "    if n <= 0 or np.isnan(frac):\n",
        "        return np.nan\n",
        "    return (frac - 0.5) / sqrt(0.25 / n)\n",
        "\n",
        "def one_sided_p_from_z(z: float):\n",
        "    \"\"\"One-sided p value from z (H1: frac > 0.5).\"\"\"\n",
        "    if np.isnan(z):\n",
        "        return np.nan\n",
        "    return 0.5 * (1 - erf(z / sqrt(2)))\n",
        "\n",
        "\n",
        "# -------------------- main --------------------\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load\n",
        "df = load_csv(SOURCE[\"path\"], SOURCE[\"member\"])\n",
        "print(\"Loaded columns:\", list(df.columns)[:20], \"...\" if len(df.columns) > 20 else \"\")\n",
        "\n",
        "# Spin\n",
        "spin = ensure_spin(df)\n",
        "mask = spin.notna()\n",
        "n_valid = int(mask.sum())\n",
        "print(f\"Non-null spins: {n_valid:,}\")\n",
        "\n",
        "if n_valid == 0:\n",
        "    raise RuntimeError(\"No finite spins found after parsing/derivation.\")\n",
        "\n",
        "# Basic RA/Dec columns (optional, for inspection)\n",
        "ra_col  = find_col([\"ra\", \"ra_deg\", \"ra_targ\"], df.columns)\n",
        "dec_col = find_col([\"dec\",\"dec_deg\",\"dec_targ\"], df.columns)\n",
        "if ra_col and dec_col:\n",
        "    peek = df.loc[mask, [ra_col, dec_col]].head(5)\n",
        "    print(\"\\nSample RA/Dec (first 5):\")\n",
        "    print(peek.to_string(index=False))\n",
        "\n",
        "# Raw fraction (as coded, spin==+1)\n",
        "frac_pos = (spin[mask] == 1).mean()\n",
        "counts   = spin[mask].value_counts(dropna=False).to_dict()\n",
        "print(\"\\nSpin counts:\", counts)\n",
        "print(f\"As-coded fraction spin=+1: {frac_pos:.3f}\")\n",
        "\n",
        "# Auto-flip so aligned ≥ 0.5\n",
        "flipped = False\n",
        "if frac_pos < 0.5:\n",
        "    frac_aligned = 1 - frac_pos\n",
        "    flipped = True\n",
        "else:\n",
        "    frac_aligned = frac_pos\n",
        "\n",
        "k = int(round(frac_aligned * n_valid))\n",
        "ci_lo, ci_hi = wilson_ci(k, n_valid, conf=0.95)\n",
        "z = z_vs_half(frac_aligned, n_valid)\n",
        "p = one_sided_p_from_z(z)\n",
        "\n",
        "print(\"\\n--- Mechanism 1 (Auto-Flip) ---\")\n",
        "print(f\"Dataset: {DATASET_LABEL}\")\n",
        "print(f\"N = {n_valid:,}\")\n",
        "print(f\"Aligned fraction (auto-flip): {frac_aligned:.3f}\")\n",
        "print(f\"95% CI: [{ci_lo:.3f}, {ci_hi:.3f}]\")\n",
        "print(f\"z vs 0.5 = {z:.2f}, one-sided p = {p:.2e}\")\n",
        "print(f\"Flip applied? {flipped}\")\n",
        "\n",
        "# -------------------- save tidy outputs --------------------\n",
        "# Summary table (compact)\n",
        "summary = pd.DataFrame([{\n",
        "    \"dataset\": DATASET_LABEL,\n",
        "    \"alignment_fraction\": frac_aligned,\n",
        "    \"null_fraction\": 1 - frac_aligned,\n",
        "    \"p_value\": p,\n",
        "    \"n_valid\": n_valid,\n",
        "    \"flip_applied\": flipped\n",
        "}])\n",
        "\n",
        "# Significance table (pipeline-style)\n",
        "significance = pd.DataFrame([{\n",
        "    \"dataset\": DATASET_LABEL,\n",
        "    \"rotation_deg\": 0,\n",
        "    \"metric\": \"frac_raw\",\n",
        "    \"n_valid\": n_valid,\n",
        "    \"frac\": frac_aligned,\n",
        "    \"CI95_lo\": ci_lo,\n",
        "    \"CI95_hi\": ci_hi,\n",
        "    \"z_vs_0_5\": z,\n",
        "    \"p_one_sided\": p\n",
        "}])\n",
        "\n",
        "sum_path = os.path.join(OUT_DIR, \"Mechanism1_summary_auto.csv\")\n",
        "sig_path = os.path.join(OUT_DIR, \"Mechanism1_significance_auto.csv\")\n",
        "summary.to_csv(sum_path, index=False)\n",
        "significance.to_csv(sig_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved summary   → {sum_path}\")\n",
        "print(f\"Saved sig table → {sig_path}\")\n",
        "# ------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN3I-Kn-Bf8r",
        "outputId": "aaa8bfda-23a0-443c-c5a0-1a9c438721f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded columns: ['ra', 'dec', 'spin'] \n",
            "Non-null spins: 667,944\n",
            "\n",
            "Sample RA/Dec (first 5):\n",
            "      ra        dec\n",
            "0.001708 -10.373806\n",
            "0.003083  -9.222278\n",
            "0.004292 -10.946667\n",
            "0.005750  15.509806\n",
            "0.006458  -0.092583\n",
            "\n",
            "Spin counts: {-1: 477719, 1: 190225}\n",
            "As-coded fraction spin=+1: 0.285\n",
            "\n",
            "--- Mechanism 1 (Auto-Flip) ---\n",
            "Dataset: MECH1\n",
            "N = 667,944\n",
            "Aligned fraction (auto-flip): 0.715\n",
            "95% CI: [0.714, 0.716]\n",
            "z vs 0.5 = 351.77, one-sided p = 0.00e+00\n",
            "Flip applied? True\n",
            "\n",
            "Saved summary   → ./Mechanism1_repro_out/Mechanism1_summary_auto.csv\n",
            "Saved sig table → ./Mechanism1_repro_out/Mechanism1_significance_auto.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mechanism 1 (Auto-Flip with Null) • One-Paste Cell -----------------------\n",
        "import os, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import erf, sqrt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# ============= USER CONFIG =============\n",
        "SOURCE = {\n",
        "    \"path\": \"/content/drive/MyDrive/repro_bundle.zip\",   # CSV or ZIP path\n",
        "    \"member\": \"sdss/SDSS_STANDARDIZED.csv\",              # or None for plain CSV\n",
        "}\n",
        "DATASET_LABEL = \"MECH1\"\n",
        "OUT_DIR = \"./Mechanism1_repro_out\"\n",
        "# =======================================\n",
        "\n",
        "# -------------------- helpers --------------------\n",
        "def load_csv(path: str, member: str | None) -> pd.DataFrame:\n",
        "    if member is None:\n",
        "        return pd.read_csv(path)\n",
        "    with zipfile.ZipFile(path) as zf:\n",
        "        with zf.open(member) as f:\n",
        "            return pd.read_csv(f)\n",
        "\n",
        "def find_col(candidates, cols):\n",
        "    lc = {c.lower(): c for c in cols}\n",
        "    for name in candidates:\n",
        "        if name.lower() in lc:\n",
        "            return lc[name.lower()]\n",
        "    return None\n",
        "\n",
        "def ensure_spin(df: pd.DataFrame) -> pd.Series:\n",
        "    cols = df.columns\n",
        "    scol = find_col([\"spin\",\"spin_num\",\"spin_sign\",\"spinlabel\"], cols)\n",
        "    if scol is not None:\n",
        "        return pd.to_numeric(df[scol], errors=\"coerce\")\n",
        "    # fallback: derive from probs if present\n",
        "    cw = find_col([\"p_cw\",\"p_cwp\"], cols)\n",
        "    ccw = find_col([\"p_ccw\",\"p_ccwp\"], cols)\n",
        "    if cw and ccw:\n",
        "        s = np.sign(df[cw] - df[ccw])\n",
        "        return pd.Series(s, index=df.index).replace(0, np.nan)\n",
        "    raise ValueError(\"No spin column found.\")\n",
        "\n",
        "def wilson_ci(k, n, conf=0.95):\n",
        "    if n == 0: return (np.nan, np.nan)\n",
        "    z = norm.ppf(1-(1-conf)/2)\n",
        "    phat = k/n\n",
        "    denom = 1+z*z/n\n",
        "    centre = (phat+z*z/(2*n))/denom\n",
        "    margin = z*np.sqrt((phat*(1-phat)/n)+(z*z/(4*n*n)))/denom\n",
        "    return (centre-margin, centre+margin)\n",
        "\n",
        "def z_vs_half(frac, n): return (frac-0.5)/np.sqrt(0.25/n) if n>0 else np.nan\n",
        "def p_from_z(z): return 0.5*(1-erf(z/np.sqrt(2))) if not np.isnan(z) else np.nan\n",
        "\n",
        "# -------------------- main --------------------\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "df = load_csv(SOURCE[\"path\"], SOURCE[\"member\"])\n",
        "spin = ensure_spin(df)\n",
        "mask = spin.notna()\n",
        "n_valid = int(mask.sum())\n",
        "\n",
        "frac_pos = (spin[mask]==1).mean()\n",
        "flipped = False\n",
        "if frac_pos < 0.5:\n",
        "    frac_aligned = 1-frac_pos\n",
        "    flipped = True\n",
        "else:\n",
        "    frac_aligned = frac_pos\n",
        "\n",
        "k = int(round(frac_aligned*n_valid))\n",
        "ci_lo, ci_hi = wilson_ci(k, n_valid)\n",
        "z = z_vs_half(frac_aligned, n_valid)\n",
        "p = p_from_z(z)\n",
        "\n",
        "print(\"\\n--- Mechanism 1 (Auto-Flip + Null) ---\")\n",
        "print(f\"N={n_valid}, frac={frac_aligned:.3f}, CI=[{ci_lo:.3f},{ci_hi:.3f}], z={z:.2f}, p={p:.2e}, flip={flipped}\")\n",
        "\n",
        "# -------- Save with Null alongside --------\n",
        "summary = pd.DataFrame([\n",
        "    {\"dataset\": DATASET_LABEL, \"alignment_fraction\": frac_aligned, \"null_fraction\": 0.5,\n",
        "     \"p_value\": p, \"n_valid\": n_valid, \"flip_applied\": flipped},\n",
        "    {\"dataset\": \"NULL\", \"alignment_fraction\": 0.5, \"null_fraction\": 0.5,\n",
        "     \"p_value\": 1.0, \"n_valid\": n_valid, \"flip_applied\": False}\n",
        "])\n",
        "\n",
        "significance = pd.DataFrame([\n",
        "    {\"dataset\": DATASET_LABEL, \"rotation_deg\": 0, \"metric\": \"frac_raw\",\n",
        "     \"n_valid\": n_valid, \"frac\": frac_aligned,\n",
        "     \"CI95_lo\": ci_lo, \"CI95_hi\": ci_hi, \"z_vs_0_5\": z, \"p_one_sided\": p},\n",
        "    {\"dataset\": \"NULL\", \"rotation_deg\": 0, \"metric\": \"frac_raw\",\n",
        "     \"n_valid\": n_valid, \"frac\": 0.5,\n",
        "     \"CI95_lo\": 0.5, \"CI95_hi\": 0.5, \"z_vs_0_5\": 0.0, \"p_one_sided\": 0.5}\n",
        "])\n",
        "\n",
        "sum_path = os.path.join(OUT_DIR, \"Mechanism1_summary_auto_withnull.csv\")\n",
        "sig_path = os.path.join(OUT_DIR, \"Mechanism1_significance_auto_withnull.csv\")\n",
        "summary.to_csv(sum_path,index=False)\n",
        "significance.to_csv(sig_path,index=False)\n",
        "\n",
        "print(f\"Saved summary   → {sum_path}\")\n",
        "print(f\"Saved sig table → {sig_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkAHAseACCsH",
        "outputId": "1ffa04c4-58b9-41e7-90a8-1684d2b133c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mechanism 1 (Auto-Flip + Null) ---\n",
            "N=667944, frac=0.715, CI=[0.714,0.716], z=351.77, p=0.00e+00, flip=True\n",
            "Saved summary   → ./Mechanism1_repro_out/Mechanism1_summary_auto_withnull.csv\n",
            "Saved sig table → ./Mechanism1_repro_out/Mechanism1_significance_auto_withnull.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Mechanism 1 (Auto-Flip + Null + Rotation Nulls) : one-paste cell =====\n",
        "# Outputs:\n",
        "#   ./Mechanism1_repro_out/Mechanism1_summary_auto_withnull.csv\n",
        "#   ./Mechanism1_repro_out/Mechanism1_significance_auto_withnull_and_rot.csv\n",
        "#\n",
        "# Notes:\n",
        "# - Expects a standardized spin catalog with columns like ['ra','dec','spin'] and spins in {-1,+1}.\n",
        "# - Works with a plain CSV path or \"zip://<zip_path>::<member_name>\".\n",
        "# - Rotation nulls are produced by circularly rolling the spin labels by k = round(N*deg/360).\n",
        "\n",
        "import os, re, math, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import erf, sqrt\n",
        "\n",
        "# --------------------- CONFIG ---------------------\n",
        "DATASET_LABEL = \"MECH1\"\n",
        "# Example inputs:\n",
        "#   INPUT_PATH = \"/content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\"\n",
        "#   INPUT_PATH = \"/content/drive/MyDrive/SDSS_STANDARDIZED.csv\"\n",
        "INPUT_PATH   = \"/content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\"  # <-- set me\n",
        "OUT_DIR      = \"./Mechanism1_repro_out\"\n",
        "ROTATION_DEG = [0, 30, 60, 90]  # rotation nulls to report\n",
        "# --------------------------------------------------\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def read_table(path: str, nrows=None) -> pd.DataFrame:\n",
        "    \"\"\"Read CSV from disk or from a zip member if path has '::'.\"\"\"\n",
        "    if \"::\" in path:\n",
        "        zip_path, member = path.split(\"::\", 1)\n",
        "        with zipfile.ZipFile(zip_path) as z:\n",
        "            with z.open(member) as f:\n",
        "                return pd.read_csv(f, nrows=nrows)\n",
        "    else:\n",
        "        return pd.read_csv(path, nrows=nrows)\n",
        "\n",
        "def find_col(df: pd.DataFrame, candidates):\n",
        "    low = {c.lower(): c for c in df.columns}\n",
        "    for name in df.columns:\n",
        "        pass\n",
        "    for want in candidates:\n",
        "        for c in df.columns:\n",
        "            if re.fullmatch(rf\"{want}\", c, flags=re.IGNORECASE):\n",
        "                return c\n",
        "        for c in df.columns:\n",
        "            if want.lower() == c.lower():\n",
        "                return c\n",
        "    # fallback: contains\n",
        "    for want in candidates:\n",
        "        for c in df.columns:\n",
        "            if want.lower() in c.lower():\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "def as_spin_series(s) -> pd.Series:\n",
        "    \"\"\"Coerce spin column to numeric ±1.\"\"\"\n",
        "    x = pd.to_numeric(s, errors=\"coerce\")\n",
        "    # if it looks like 0/1, map to -1/+1\n",
        "    uniq = pd.Series(x.dropna().unique())\n",
        "    if set(uniq.astype(int).unique()).issubset({0,1}):\n",
        "        x = x*2 - 1\n",
        "    # clamp signs to {-1,+1}\n",
        "    x = x.apply(lambda v: np.nan if pd.isna(v) else (1 if v >= 0 else -1))\n",
        "    return x.astype(\"float64\")\n",
        "\n",
        "def wilson_ci(k, n, z=1.959963984540054):  # z ~ 1.96 for 95% CI\n",
        "    if n <= 0:\n",
        "        return (np.nan, np.nan)\n",
        "    p = k/n\n",
        "    denom = 1 + z*z/n\n",
        "    center = (p + z*z/(2*n)) / denom\n",
        "    half = z * math.sqrt((p*(1-p) + z*z/(4*n))/n) / denom\n",
        "    return (center - half, center + half)\n",
        "\n",
        "def z_vs_half(p_hat, n):\n",
        "    if n <= 0 or not np.isfinite(p_hat): return (np.nan, np.nan)\n",
        "    z = (p_hat - 0.5) / math.sqrt(0.25 / n)\n",
        "    p_one = 0.5 * (1 - erf(z/sqrt(2)))\n",
        "    return z, p_one\n",
        "\n",
        "# --------------------- LOAD ---------------------\n",
        "df = read_table(INPUT_PATH)\n",
        "ra_col   = find_col(df, [\"ra\",\"ra_deg\",\"RA\",\"ra_targ\",\"RA_TARG\"])\n",
        "dec_col  = find_col(df, [\"dec\",\"dec_deg\",\"DEC\",\"dec_targ\",\"DEC_TARG\"])\n",
        "spin_col = find_col(df, [\"spin\",\"spin_num\",\"spin_sign\",\"spinlabel\",\"spin_num_bin\",\"s\"])\n",
        "assert spin_col is not None, \"Could not find a spin column.\"\n",
        "\n",
        "spins = as_spin_series(df[spin_col])\n",
        "valid = spins.dropna().copy()\n",
        "N = int(valid.shape[0])\n",
        "assert N > 0, \"No valid spins found.\"\n",
        "\n",
        "# ----------------- AUTO-FLIP (observed) -----------------\n",
        "# Raw fraction of +1:\n",
        "raw_frac = (valid > 0).mean()\n",
        "# Choose global flip to maximize alignment:\n",
        "flip_sign = 1 if raw_frac >= 0.5 else -1\n",
        "aligned = valid * flip_sign\n",
        "frac = (aligned > 0).mean()\n",
        "k = int((aligned > 0).sum())\n",
        "ci_lo, ci_hi = wilson_ci(k, N)\n",
        "z, p = z_vs_half(frac, N)\n",
        "\n",
        "# ----------------- NULL BASELINE -----------------\n",
        "null_row = {\n",
        "    \"dataset\": \"NULL\",\n",
        "    \"alignment_fraction\": 0.5,\n",
        "    \"null_fraction\": 0.5,\n",
        "    \"p_value\": 0.5,\n",
        "    \"n_valid\": N,\n",
        "    \"flip_applied\": False\n",
        "}\n",
        "\n",
        "# ----------------- ROTATION NULLS -----------------\n",
        "# Emulate rotating the field over sources by circularly rolling spin labels.\n",
        "# Keep the SAME flip_sign chosen on the observed data (so comparison is apples-to-apples).\n",
        "rows = []\n",
        "for deg in ROTATION_DEG:\n",
        "    kroll = int(round(N * (deg % 360) / 360.0))\n",
        "    spun = aligned.copy()  # already flip-adjusted\n",
        "    if kroll != 0:\n",
        "        spun = spun.to_numpy()\n",
        "        spun = np.roll(spun, kroll)\n",
        "        spun = pd.Series(spun)\n",
        "    frac_r = (spun > 0).mean()\n",
        "    k_r = int((spun > 0).sum())\n",
        "    lo_r, hi_r = wilson_ci(k_r, N)\n",
        "    z_r, p_r = z_vs_half(frac_r, N)\n",
        "    rows.append({\n",
        "        \"dataset\": DATASET_LABEL,\n",
        "        \"rotation_deg\": deg,\n",
        "        \"metric\": \"frac_raw\",\n",
        "        \"n_valid\": N,\n",
        "        \"frac\": frac_r,\n",
        "        \"CI95_lo\": lo_r,\n",
        "        \"CI95_hi\": hi_r,\n",
        "        \"z_vs_0_5\": z_r,\n",
        "        \"p_one_sided\": p_r\n",
        "    })\n",
        "\n",
        "# Also include the NULL row in the significance table for convenience\n",
        "sig_tbl = pd.DataFrame(rows + [{\n",
        "    \"dataset\": \"NULL\", \"rotation_deg\": 0, \"metric\": \"frac_raw\",\n",
        "    \"n_valid\": N, \"frac\": 0.5, \"CI95_lo\": 0.5, \"CI95_hi\": 0.5,\n",
        "    \"z_vs_0_5\": 0.0, \"p_one_sided\": 0.5\n",
        "}])\n",
        "\n",
        "# ----------------- SUMMARY (observed + NULL) -----------------\n",
        "summary = pd.DataFrame([\n",
        "    {\n",
        "        \"dataset\": DATASET_LABEL,\n",
        "        \"alignment_fraction\": frac,\n",
        "        \"null_fraction\": 0.5,\n",
        "        \"p_value\": p,\n",
        "        \"n_valid\": N,\n",
        "        \"flip_applied\": bool(flip_sign == -1)\n",
        "    },\n",
        "    null_row\n",
        "])\n",
        "\n",
        "# ----------------- WRITE + PRINT -----------------\n",
        "sum_path = os.path.join(OUT_DIR, \"Mechanism1_summary_auto_withnull.csv\")\n",
        "sig_path = os.path.join(OUT_DIR, \"Mechanism1_significance_auto_withnull_and_rot.csv\")\n",
        "summary.to_csv(sum_path, index=False)\n",
        "sig_tbl.to_csv(sig_path, index=False)\n",
        "\n",
        "print(\"Loaded columns:\", [ra_col, dec_col, spin_col])\n",
        "print(f\"Non-null spins: {N:,}\")\n",
        "print(\"\\n--- Mechanism 1 (Auto-Flip + Null + Rot) ---\")\n",
        "print(f\"Dataset: {DATASET_LABEL}\")\n",
        "print(f\"N = {N:,}, frac = {frac:.3f}, CI = [{ci_lo:.3f}, {ci_hi:.3f}], z={z:.2f}, p={p:.2e}, flip={flip_sign==-1}\")\n",
        "print(\"Rotation nulls:\")\n",
        "print(sig_tbl.query(\"dataset == @DATASET_LABEL\")[[\"rotation_deg\",\"frac\",\"CI95_lo\",\"CI95_hi\",\"z_vs_0_5\",\"p_one_sided\"]].to_string(index=False))\n",
        "print(\"\\nSaved summary  ->\", sum_path)\n",
        "print(\"Saved sig table->\", sig_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7uJSWzZDNnU",
        "outputId": "7d03fa12-beaf-4b08-f60e-4d8fcdbb50ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded columns: ['ra', 'dec', 'spin']\n",
            "Non-null spins: 667,944\n",
            "\n",
            "--- Mechanism 1 (Auto-Flip + Null + Rot) ---\n",
            "Dataset: MECH1\n",
            "N = 667,944, frac = 0.715, CI = [0.714, 0.716], z=351.77, p=0.00e+00, flip=True\n",
            "Rotation nulls:\n",
            " rotation_deg     frac  CI95_lo  CI95_hi   z_vs_0_5  p_one_sided\n",
            "            0 0.715208 0.714125 0.716289 351.769968          0.0\n",
            "           30 0.715208 0.714125 0.716289 351.769968          0.0\n",
            "           60 0.715208 0.714125 0.716289 351.769968          0.0\n",
            "           90 0.715208 0.714125 0.716289 351.769968          0.0\n",
            "\n",
            "Saved summary  -> ./Mechanism1_repro_out/Mechanism1_summary_auto_withnull.csv\n",
            "Saved sig table-> ./Mechanism1_repro_out/Mechanism1_significance_auto_withnull_and_rot.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mechanism 1: Auto-Flip + Robust Null (coin-flip) + Optional Block Bootstrap ===\n",
        "# One-paste, Colab-ready\n",
        "\n",
        "import os, re, math, zipfile, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------ USER CONFIG ------------------\n",
        "# If you already have df with ['ra','dec','spin'] in memory, set CSV_OR_ZIP=None\n",
        "# Otherwise, point CSV_OR_ZIP to either:\n",
        "#   - a CSV path (e.g. \"/content/drive/MyDrive/SDSS_STANDARDIZED.csv\")\n",
        "#   - a ZIP path with a single CSV member (e.g. \"zip:///content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\")\n",
        "CSV_OR_ZIP = None  # e.g. \"zip:///content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\"\n",
        "\n",
        "# Output directory\n",
        "OUT_DIR = \"./Mechanism1_repro_out\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Label for this dataset row in outputs\n",
        "DATASET_LABEL = \"MECH1\"\n",
        "\n",
        "# Monte-Carlo null settings\n",
        "N_BOOT = 2000         # increase for final figures (e.g. 10000)\n",
        "SEED   = 2025\n",
        "rng    = np.random.default_rng(SEED)\n",
        "\n",
        "# Block bootstrap (uncertainty on observed fraction)\n",
        "USE_BLOCK_BOOTSTRAP = True\n",
        "RA_BINS  = 12   # 30° bins if ra in degrees (0..360)\n",
        "DEC_BINS =  6   # ~30° bins if dec in degrees (-90..+90)\n",
        "N_JK     = 200  # jackknife-like resamples (leave-one-tile-out bootstrap)\n",
        "# --------------------------------------------------\n",
        "\n",
        "def load_csv_or_zip(path):\n",
        "    # path format for zip: \"zip:///full/path.zip::inner/file.csv\"\n",
        "    if path is None:\n",
        "        raise ValueError(\"CSV_OR_ZIP is None but no in-memory df provided. Set CSV_OR_ZIP to a CSV or ZIP::MEMBER path, or pass df directly.\")\n",
        "    if path.startswith(\"zip://\"):\n",
        "        m = re.match(r\"zip://(.+?)::(.+)\", path)\n",
        "        if not m:\n",
        "            raise ValueError(\"ZIP path must look like 'zip:///path/to.zip::member.csv'\")\n",
        "        zip_path, member = m.group(1), m.group(2)\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "            with z.open(member, \"r\") as fh:\n",
        "                return pd.read_csv(io.BytesIO(fh.read()))\n",
        "    else:\n",
        "        return pd.read_csv(path)\n",
        "\n",
        "def ensure_df(df):\n",
        "    # Normalize columns to lowercase, strip spaces/units\n",
        "    df = df.rename(columns={c: re.sub(r\"[^0-9a-zA-Z_]+\",\"_\",c).strip(\"_\").lower() for c in df.columns})\n",
        "    for c in (\"ra\",\"dec\",\"spin\"):\n",
        "        assert c in df.columns, f\"Missing required column '{c}' in df (have: {list(df.columns)[:12]} ...)\"\n",
        "    # Force numeric and drop NaNs in required cols\n",
        "    df[\"ra\"]   = pd.to_numeric(df[\"ra\"], errors=\"coerce\")\n",
        "    df[\"dec\"]  = pd.to_numeric(df[\"dec\"], errors=\"coerce\")\n",
        "    df[\"spin\"] = pd.to_numeric(df[\"spin\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"ra\",\"dec\",\"spin\"]).copy()\n",
        "    # Ensure spins are ±1\n",
        "    s = np.sign(df[\"spin\"].values)\n",
        "    s[s==0] = -1\n",
        "    df[\"spin\"] = s.astype(np.int8)\n",
        "    return df\n",
        "\n",
        "def auto_flip_to_align(spins):\n",
        "    \"\"\"If majority spin is −1, flip all to make 'aligned' = +1; returns (spins_aligned, flipped_bool).\"\"\"\n",
        "    cnt_pos = (spins ==  1).sum()\n",
        "    cnt_neg = (spins == -1).sum()\n",
        "    flipped = False\n",
        "    if cnt_neg > cnt_pos:\n",
        "        spins = -spins\n",
        "        flipped = True\n",
        "    return spins, flipped\n",
        "\n",
        "def frac_plus_one(spins):\n",
        "    return (spins == 1).mean()\n",
        "\n",
        "def binom_theory_z_p(f, N, p0=0.5):\n",
        "    # Theoretical z, p for H0: p = p0\n",
        "    se = math.sqrt(p0*(1-p0)/N)\n",
        "    z  = (f - p0)/se if se>0 else np.inf\n",
        "    p_one = 1.0 - 0.5*(1.0+math.erf(z/math.sqrt(2)))\n",
        "    return z, p_one\n",
        "\n",
        "def block_bootstrap_frac(df, ra_bins=12, dec_bins=6, n_jk=200, rng=None):\n",
        "    \"\"\"Conservative uncertainty on observed fraction: leave-one-tile-out style bootstrap.\"\"\"\n",
        "    # Tile indices:\n",
        "    ra  = df[\"ra\"].values % 360.0\n",
        "    dec = df[\"dec\"].values\n",
        "    ra_idx  = np.clip(np.floor(ra/360.0*ra_bins).astype(int), 0, ra_bins-1)\n",
        "    # map dec (-90..+90) to [0..1] then *dec_bins\n",
        "    decn = (dec + 90.0) / 180.0\n",
        "    dec_idx = np.clip(np.floor(decn*dec_bins).astype(int), 0, dec_bins-1)\n",
        "    tile_id = ra_idx*dec_bins + dec_idx\n",
        "    uniq = np.unique(tile_id)\n",
        "    # Precompute per tile spins:\n",
        "    by_tile = {tid: (df.loc[tile_id==tid, \"spin\"].values) for tid in uniq}\n",
        "    N = len(df)\n",
        "    fracs = []\n",
        "    for _ in range(n_jk):\n",
        "        # sample tiles with replacement to build a pseudo-sample\n",
        "        tiles = rng.choice(uniq, size=len(uniq), replace=True)\n",
        "        # Concatenate spins (if a tile repeats, we re-use it)\n",
        "        spins = np.concatenate([by_tile[t] for t in tiles]) if len(tiles) else np.array([], dtype=int)\n",
        "        if spins.size == 0:\n",
        "            continue\n",
        "        # auto-flip per resample:\n",
        "        s_aligned, _ = auto_flip_to_align(spins)\n",
        "        fracs.append(frac_plus_one(s_aligned))\n",
        "    fracs = np.array(fracs)\n",
        "    if fracs.size == 0:\n",
        "        return np.nan, np.nan\n",
        "    lo = np.percentile(fracs, 2.5)\n",
        "    hi = np.percentile(fracs,97.5)\n",
        "    return lo, hi\n",
        "\n",
        "# ------------------ LOAD DATA ------------------\n",
        "if CSV_OR_ZIP is not None:\n",
        "    df = load_csv_or_zip(CSV_OR_ZIP)\n",
        "else:\n",
        "    # Expect df already defined in memory\n",
        "    if \"df\" not in globals():\n",
        "        raise RuntimeError(\"df not found in memory and CSV_OR_ZIP is None. Define 'df' with ['ra','dec','spin'] or set CSV_OR_ZIP.\")\n",
        "df = ensure_df(df)\n",
        "\n",
        "# ------------------ OBSERVED (auto-flip) ------------------\n",
        "spins_obs, flipped = auto_flip_to_align(df[\"spin\"].values)\n",
        "N = spins_obs.size\n",
        "f_obs = frac_plus_one(spins_obs)\n",
        "\n",
        "# Block bootstrap CI on observed (optional)\n",
        "if USE_BLOCK_BOOTSTRAP:\n",
        "    ci_lo, ci_hi = block_bootstrap_frac(df.assign(spin=spins_obs), ra_bins=RA_BINS, dec_bins=DEC_BINS, n_jk=N_JK, rng=rng)\n",
        "else:\n",
        "    # fall back to normal approx around f_obs (NOT null!)\n",
        "    se_obs = math.sqrt(f_obs*(1-f_obs)/max(N,1))\n",
        "    ci_lo, ci_hi = (f_obs - 1.96*se_obs, f_obs + 1.96*se_obs)\n",
        "\n",
        "# Theoretical z, p (H0: p=0.5)\n",
        "z_th, p_th = binom_theory_z_p(f_obs, N, p0=0.5)\n",
        "\n",
        "# ------------------ MONTE-CARLO NULL (coin flips at p=0.5) ------------------\n",
        "# This approximates the 0.5 null and returns an empirical p.\n",
        "# We simulate aligned fractions for N draws with p=0.5, for each bootstrap.\n",
        "null_fracs = rng.binomial(N, 0.5, size=N_BOOT)/N\n",
        "# one-sided (greater) empirical p\n",
        "p_emp = (np.sum(null_fracs >= f_obs) + 1) / (N_BOOT + 1)\n",
        "\n",
        "# Null summary row\n",
        "null_row = {\n",
        "    \"dataset\": \"NULL\",\n",
        "    \"rotation_deg\": 0,\n",
        "    \"metric\": \"frac_raw\",\n",
        "    \"n_valid\": N,\n",
        "    \"frac\": 0.5,\n",
        "    \"CI95_lo\": np.percentile(null_fracs,  2.5),\n",
        "    \"CI95_hi\": np.percentile(null_fracs, 97.5),\n",
        "    \"z_vs_0_5\": 0.0,\n",
        "    \"p_one_sided\": 0.5\n",
        "}\n",
        "\n",
        "# Observed summary row\n",
        "obs_row = {\n",
        "    \"dataset\": DATASET_LABEL,\n",
        "    \"rotation_deg\": 0,\n",
        "    \"metric\": \"frac_raw\",\n",
        "    \"n_valid\": N,\n",
        "    \"frac\": f_obs,\n",
        "    \"CI95_lo\": ci_lo,\n",
        "    \"CI95_hi\": ci_hi,\n",
        "    \"z_vs_0_5\": z_th,\n",
        "    \"p_one_sided\": p_th,\n",
        "    \"flip_applied\": flipped\n",
        "}\n",
        "\n",
        "# Long significance table (one row per bootstrap null + one observed row)\n",
        "sig_tbl = pd.DataFrame({\n",
        "    \"dataset\":   [DATASET_LABEL] + [\"NULL\"]*N_BOOT,\n",
        "    \"rotation_deg\": [0] + [0]*N_BOOT,\n",
        "    \"metric\":    [\"frac_raw\"]*(N_BOOT+1),\n",
        "    \"n_valid\":   [N]*(N_BOOT+1),\n",
        "    \"frac\":      np.concatenate([[f_obs], null_fracs]),\n",
        "    \"z_vs_0_5\":  np.concatenate([[z_th],  (null_fracs - 0.5)/np.sqrt(0.25/N)]),\n",
        "    \"p_one_sided\": np.concatenate([[p_th], np.zeros(N_BOOT)])  # p for null rows is not used\n",
        "})\n",
        "\n",
        "# Compact summary table\n",
        "summary_tbl = pd.DataFrame([obs_row, null_row])\n",
        "\n",
        "# ------------------ SAVE + PRINT ------------------\n",
        "sum_path = os.path.join(OUT_DIR, \"Mechanism1_summary_coin_null.csv\")\n",
        "sig_path = os.path.join(OUT_DIR, \"Mechanism1_significance_coin_null.csv\")\n",
        "summary_tbl.to_csv(sum_path, index=False)\n",
        "sig_tbl.to_csv(sig_path, index=False)\n",
        "\n",
        "print(\"\\n--- Mechanism 1 (Auto-Flip + Coin-Null) ---\")\n",
        "print(f\"Dataset: {DATASET_LABEL}\")\n",
        "print(f\"N = {N:,}, frac = {f_obs:.3f}, CI (block bootstrap): [{ci_lo:.3f}, {ci_hi:.3f}]\")\n",
        "print(f\"z vs 0.5 = {z_th:.2f}, p_one_sided (theory) = {p_th:.2e}\")\n",
        "print(f\"Empirical p_one_sided (coin-null, {N_BOOT} draws) = {p_emp:.2e}\")\n",
        "print(f\"Flip applied? {flipped}\")\n",
        "print(\"\\nSaved summary ->\", sum_path)\n",
        "print(\"Saved significance (with null draws) ->\", sig_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF4zs5v-E75P",
        "outputId": "c32de8a4-63ce-406b-9126-514eeb5ed20c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mechanism 1 (Auto-Flip + Coin-Null) ---\n",
            "Dataset: MECH1\n",
            "N = 667,944, frac = 0.715, CI (block bootstrap): [0.710, 0.721]\n",
            "z vs 0.5 = 351.77, p_one_sided (theory) = 0.00e+00\n",
            "Empirical p_one_sided (coin-null, 2000 draws) = 5.00e-04\n",
            "Flip applied? True\n",
            "\n",
            "Saved summary -> ./Mechanism1_repro_out/Mechanism1_summary_coin_null.csv\n",
            "Saved significance (with null draws) -> ./Mechanism1_repro_out/Mechanism1_significance_coin_null.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mechanism 1: Probability-weighted + Subsample Symmetry (one-paste cell) ===\n",
        "import pandas as pd, numpy as np, re, zipfile, io, math\n",
        "from math import erf, sqrt\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Point this to the same SDSS table you used (zip members supported)\n",
        "#    Examples:\n",
        "#    - CSV on Drive: \"/content/drive/MyDrive/SDSS_STANDARDIZED.csv\"\n",
        "#    - Zip member:   \"zip::/content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\"\n",
        "# ---------------------------------------------------------------------\n",
        "DATA_PATH = \"zip::/content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\"  # <-- EDIT if needed\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# helpers\n",
        "# ---------------------------------------------------------------------\n",
        "def read_table(path, nrows=None):\n",
        "    if path.startswith(\"zip::\"):\n",
        "        zip_path, member = path[5:].split(\"::\", 1)\n",
        "        with zipfile.ZipFile(zip_path) as zf:\n",
        "            with zf.open(member) as fh:\n",
        "                return pd.read_csv(fh, nrows=nrows)\n",
        "    return pd.read_csv(path, nrows=nrows)\n",
        "\n",
        "def find_col(cols, *cands):\n",
        "    \"\"\"case-insensitive fuzzy pick of the first column matching any candidate regex.\"\"\"\n",
        "    for pat in cands:\n",
        "        for c in cols:\n",
        "            if re.search(pat, c, flags=re.I):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "def wilson_ci(k, n, z=1.96):  # 95% by default\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    phat = k / n\n",
        "    denom = 1 + z*z/n\n",
        "    center = (phat + z*z/(2*n)) / denom\n",
        "    half = (z/denom) * math.sqrt(phat*(1-phat)/n + z*z/(4*n*n))\n",
        "    return center - half, center + half\n",
        "\n",
        "def norm_ci_for_probs(p, n):  # simple normal approx around mean(p)\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    p = np.asarray(p)\n",
        "    v = np.mean(p*(1-p))   # E[p(1-p)]\n",
        "    se = math.sqrt(v / n)\n",
        "    return float(np.mean(p) - 1.96*se), float(np.mean(p) + 1.96*se)\n",
        "\n",
        "def z_vs_half(frac, n):\n",
        "    # normal approx z for (p-0.5)/sqrt(0.25/n)\n",
        "    if n == 0:\n",
        "        return np.nan\n",
        "    return (frac - 0.5) / math.sqrt(0.25/n)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Load & detect columns\n",
        "# ---------------------------------------------------------------------\n",
        "df = read_table(DATA_PATH)\n",
        "cols = df.columns.tolist()\n",
        "\n",
        "# spin (hard labels)\n",
        "spin_col = find_col(cols, r'^(spin|spin_num|spin_sign|spinlabel)\\b')\n",
        "if spin_col is None:\n",
        "    raise ValueError(f\"Couldn't find a spin column in: {cols[:12]} ...\")\n",
        "\n",
        "# probabilities (optional)\n",
        "cw_col  = find_col(cols, r'(p[_\\-]?cw\\b|cw[_\\-]?prob\\b|prob[_\\-]?cw\\b)')\n",
        "ccw_col = find_col(cols, r'(p[_\\-]?ccw\\b|ccw[_\\-]?prob\\b|prob[_\\-]?ccw\\b)')\n",
        "\n",
        "# RA/Dec (optional; nice for sanity)\n",
        "ra_col  = find_col(cols, r'(^ra\\b|ra[_\\-]?targ\\b)')\n",
        "dec_col = find_col(cols, r'(^dec\\b|dec[_\\-]?targ\\b)')\n",
        "\n",
        "# pick a stratification proxy: magnitude if present, else redshift-like\n",
        "strata_col = find_col(cols, r'(^.*mag.*$)') or find_col(cols, r'(^z$|z[_\\-]?spec|redshift)')\n",
        "has_strata = strata_col is not None and np.issubdtype(df[strata_col].dtype, np.number)\n",
        "\n",
        "print(\"Loaded columns:\", cols[:8], \"...\")\n",
        "print(\"Detected -> spin:\", spin_col, \"| p_cw:\", cw_col, \"| p_ccw:\", ccw_col, \"| RA/Dec:\", ra_col, dec_col, \"| strata:\", strata_col)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Clean & coerce\n",
        "# ---------------------------------------------------------------------\n",
        "# coerce spin to numeric {-1, +1}\n",
        "s = pd.to_numeric(df[spin_col], errors='coerce')\n",
        "# common mappings (0/1, CW/CCW strings) -> try to lift to ±1 if needed\n",
        "if s.dropna().isin([0,1]).all():\n",
        "    s = s.replace({0:-1, 1:1})\n",
        "df['_spin_'] = s\n",
        "\n",
        "# coerce probs if available\n",
        "p_plus = None  # probability that spin=+1 after auto-flip\n",
        "if cw_col and ccw_col:\n",
        "    pcw  = pd.to_numeric(df[cw_col],  errors='coerce')\n",
        "    pccw = pd.to_numeric(df[ccw_col], errors='coerce')\n",
        "    denom = pcw + pccw\n",
        "    good = denom > 0\n",
        "    pcw[good]  = pcw[good]  / denom[good]\n",
        "    pccw[good] = pccw[good] / denom[good]\n",
        "else:\n",
        "    pcw = pccw = None\n",
        "\n",
        "# keep finite rows\n",
        "mask = df['_spin_'].isin([-1,1])\n",
        "df = df.loc[mask].copy()\n",
        "N = len(df)\n",
        "print(f\"\\nNon-null spins: {N:,}\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Auto-flip standardization (majority -> +1)\n",
        "# ---------------------------------------------------------------------\n",
        "as_coded_frac_plus = (df['_spin_'] == 1).mean()\n",
        "flip = as_coded_frac_plus < 0.5\n",
        "if flip:\n",
        "    df['_spin_'] = -df['_spin_']\n",
        "    if pcw is not None:\n",
        "        # swap cw<->ccw so that +1 remains \"aligned\" in probability space\n",
        "        pcw, pccw = pccw, pcw\n",
        "\n",
        "# probability that spin=+1 after flip\n",
        "if pcw is not None and pccw is not None:\n",
        "    p_plus = (pcw)  # since we swapped on flip, p_cw now corresponds to +1\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Unweighted alignment & CI (Wilson)\n",
        "# ---------------------------------------------------------------------\n",
        "k_plus = int((df['_spin_'] == 1).sum())\n",
        "frac_unw = k_plus / N\n",
        "ci_lo_unw, ci_hi_unw = wilson_ci(k_plus, N)\n",
        "z_unw = z_vs_half(frac_unw, N)\n",
        "p_theory = 0.5*(1 - erf(z_unw/sqrt(2)))  # one-sided vs 0.5\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Probability-weighted alignment & CI (if probs exist)\n",
        "# ---------------------------------------------------------------------\n",
        "if p_plus is not None:\n",
        "    p_plus = p_plus.astype(float)\n",
        "    p_plus = p_plus.where(p_plus.notna(), 0.5)   # neutral where probs missing\n",
        "    frac_w = float(p_plus.mean())\n",
        "    ci_lo_w, ci_hi_w = norm_ci_for_probs(p_plus, len(p_plus))\n",
        "else:\n",
        "    frac_w = ci_lo_w = ci_hi_w = np.nan\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7) Subsample symmetry: quartiles of a proxy (mag or z)\n",
        "# ---------------------------------------------------------------------\n",
        "def safe_qcut(x, q=4):\n",
        "    try:\n",
        "        return pd.qcut(x, q=q, duplicates='drop')\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "sub_tbl = None\n",
        "if has_strata:\n",
        "    x = pd.to_numeric(df[strata_col], errors='coerce')\n",
        "    bins = safe_qcut(x, 4)\n",
        "    if bins is not None:\n",
        "        grp = df.assign(_bin=bins)\n",
        "        rows = []\n",
        "        for b, g in grp.groupby('_bin', observed=True):\n",
        "            n = len(g)\n",
        "            if n == 0:\n",
        "                continue\n",
        "            k = int((g['_spin_']==1).sum())\n",
        "            f = k/n\n",
        "            z = z_vs_half(f, n)\n",
        "            # weighted per bin (if available)\n",
        "            if p_plus is not None:\n",
        "                pw = float(p_plus.loc[g.index].mean())\n",
        "            else:\n",
        "                pw = np.nan\n",
        "            rows.append({\"bin\": str(b), \"N\": n, \"frac_unweighted\": f, \"frac_weighted\": pw, \"z_vs_0.5\": z})\n",
        "        sub_tbl = pd.DataFrame(rows).sort_values(\"bin\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8) Report\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\n--- Mechanism 1 (Auto-Flip) : probability-weighted + subsample symmetry ---\")\n",
        "print(f\"Dataset path: {DATA_PATH}\")\n",
        "print(f\"As-coded fraction spin=+1: {as_coded_frac_plus:.3f}  |  Flip applied? {flip}\")\n",
        "print(f\"N = {N:,}\")\n",
        "print(f\"Unweighted aligned fraction: {frac_unw:.3f},  CI (Wilson): [{ci_lo_unw:.3f}, {ci_hi_unw:.3f}],  z={z_unw:.2f},  p_one_sided(theory)={p_theory:.2e}\")\n",
        "if p_plus is not None:\n",
        "    print(f\"Probability-weighted aligned fraction: {frac_w:.3f},  CI (normal): [{ci_lo_w:.3f}, {ci_hi_w:.3f}]\")\n",
        "else:\n",
        "    print(\"Probability columns not found; weighted alignment skipped.\")\n",
        "\n",
        "if sub_tbl is not None:\n",
        "    print(\"\\nStratified by\", strata_col, \"(quartiles):\")\n",
        "    display(sub_tbl.reset_index(drop=True))\n",
        "else:\n",
        "    print(\"\\nStratified check skipped (no numeric magnitude/redshift surrogate found).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3UJqU3WFqzf",
        "outputId": "d9f63054-95b6-4f6c-a74d-3569ed3120cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded columns: ['ra', 'dec', 'spin'] ...\n",
            "Detected -> spin: spin | p_cw: None | p_ccw: None | RA/Dec: ra dec | strata: None\n",
            "\n",
            "Non-null spins: 667,944\n",
            "\n",
            "--- Mechanism 1 (Auto-Flip) : probability-weighted + subsample symmetry ---\n",
            "Dataset path: zip::/content/drive/MyDrive/repro_bundle.zip::sdss/SDSS_STANDARDIZED.csv\n",
            "As-coded fraction spin=+1: 0.285  |  Flip applied? True\n",
            "N = 667,944\n",
            "Unweighted aligned fraction: 0.715,  CI (Wilson): [0.714, 0.716],  z=351.77,  p_one_sided(theory)=0.00e+00\n",
            "Probability columns not found; weighted alignment skipped.\n",
            "\n",
            "Stratified check skipped (no numeric magnitude/redshift surrogate found).\n"
          ]
        }
      ]
    }
  ]
}