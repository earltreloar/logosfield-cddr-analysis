{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vVrosXsm0ggtIuMnPy_rIarxVs-kCORP",
      "authorship_tag": "ABX9TyNHWvxrlG3Mv/uwE34NPJvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earltreloar/logosfield-cddr-analysis/blob/main/1_2_million_galaxies_tested_(SDSS%2C_HSC%2C_JWST)_spin_alignment_correlation_to_Logosfield.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crmwu4WkpXiy",
        "outputId": "6ff7f6e4-c5e6-4948-a58b-2cac741f6928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: alignment_summary_bins.csv alignment_summary_bins.json Mechanism1_SDSS_HSC_alignment_by_redshift.png Mechanism1_SDSS_HSC_Repro.zip\n",
            "\n",
            "Head of per-bin summary:\n",
            "  survey  z_min  z_max       n  k_aligned  aligned_frac       k  p_hat  z_mid  \\\n",
            "0    HSC    0.3    1.0  325000        NaN         0.605  196625  0.605   0.65   \n",
            "1   SDSS    0.0    0.3  890450        NaN         0.623  554750  0.623   0.15   \n",
            "\n",
            "     ci_low   ci_high           z  p_two_tailed  \n",
            "0  0.603317  0.606681  119.718420           0.0  \n",
            "1  0.621992  0.624006  232.133858           0.0  \n"
          ]
        }
      ],
      "source": [
        "# === Mechanism #1 — SDSS + HSC Spin Alignment: Summary/Plot Repro Pack (no Bayes factor) ===\n",
        "# Outputs:\n",
        "#   * alignment_summary_bins.csv\n",
        "#   * alignment_summary_bins.json\n",
        "#   * Mechanism1_SDSS_HSC_alignment_by_redshift.png\n",
        "#   * methods_note.txt\n",
        "#   * Mechanism1_SDSS_HSC_Repro.zip\n",
        "\n",
        "import io, json, zipfile, math, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "USE_UPLOAD = False  # set True to upload a CSV with your final per-bin numbers\n",
        "TITLE = \"Mechanism #1 – Spin Alignment (SDSS + HSC, awaiting JWST)\"\n",
        "NULL_P = 0.5\n",
        "ALPHA = 0.05  # 95% CIs\n",
        "\n",
        "# Inline template data — replace with your exact bins or upload a CSV\n",
        "# You can provide either k_aligned OR aligned_frac per row (k_aligned takes precedence if both given)\n",
        "rows_inline = [\n",
        "    # survey, z_min, z_max,   n,    k_aligned, aligned_frac\n",
        "    [\"SDSS\", 0.00, 0.30, 890450,     None,      0.623],   # overall SDSS (example)\n",
        "    [\"HSC\",  0.30, 1.00, 325000,     None,      0.605],   # overall HSC (example)\n",
        "\n",
        "    # SDSS per-bin placeholders — fill with your counts/fractions when ready\n",
        "    [\"SDSS\", 0.00, 0.10, 342000,     None,      None],\n",
        "    [\"SDSS\", 0.10, 0.20, 291000,     None,      None],\n",
        "    [\"SDSS\", 0.20, 0.30, 198000,     None,      None],\n",
        "    [\"SDSS\", 0.30, 9.99,  59450,     None,      None],\n",
        "\n",
        "    # HSC per-bin placeholders — fill with your counts/fractions when ready\n",
        "    [\"HSC\",  0.30, 0.50, 120000,     None,      None],\n",
        "    [\"HSC\",  0.50, 0.80, 150000,     None,      None],\n",
        "    [\"HSC\",  0.80, 1.00,  55000,     None,      None],\n",
        "]\n",
        "\n",
        "# -------------- OPTIONAL UPLOAD --------------\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def read_uploaded_csv() -> Optional[pd.DataFrame]:\n",
        "    if not (USE_UPLOAD and IN_COLAB):\n",
        "        return None\n",
        "    print(\"Upload CSV with columns: survey,z_min,z_max,n,k_aligned,aligned_frac\")\n",
        "    up = files.upload()\n",
        "    if not up: return None\n",
        "    name = next(iter(up.keys()))\n",
        "    return pd.read_csv(io.BytesIO(up[name]))\n",
        "\n",
        "# -------------- STAT HELPERS (no Bayes) --------------\n",
        "def clopper_pearson_ci(k: int, n: int, alpha: float = ALPHA):\n",
        "    from scipy.stats import beta\n",
        "    if n <= 0: return (float(\"nan\"), float(\"nan\"))\n",
        "    lo = 0.0 if k == 0 else beta.ppf(alpha/2, k, n-k+1)\n",
        "    hi = 1.0 if k == n else beta.ppf(1 - alpha/2, k+1, n-k)\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "def z_test_p(value: float, n: int, p0: float = NULL_P, two_tailed: bool = True):\n",
        "    se = math.sqrt(p0*(1-p0)/n) if n > 0 else float(\"nan\")\n",
        "    z = (value - p0) / se if (se and se > 0) else float(\"nan\")\n",
        "    from math import erf\n",
        "    p_one = (0.5 * (1 - erf(abs(z)/math.sqrt(2)))) if np.isfinite(z) else float(\"nan\")\n",
        "    return (z, 2*p_one if two_tailed else p_one)\n",
        "\n",
        "# -------------- DATA INGEST --------------\n",
        "df_in = read_uploaded_csv()\n",
        "if df_in is None:\n",
        "    df_in = pd.DataFrame(rows_inline, columns=[\"survey\",\"z_min\",\"z_max\",\"n\",\"k_aligned\",\"aligned_frac\"])\n",
        "\n",
        "# Coerce types\n",
        "for c in [\"z_min\",\"z_max\",\"n\",\"k_aligned\",\"aligned_frac\"]:\n",
        "    df_in[c] = pd.to_numeric(df_in[c], errors=\"coerce\")\n",
        "df_in[\"survey\"] = df_in[\"survey\"].astype(str)\n",
        "\n",
        "# Build k (aligned count)\n",
        "def choose_k(row):\n",
        "    if pd.notna(row[\"k_aligned\"]):\n",
        "        return int(round(row[\"k_aligned\"]))\n",
        "    if pd.notna(row[\"aligned_frac\"]) and pd.notna(row[\"n\"]) and row[\"n\"]>0:\n",
        "        return int(round(row[\"aligned_frac\"] * row[\"n\"]))\n",
        "    return np.nan\n",
        "\n",
        "df = df_in.copy()\n",
        "df[\"k\"] = df.apply(choose_k, axis=1)\n",
        "df = df.dropna(subset=[\"k\",\"n\"]).copy()\n",
        "df[\"k\"] = df[\"k\"].astype(int)\n",
        "df[\"n\"] = df[\"n\"].astype(int)\n",
        "df[\"p_hat\"] = df[\"k\"] / df[\"n\"]\n",
        "df[\"z_mid\"] = 0.5*(df[\"z_min\"].fillna(0) + df[\"z_max\"].fillna(0))\n",
        "\n",
        "# CIs and z/p\n",
        "cis = df.apply(lambda r: clopper_pearson_ci(int(r[\"k\"]), int(r[\"n\"]), ALPHA), axis=1)\n",
        "df[\"ci_low\"]  = [c[0] for c in cis]\n",
        "df[\"ci_high\"] = [c[1] for c in cis]\n",
        "zp = df.apply(lambda r: z_test_p(r[\"p_hat\"], int(r[\"n\"]), NULL_P, True), axis=1)\n",
        "df[\"z\"] = [v[0] for v in zp]\n",
        "df[\"p_two_tailed\"] = [v[1] for v in zp]\n",
        "\n",
        "# -------------- SAVE TABLES --------------\n",
        "summary_csv  = \"alignment_summary_bins.csv\"\n",
        "summary_json = \"alignment_summary_bins.json\"\n",
        "df.sort_values([\"survey\",\"z_mid\"]).to_csv(summary_csv, index=False)\n",
        "with open(summary_json,\"w\") as f:\n",
        "    json.dump(df.to_dict(orient=\"records\"), f, indent=2)\n",
        "\n",
        "# -------------- PLOT --------------\n",
        "plt.figure(figsize=(9,5.2), dpi=160)\n",
        "\n",
        "# Null baseline and per-bin ±1σ under random (for that bin's n)\n",
        "for _, r in df.iterrows():\n",
        "    if r[\"n\"]>0:\n",
        "        sigma = math.sqrt(NULL_P*(1-NULL_P)/r[\"n\"])\n",
        "        plt.vlines(r[\"z_mid\"], NULL_P - sigma, NULL_P + sigma, alpha=0.15)\n",
        "plt.axhline(NULL_P, linestyle=\"--\", label=\"Random baseline (50%)\")\n",
        "\n",
        "for survey, grp in df.groupby(\"survey\"):\n",
        "    g = grp.sort_values(\"z_mid\")\n",
        "    yerr = np.vstack([g[\"p_hat\"]-g[\"ci_low\"], g[\"ci_high\"]-g[\"p_hat\"]])\n",
        "    plt.errorbar(g[\"z_mid\"], g[\"p_hat\"], yerr=yerr, fmt=\"o-\", capsize=3,\n",
        "                 label=f\"{survey} (n≈{int(g['n'].sum())})\")\n",
        "\n",
        "plt.title(TITLE)\n",
        "plt.xlabel(\"Redshift z (bin midpoints)\")\n",
        "plt.ylabel(\"Alignment fraction (θ < 15°)\")\n",
        "plt.ylim(0.45, 0.75)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plot_path = \"Mechanism1_SDSS_HSC_alignment_by_redshift.png\"\n",
        "plt.savefig(plot_path, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "# -------------- METHODS NOTE --------------\n",
        "methods = f\"\"\"Mechanism #1 – Spin Alignment (SDSS + HSC)\n",
        "Stats reported: per-bin counts (k, n), proportion p̂ = k/n, Clopper–Pearson {int((1-ALPHA)*100)}% CIs, and normal z-test vs 0.5.\n",
        "Null baseline: 50%. Rotational/shuffle nulls are part of the main alignment runner.\n",
        "This pack: {summary_csv}, {summary_json}, {plot_path}.\n",
        "\"\"\"\n",
        "with open(\"methods_note.txt\",\"w\") as f:\n",
        "    f.write(methods)\n",
        "\n",
        "# -------------- ZIP BUNDLE --------------\n",
        "zip_name = \"Mechanism1_SDSS_HSC_Repro.zip\"\n",
        "with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    z.write(summary_csv)\n",
        "    z.write(summary_json)\n",
        "    z.write(plot_path)\n",
        "    z.write(\"methods_note.txt\")\n",
        "\n",
        "print(\"Wrote:\", summary_csv, summary_json, plot_path, zip_name)\n",
        "print(\"\\nHead of per-bin summary:\")\n",
        "print(pd.read_csv(summary_csv).head(10))\n"
      ]
    }
  ]
}