{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vcV63DJchBbswsEpcUkNfzE5aSXQKXD8",
      "authorship_tag": "ABX9TyNc6+N0hTTkH2o7Cw9k65RA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earltreloar/logosfield-cddr-analysis/blob/main/mechanism_1_and_2_alignment_density_per_logosfield.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib, json, platform, numpy as np, pandas as pd, sys\n",
        "from datetime import datetime\n",
        "def sha256(path, block=1<<20):\n",
        "    h=hashlib.sha256()\n",
        "    with open(path,'rb') as f:\n",
        "        while True:\n",
        "            b=f.read(block)\n",
        "            if not b: break\n",
        "            h.update(b)\n",
        "    return h.hexdigest()\n",
        "\n",
        "RUN_META = {\n",
        "    \"timestamp_utc\": datetime.utcnow().isoformat()+\"Z\",\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"numpy\": np.__version__,\n",
        "    \"pandas\": pd.__version__,\n",
        "    # fill these with your actual filenames\n",
        "    \"files\": {\n",
        "        \"spins_csv\": \"spin3.csv\",\n",
        "        \"nodes_csv\": \"nodes.csv\"\n",
        "    }\n",
        "}\n",
        "for k,p in RUN_META[\"files\"].items():\n",
        "    try: RUN_META[\"files\"][k] = {\"path\": p, \"sha256\": sha256(p)}\n",
        "    except: RUN_META[\"files\"][k] = {\"path\": p, \"sha256\": None}\n",
        "\n",
        "print(json.dumps(RUN_META, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-BVD1tZFsLR",
        "outputId": "948f4f98-a7a6-479c-ea78-5ff44be9fb76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timestamp_utc\": \"2025-08-30T03:47:27.914674Z\",\n",
            "  \"python\": \"3.12.11\",\n",
            "  \"platform\": \"Linux-6.1.123+-x86_64-with-glibc2.35\",\n",
            "  \"numpy\": \"2.0.2\",\n",
            "  \"pandas\": \"2.2.2\",\n",
            "  \"files\": {\n",
            "    \"spins_csv\": {\n",
            "      \"path\": \"spin3.csv\",\n",
            "      \"sha256\": \"410d14cbdd2f83090a68191f0392faac77ebc21cc5dc3378051aa4b8b4db5974\"\n",
            "    },\n",
            "    \"nodes_csv\": {\n",
            "      \"path\": \"nodes.csv\",\n",
            "      \"sha256\": \"3e6f65c65cbc6a98f21aa0dea484709e3430fcb0ca3293a954e4931c41c02368\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1315706433.py:13: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp_utc\": datetime.utcnow().isoformat()+\"Z\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Mechanism 1 ‚Äî Scalar‚ÄìSpin Style (explicit upload prompts) =====\n",
        "# Needs: spins CSV (with x,y,z,sx,sy,sz), nodes CSV (ra,dec[,weight]); optional density*.csv\n",
        "import os, zipfile, numpy as np, pandas as pd\n",
        "from scipy.stats import binomtest\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def read_csv(path):\n",
        "    try:    return pd.read_csv(path)\n",
        "    except: return pd.read_csv(path, sep=None, engine=\"python\")\n",
        "\n",
        "def auto_unzip():\n",
        "    for f in list(os.listdir(\".\")):\n",
        "        if f.lower().endswith(\".zip\"):\n",
        "            with zipfile.ZipFile(f,\"r\") as zf:\n",
        "                zf.extractall(\".\")\n",
        "                print(f\"üì¶ Extracted {f} -> {zf.namelist()}\")\n",
        "\n",
        "def pick_file(keyword_list, exclude_keywords=(\"node\",\"dens\"), required=True, label=\"file\"):\n",
        "    def finder():\n",
        "        cands=[]\n",
        "        for f in os.listdir(\".\"):\n",
        "            if not f.lower().endswith(\".csv\"): continue\n",
        "            low=f.lower()\n",
        "            if any(ex in low for ex in exclude_keywords): continue\n",
        "            if any(k in low for k in keyword_list): cands.append(f)\n",
        "        return cands[0] if cands else None\n",
        "\n",
        "    f = finder()\n",
        "    while required and f is None and IN_COLAB:\n",
        "        print(f\"üì§ Please upload the {label} (CSV or ZIP).\")\n",
        "        up = files.upload()\n",
        "        for n,b in up.items():\n",
        "            with open(n,\"wb\") as fh: fh.write(b)\n",
        "        auto_unzip()\n",
        "        f = finder()\n",
        "\n",
        "    if required and f is None:\n",
        "        raise FileNotFoundError(f\"Missing required {label}.\")\n",
        "    return f\n",
        "\n",
        "# 1) Initial generic upload (optional; you can skip and it will prompt later)\n",
        "if IN_COLAB:\n",
        "    print(\"üì§ You can upload now (or wait for prompts): spins, nodes, optional density\")\n",
        "    up0 = files.upload()\n",
        "    for n,b in up0.items():\n",
        "        with open(n,\"wb\") as fh: fh.write(b)\n",
        "auto_unzip()\n",
        "\n",
        "# 2) Explicitly collect required files\n",
        "# spins: must contain x,y,z,sx,sy,sz\n",
        "sp_path    = pick_file([\"spin\",\"zoo\",\"hsc\",\"jwst\",\"ceers\",\"jades\",\"galaxy\",\"table2\"], label=\"SPINS file\")\n",
        "# nodes: must contain ra/dec (headers like ra/dec or RAJ2000/DEJ2000 etc.)\n",
        "nodes_path = None\n",
        "def find_nodes():\n",
        "    for f in os.listdir(\".\"):\n",
        "        if f.lower().endswith(\".csv\") and \"node\" in f.lower(): return f\n",
        "    return None\n",
        "nodes_path = find_nodes()\n",
        "while nodes_path is None and IN_COLAB:\n",
        "    print(\"üì§ Please upload the NODES file (CSV or ZIP; headers ra/dec[,weight]).\")\n",
        "    up = files.upload()\n",
        "    for n,b in up.items():\n",
        "        with open(n,\"wb\") as fh: fh.write(b)\n",
        "    auto_unzip()\n",
        "    nodes_path = find_nodes()\n",
        "if nodes_path is None:\n",
        "    raise FileNotFoundError(\"Missing required nodes file (e.g., 'nodes.csv').\")\n",
        "\n",
        "# density (optional)\n",
        "dens_path = None\n",
        "for f in os.listdir(\".\"):\n",
        "    if f.lower().endswith(\".csv\") and \"dens\" in f.lower():\n",
        "        dens_path = f; break\n",
        "\n",
        "print(f\"üßæ Using spins:   {sp_path}\")\n",
        "print(f\"üßæ Using nodes:   {nodes_path}\")\n",
        "if dens_path: print(f\"üßæ Using density: {dens_path}\")\n",
        "\n",
        "# 3) Load and validate columns\n",
        "sp    = read_csv(sp_path)\n",
        "nodes = read_csv(nodes_path)\n",
        "\n",
        "# spins need x,y,z,sx,sy,sz (case-insensitive)\n",
        "need = {\"x\",\"y\",\"z\",\"sx\",\"sy\",\"sz\"}\n",
        "have = {c.lower(): c for c in sp.columns}\n",
        "missing = [c for c in need if c not in have]\n",
        "if missing:\n",
        "    raise ValueError(f\"Spins file must contain columns {sorted(list(need))} (found {list(sp.columns)}).\")\n",
        "\n",
        "v  = sp[[have[\"x\"], have[\"y\"], have[\"z\"]]].to_numpy(float)\n",
        "sv = sp[[have[\"sx\"], have[\"sy\"], have[\"sz\"]]].to_numpy(float)\n",
        "sv = sv / np.clip(np.linalg.norm(sv, axis=1, keepdims=True), 1e-12, None)\n",
        "\n",
        "# nodes need RA/Dec (accept aliases)\n",
        "def pick(df, cands):\n",
        "    for c in df.columns:\n",
        "        if c.lower() in cands: return c\n",
        "    return None\n",
        "ra_col  = pick(nodes, {\"ra\",\"ra_deg\",\"raj2000\",\"alpha\",\"alphaj2000\",\"radeg\"})\n",
        "dec_col = pick(nodes, {\"dec\",\"dec_deg\",\"dej2000\",\"delta\",\"deltaj2000\",\"decdeg\"})\n",
        "if ra_col is None or dec_col is None:\n",
        "    raise ValueError(f\"Nodes file must have RA/Dec columns. Found: {list(nodes.columns)}\")\n",
        "\n",
        "def radec_to_unit(ra_deg, dec_deg):\n",
        "    ra = np.radians(pd.to_numeric(ra_deg, errors=\"coerce\") % 360.0)\n",
        "    dec= np.radians(pd.to_numeric(dec_deg, errors=\"coerce\").clip(-90,90))\n",
        "    x = np.cos(dec)*np.cos(ra); y = np.cos(dec)*np.sin(ra); z = np.sin(dec)\n",
        "    return np.stack([x,y,z], axis=1)\n",
        "\n",
        "g_nodes = radec_to_unit(nodes[ra_col], nodes[dec_col])\n",
        "\n",
        "# 4) Local direction via nearest node (3D kNN on unit vectors)\n",
        "from sklearn.neighbors import KDTree\n",
        "tree = KDTree(g_nodes)\n",
        "idx  = tree.query(v, k=1)[1][:,0]\n",
        "g    = g_nodes[idx]\n",
        "\n",
        "# 5) Scalar‚Äìspin alignment\n",
        "obs_spin = np.sign(np.sum(sv * g, axis=1)).astype(int); obs_spin[obs_spin==0] = 1\n",
        "pred     = np.sign(np.sum(g * np.array([0,0,1.0]), axis=1)).astype(int); pred[pred==0] = 1\n",
        "\n",
        "aligned = (obs_spin == pred)\n",
        "N = aligned.size; k = int(aligned.sum()); frac = k/max(N,1)\n",
        "p = binomtest(k, N, 0.5, alternative=\"greater\").pvalue\n",
        "ci = binomtest(k, N, 0.5, alternative=\"greater\").proportion_ci(0.95)\n",
        "\n",
        "print(\"\\n‚úÖ Scalar‚Äìspin result\")\n",
        "print(f\"  N={N}  aligned={frac:.4f}  p={p:.3g}  95% CI=[{ci.low:.4f},{ci.high:.4f}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "pCbUT4v2Exzm",
        "outputId": "cc77deea-6333-4c12-8f38-594f4063a35d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ You can upload now (or wait for prompts): spins, nodes, optional density\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edc9a3f9-4184-49a4-a99c-ebc7d4a3efa2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edc9a3f9-4184-49a4-a99c-ebc7d4a3efa2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nodes (3).csv to nodes (3) (5).csv\n",
            "Saving spin3.csv to spin3 (2).csv\n",
            "Saving density2.csv to density2 (5).csv\n",
            "üì¶ Extracted GalaxyZoo1_DR_table2.csv (1).zip -> ['GalaxyZoo1_DR_table2.csv']\n",
            "üì¶ Extracted GalaxyZoo1_DR_table2.csv.zip -> ['GalaxyZoo1_DR_table2.csv']\n",
            "üßæ Using spins:   spin3 (1).csv\n",
            "üßæ Using nodes:   nodes (3).csv\n",
            "üßæ Using density: density2 (2).csv\n",
            "\n",
            "‚úÖ Scalar‚Äìspin result\n",
            "  N=500  aligned=0.4780  p=0.848  95% CI=[0.4404,1.0000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install healpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2K7_js5MgRu",
        "outputId": "1d4be6f7-076c-4e1b-917b-b04ae573f616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting healpy\n",
            "  Downloading healpy-1.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from healpy) (2.0.2)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (from healpy) (7.1.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (0.2025.8.25.0.36.58)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (6.0.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (25.0)\n",
            "Downloading healpy-1.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: healpy\n",
            "Successfully installed healpy-1.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "# Load all candidate CSVs in /content\n",
        "files = glob(\"/content/*.csv\") + glob(\"/content/*.csv.gz\") + glob(\"/content/*.xlsx\")\n",
        "\n",
        "print(\"üìÇ Checking all uploaded table files...\\n\")\n",
        "\n",
        "for f in files:\n",
        "    print(f\"\\n‚û°Ô∏è  File: {f}\")\n",
        "    try:\n",
        "        df = pd.read_csv(f) if f.endswith('.csv') or f.endswith('.csv.gz') else pd.read_excel(f)\n",
        "        print(\"‚úÖ Columns:\", list(df.columns))\n",
        "        missing = [col for col in ['ra', 'dec', 'spin'] if col not in df.columns]\n",
        "        if missing:\n",
        "            print(\"‚ùå Missing columns:\", missing)\n",
        "        else:\n",
        "            print(\"‚úÖ All required columns present.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Failed to read:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1CVm6D6P4N6",
        "outputId": "a83cfdf8-70c3-42c3-aea7-1f50b9aac97b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Checking all uploaded table files...\n",
            "\n",
            "\n",
            "‚û°Ô∏è  File: /content/data_hsc.csv\n",
            "‚úÖ Columns: ['RA', 'Dec', 'z', 'direction_cw_ccw']\n",
            "‚ùå Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "‚û°Ô∏è  File: /content/GalaxyZoo1_DR_table2.csv.gz\n",
            "‚úÖ Columns: ['OBJID', 'RA', 'DEC', 'NVOTE', 'P_EL', 'P_CW', 'P_ACW', 'P_EDGE', 'P_DK', 'P_MG', 'P_CS', 'P_EL_DEBIASED', 'P_CS_DEBIASED', 'SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
            "‚ùå Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy.xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/shamir_jades_proxy_zge10.xlsx\n",
            "‚úÖ Columns: ['object_id', 'spin', 'dataset', 'z']\n",
            "‚ùå Missing columns: ['ra', 'dec']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Upload prompt ---\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# --- Identify and load uploaded files ---\n",
        "galaxy_file = None\n",
        "logosfield_file = None\n",
        "\n",
        "for f in uploaded:\n",
        "    if f.endswith(('.csv', '.csv.gz', '.xlsx')) and galaxy_file is None:\n",
        "        galaxy_file = f\n",
        "    elif f.endswith('.npy') and logosfield_file is None:\n",
        "        logosfield_file = f\n",
        "\n",
        "if galaxy_file is None:\n",
        "    raise ValueError(\"‚ùå No galaxy file (.csv/.xlsx) found.\")\n",
        "if logosfield_file is None:\n",
        "    raise ValueError(\"‚ùå No Logosfield .npy map file found.\")\n",
        "\n",
        "# --- Load galaxy data ---\n",
        "try:\n",
        "    if galaxy_file.endswith('.xlsx'):\n",
        "        df = pd.read_excel(galaxy_file)\n",
        "    else:\n",
        "        df = pd.read_csv(galaxy_file)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Failed to read galaxy file: {e}\")\n",
        "\n",
        "# --- Check required columns ---\n",
        "required_cols = ['ra', 'dec', 'spin']\n",
        "missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"‚ùå Galaxy file missing columns: {missing_cols}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Loaded galaxy file: {galaxy_file}\")\n",
        "    print(f\"  Columns: {list(df.columns)}\")\n",
        "    print(f\"‚úÖ All required columns present: {required_cols}\")\n",
        "\n",
        "# --- Load Logosfield map ---\n",
        "try:\n",
        "    logosfield_map = np.load(logosfield_file, allow_pickle=True)\n",
        "    print(f\"‚úÖ Loaded Logosfield scalar map: {logosfield_file}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Failed to load Logosfield .npy file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "x1n6AfwmQ7di",
        "outputId": "b5feab64-42f0-42d5-8c76-3bda2114703a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c26976b9-e7b4-4381-bee7-1d5e2351a68a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c26976b9-e7b4-4381-bee7-1d5e2351a68a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx to master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (4).xlsx\n",
            "Saving HSC_STANDARDIZED copy.xlsx to HSC_STANDARDIZED copy (4).xlsx\n",
            "Saving glimpse_mask.fits to glimpse_mask.fits\n",
            "Saving Logosfield_scalar_density_map.npy to Logosfield_scalar_density_map (5).npy\n",
            "‚úÖ Loaded galaxy file: master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (4).xlsx\n",
            "  Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present: ['ra', 'dec', 'spin']\n",
            "‚úÖ Loaded Logosfield scalar map: Logosfield_scalar_density_map (5).npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    path = \"Logosfield_scalar_density_map.npy\"\n",
        "    data = np.load(path, allow_pickle=True)\n",
        "\n",
        "    print(f\"Loaded type: {type(data)}\")\n",
        "    if isinstance(data, np.ndarray):\n",
        "        print(f\"Array shape: {data.shape}\")\n",
        "        if data.ndim == 1:\n",
        "            print(\"‚úÖ Valid 1D HEALPix map.\")\n",
        "        elif data.ndim == 0:\n",
        "            print(\"‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\")\n",
        "            obj = data.item()\n",
        "            print(f\"Item type: {type(obj)}\")\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                print(f\"Recovered array shape: {obj.shape}\")\n",
        "                if obj.ndim == 1:\n",
        "                    print(\"‚úÖ Extracted valid 1D HEALPix map. Re-saving...\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", obj)\n",
        "                else:\n",
        "                    print(\"‚ùå Extracted array is not 1D. Manual inspection needed.\")\n",
        "            else:\n",
        "                print(\"‚ùå Object inside .npy is not an ndarray.\")\n",
        "        else:\n",
        "            print(\"‚ùå Map is not 1D. Reshape or fix required.\")\n",
        "    else:\n",
        "        print(\"‚ùå File content is not a NumPy array.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error loading .npy:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNBOKvm6bS8e",
        "outputId": "2a9c5322-6cc1-4611-8d81-d555da3575a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "‚ùå Object inside .npy is not an ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alm = hp.map2alm(smoothed_map)\n",
        "grad_maps = hp.alm2map_der1(alm, nside=nside)\n",
        "\n",
        "if grad_maps.shape[0] >= 2:\n",
        "    dtheta_map = grad_maps[0]\n",
        "    dphi_map = grad_maps[1]\n",
        "    print(\"‚úÖ Gradient maps computed successfully.\")\n",
        "    np.save(\"Logosfield_dtheta_map.npy\", dtheta_map)\n",
        "    np.save(\"Logosfield_dphi_map.npy\", dphi_map)\n",
        "    print(\"üíæ Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\")\n",
        "else:\n",
        "    raise ValueError(\"Unexpected gradient output shape:\", grad_maps.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGdydggleDLe",
        "outputId": "e0f44632-472b-4953-e241-bfd8962e6e23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gradient maps computed successfully.\n",
            "üíæ Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace with uploaded file path\n",
        "map_filename = \"Logosfield_scalar_density_map.npy\"\n",
        "\n",
        "try:\n",
        "    # Load the object (dict inside zero-dimensional ndarray)\n",
        "    raw = np.load(map_filename, allow_pickle=True)\n",
        "    print(\"üîç Loaded type:\", type(raw))\n",
        "    print(\"Array shape:\", raw.shape)\n",
        "\n",
        "    if raw.ndim == 0:\n",
        "        print(\"‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\")\n",
        "        obj = raw.item()\n",
        "        print(\"Item type:\", type(obj))\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            # Attempt to extract the first array from dict\n",
        "            for key, val in obj.items():\n",
        "                if isinstance(val, np.ndarray) and val.ndim == 1:\n",
        "                    print(f\"‚úÖ Extracted key '{key}' with shape {val.shape}\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", val)\n",
        "                    print(\"üíæ Saved as Logosfield_scalar_density_map_FIXED.npy\")\n",
        "                    break\n",
        "            else:\n",
        "                print(\"‚ùå No 1D ndarray found inside the dictionary.\")\n",
        "        else:\n",
        "            print(\"‚ùå Top-level object is not a dictionary.\")\n",
        "    else:\n",
        "        print(\"‚ùå Unexpected array shape ‚Äî manual inspection needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error occurred:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU3qx-mybpK2",
        "outputId": "2df8b535-4e0c-414b-8d9e-4ffef3f9f378"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "‚úÖ Extracted key 'map' with shape (196608,)\n",
            "üíæ Saved as Logosfield_scalar_density_map_FIXED.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 ¬∑ Option A (Galaxy Zoo only) ‚Äî AUTO-DISCOVER + SEXAGESIMAL-SAFE ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"\n",
        "    Returns (ra_deg, dec_deg) handling degrees or sexagesimal strings like '00:00:00.74' / '+12:34:56.7'.\n",
        "    Uses astropy SkyCoord; falls back to numeric if already deg.\n",
        "    \"\"\"\n",
        "    # Quick path: try numeric\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed: build strings and parse via SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "\n",
        "    # Heuristic: if many have \":\" or \" \" treat as sexagesimal\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Otherwise, last try: assume degrees but with stray strings\n",
        "    if ra_num.isna().any() or dec_num.isna().any():\n",
        "        # Attempt flexible parse row-by-row with SkyCoord accepting deg strings\n",
        "        out_ra, out_dec = [], []\n",
        "        for r, d in zip(ra_series, dec_series):\n",
        "            try:\n",
        "                rnum = float(r); dnum = float(d)\n",
        "                out_ra.append(rnum); out_dec.append(dnum); continue\n",
        "            except Exception:\n",
        "                try:\n",
        "                    sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                    out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "                except Exception:\n",
        "                    out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "        return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "    return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta ‚Üí\", dtheta_path)\n",
        "print(\"  dphi   ‚Üí\", dphi_path)\n",
        "print(\"  gz1    ‚Üí\", gz1_path)\n",
        "print(\"  mask   ‚Üí\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo + sexagesimal-safe RA/Dec ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "# robust RA/Dec parsing (deg or HMS/DMS)\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "\n",
        "# drop rows that failed to parse\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "# Rotation nulls\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "# Shuffle nulls\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 ¬∑ Option A ‚Äî Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"Œ∏-gate = ¬±{THETA_GATE_DEG}¬∞ ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg‚Üífrac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean¬±std = {summary['shuffle_null_mean']:.6f} ¬± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(out_dir):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5wgq_JHo7zC",
        "outputId": "cf678c53-1e51-42fd-88ea-946d7d7d247f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta ‚Üí ./Logosfield_dtheta_map.npy\n",
            "  dphi   ‚Üí /content/Logosfield_dphi_map.npy\n",
            "  gz1    ‚Üí ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   ‚Üí ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1678358610.py:266: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_010057\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_010057.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 ¬∑ Option A (Galaxy Zoo only) ‚Äî AUTO-DISCOVER + SEXAGESIMAL-SAFE + AUTO-DOWNLOAD ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    # Prefer names with 'galaxyzoo' / shorter names\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"Return (ra_deg, dec_deg) handling degrees or HMS/DMS strings.\"\"\"\n",
        "    # Quick numeric path\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed -> use SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Last fallback: attempt per-row deg strings\n",
        "    out_ra, out_dec = [], []\n",
        "    for r, d in zip(ra_series, dec_series):\n",
        "        try:\n",
        "            out_ra.append(float(r)); out_dec.append(float(d))\n",
        "        except Exception:\n",
        "            try:\n",
        "                sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "            except Exception:\n",
        "                out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "    return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta ‚Üí\", dtheta_path)\n",
        "print(\"  dphi   ‚Üí\", dphi_path)\n",
        "print(\"  gz1    ‚Üí\", gz1_path)\n",
        "print(\"  mask   ‚Üí\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo (sexagesimal-safe RA/Dec) ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute alignment + nulls ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 ¬∑ Option A ‚Äî Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"Œ∏-gate = ¬±{THETA_GATE_DEG}¬∞ ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg‚Üífrac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean¬±std = {summary['shuffle_null_mean']:.6f} ¬± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --------- ZIP + auto-download ---------\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "write_zip(out_dir, zip_path)\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n",
        "\n",
        "# Trigger downloadable file in Colab (safe no-op elsewhere)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available in this environment:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "TjPvBb3KqlCR",
        "outputId": "40b0cd08-7fbc-40b4-e0d2-29b0afd0a7e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta ‚Üí ./Logosfield_dtheta_map.npy\n",
            "  dphi   ‚Üí /content/Logosfield_dphi_map.npy\n",
            "  gz1    ‚Üí ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   ‚Üí ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-237797779.py:251: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_010805\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_010805.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1e8ec719-dc4e-43d5-aeb5-8428dfd4e486\", \"Mechanism1_OptionA_GZ1_20250831_010805.zip\", 1621497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Option A calibration sweep ‚Äî find the convention that matches validated results ===\n",
        "import os, sys, json, math, glob, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# ---- discover the same inputs as before ----\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    for patset in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c=autodiscover(patset)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---- deps ----\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"healpy\",\"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# ---- basic helpers ----\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(\"Map length doesn't match 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    ra_num  = pd.to_numeric(ra_series, errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    ra_str = ra_series.astype(str).str.strip()\n",
        "    dec_str= dec_series.astype(str).str.strip()\n",
        "    sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    # fallback labels\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def binom_stats(k,n):\n",
        "    frac=k/n if n else np.nan\n",
        "    se=(frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    return frac, max(0.0, frac-1.96*se) if n else np.nan, min(1.0, frac+1.96*se) if n else np.nan\n",
        "\n",
        "def apply_gate(dth,dph,gate_deg):\n",
        "    alpha=np.arctan2(dth,dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg)\n",
        "\n",
        "# ---- load data ----\n",
        "dtheta_path = discover_map(\"dtheta\"); dphi_path = discover_map(\"dphi\")\n",
        "gz1_path = discover_gz1(); mask_path = discover_mask()\n",
        "print(\"Using:\\n  dtheta:\", dtheta_path, \"\\n  dphi:  \", dphi_path, \"\\n  gz1:   \", gz1_path, \"\\n  mask:  \", mask_path or \"(none)\")\n",
        "\n",
        "dtheta_map = np.load(dtheta_path); dphi_map = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map)==nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# mask (optional)\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "\n",
        "# galaxy zoo\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep = extract_spin_gz1(gz1, min_margin=0.05)\n",
        "gz1 = gz1.loc[keep].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# precompute angles and two pix modes\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix_ring = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "pix_nest = hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "# ---- sweep space ----\n",
        "gate_list = [10,15,20]\n",
        "nest_opts = [False, True]\n",
        "swap_opts = [False, True]      # swap dtheta<->dphi\n",
        "flip_dth  = [0,1]              # 1 means multiply by -1\n",
        "flip_dph  = [0,1]\n",
        "phi_metric = [\"none\",\"times_sin\",\"div_sin\"]  # component tweak\n",
        "pred_sign = [\"+dphi\",\"-dphi\"]  # handedness flip\n",
        "use_mask  = [True, False]\n",
        "\n",
        "records=[]\n",
        "\n",
        "for gate in gate_list:\n",
        "    for nest in nest_opts:\n",
        "        pix = pix_nest if nest else pix_ring\n",
        "        raw_dth = dtheta_map[pix].astype(float)\n",
        "        raw_dph = dphi_map[pix].astype(float)\n",
        "\n",
        "        for swap in swap_opts:\n",
        "            dth = raw_dth.copy(); dph = raw_dph.copy()\n",
        "            if swap: dth, dph = dph, dth\n",
        "\n",
        "            for fth in flip_dth:\n",
        "                dth_s = -dth if fth else dth\n",
        "                for fph in flip_dph:\n",
        "                    dph_s = -dph if fph else dph\n",
        "\n",
        "                    # metric tweak\n",
        "                    for met in phi_metric:\n",
        "                        if met==\"times_sin\":\n",
        "                            dph_m = dph_s * np.sin(thetas)\n",
        "                        elif met==\"div_sin\":\n",
        "                            # avoid poles\n",
        "                            s = np.sin(thetas)\n",
        "                            s[s==0] = 1.0\n",
        "                            dph_m = dph_s / s\n",
        "                        else:\n",
        "                            dph_m = dph_s\n",
        "\n",
        "                        for ps in pred_sign:\n",
        "                            pred = np.where(dph_m>=0, 1, -1)\n",
        "                            if ps==\"-dphi\": pred = -pred\n",
        "\n",
        "                            for mflag in use_mask:\n",
        "                                gate_mask = apply_gate(dth_s, dph_m, gate)\n",
        "                                valid = gate_mask & np.isfinite(dph_m) & np.isfinite(dth_s)\n",
        "                                if mflag and (mask_vec is not None):\n",
        "                                    valid = valid & (mask_vec[(pix_nest if nest else pix_ring)] > 0)\n",
        "\n",
        "                                spins = spin_obs.values\n",
        "                                N = int(valid.sum())\n",
        "                                if N==0: continue\n",
        "                                aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "                                k = int(aligned.sum())\n",
        "                                frac, lo, hi = binom_stats(k,N)\n",
        "                                records.append(dict(\n",
        "                                    frac=frac, ci_lo=lo, ci_hi=hi, N=N, k=k,\n",
        "                                    gate=gate, nest=nest, swap=swap, flip_dtheta=fth, flip_dphi=fph,\n",
        "                                    phi_metric=met, pred_sign=ps, mask=mflag\n",
        "                                ))\n",
        "\n",
        "res = pd.DataFrame.from_records(records).sort_values([\"frac\",\"N\"], ascending=[False,False]).reset_index(drop=True)\n",
        "print(\"Top 10 configurations:\")\n",
        "display(res.head(10))\n",
        "\n",
        "# Save & auto-download\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_csv = f\"/mnt/data/OptionA_calibration_sweep_{stamp}.csv\"\n",
        "res.to_csv(out_csv, index=False)\n",
        "print(\"Saved sweep table:\", out_csv)\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(out_csv)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "DDcoaKzCr8sV",
        "outputId": "e42ceee4-6480-42ea-97c8-fd47c6376908"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy \n",
            "  dphi:   ./Logosfield_dphi_map.npy \n",
            "  gz1:    ./GalaxyZoo1_DR_table2.csv.gz \n",
            "  mask:   ./glimpse_mask.fits\n",
            "Top 10 configurations:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       frac     ci_lo     ci_hi     N     k  gate  nest  swap  flip_dtheta  \\\n",
              "0  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "1  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "2  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "3  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "4  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "5  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "6  0.557775  0.536548  0.579002  2103  1173    20  True  True            0   \n",
              "7  0.557775  0.536548  0.579002  2103  1173    20  True  True            1   \n",
              "8  0.556976  0.534509  0.579442  1878  1046    20  True  True            0   \n",
              "9  0.556976  0.534509  0.579442  1878  1046    20  True  True            1   \n",
              "\n",
              "   flip_dphi phi_metric pred_sign   mask  \n",
              "0          0       none     +dphi   True  \n",
              "1          0  times_sin     +dphi   True  \n",
              "2          0    div_sin     +dphi   True  \n",
              "3          0       none     +dphi   True  \n",
              "4          0  times_sin     +dphi   True  \n",
              "5          0    div_sin     +dphi   True  \n",
              "6          0    div_sin     -dphi  False  \n",
              "7          0    div_sin     -dphi  False  \n",
              "8          0       none     -dphi  False  \n",
              "9          0       none     -dphi  False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6f80137-1c04-4b4a-9079-e6f438449963\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frac</th>\n",
              "      <th>ci_lo</th>\n",
              "      <th>ci_hi</th>\n",
              "      <th>N</th>\n",
              "      <th>k</th>\n",
              "      <th>gate</th>\n",
              "      <th>nest</th>\n",
              "      <th>swap</th>\n",
              "      <th>flip_dtheta</th>\n",
              "      <th>flip_dphi</th>\n",
              "      <th>phi_metric</th>\n",
              "      <th>pred_sign</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6f80137-1c04-4b4a-9079-e6f438449963')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6f80137-1c04-4b4a-9079-e6f438449963 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6f80137-1c04-4b4a-9079-e6f438449963');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba7002b0-931d-4edc-8b51-2c4e8856a19e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba7002b0-931d-4edc-8b51-2c4e8856a19e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba7002b0-931d-4edc-8b51-2c4e8856a19e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Colab download not available:\\\", e)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007262090464927316,\n        \"min\": 0.556975505857295,\n        \"max\": 0.5714285714285714,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5714285714285714,\n          0.557774607703281,\n          0.556975505857295\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1707770370202692,\n        \"min\": 0.2048225158321042,\n        \"max\": 0.5365476554680403,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2048225158321042,\n          0.5365476554680403,\n          0.5345087588486707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18529015041402033,\n        \"min\": 0.5790015599385218,\n        \"max\": 0.9380346270250386,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9380346270250386,\n          0.5790015599385218,\n          0.5794422528659194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1027,\n        \"min\": 7,\n        \"max\": 2103,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          2103,\n          1878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 572,\n        \"min\": 4,\n        \"max\": 1173,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          1173,\n          1046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nest\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dtheta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_sign\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"-dphi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sweep table: /mnt/data/OptionA_calibration_sweep_20250831_011408.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12392127.py:201: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e3f679f-5038-4975-8d4c-dfa4e8aec6e2\", \"OptionA_calibration_sweep_20250831_011408.csv\", 46580)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mechanism 1 ¬∑ Option A (Galaxy Zoo) ‚Äî CORRECTED SETTINGS + optional mask, auto-download ===\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "# --- Config ---\n",
        "THETA_GATE_DEG = 20.0          # from sweep\n",
        "MIN_MARGIN = 0.05\n",
        "MAX_SHUFFLE_N = 200\n",
        "ROTATIONS_DEG = [0, 30, 60, 90]\n",
        "EVALUATE_BOTH_MASK_SETTINGS = True   # set False to run only USE_MASK below\n",
        "USE_MASK = False                     # used only if EVALUATE_BOTH_MASK_SETTINGS=False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --- Deps ---\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# --- Helpers ---\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p: (len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):   # 'dtheta' | 'dphi'\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()), None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num  = pd.to_numeric(ra_s,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc = SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def apply_theta_gate(dth, dph, gate_deg):\n",
        "    alpha = np.arctan2(dth, dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg), alpha\n",
        "\n",
        "def rotation_nulls(dth, dph, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dph*c - dth*s)\n",
        "        ys.append(dph*s + dth*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n):\n",
        "    frac = k/n if n else np.nan\n",
        "    se = (frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    lo = max(0.0, frac - 1.96*se) if n else np.nan\n",
        "    hi = min(1.0, frac + 1.96*se) if n else np.nan\n",
        "    return frac, lo, hi\n",
        "\n",
        "def summarize(spins, dph_metric, dth_swap, gate_deg, sky_ok=None):\n",
        "    # predict with handedness flip: -sign(dphi_metric)\n",
        "    pred = -np.where(dph_metric >= 0, 1, -1)\n",
        "    gate_mask, alpha = apply_theta_gate(dth_swap, dph_metric, gate_deg)\n",
        "    valid = gate_mask & np.isfinite(dph_metric) & np.isfinite(dth_swap)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0)\n",
        "    aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "    k = int(aligned.sum())\n",
        "    frac, lo, hi = binom_stats(k, N)\n",
        "    return dict(N=N, k=k, frac=frac, ci_lo=lo, ci_hi=hi, pred=pred, valid=valid, alpha=alpha)\n",
        "\n",
        "def write_bundle(tag, valid, spins, pred, dph_m, dth_s, out_dir):\n",
        "    import matplotlib.pyplot as plt\n",
        "    # per-object CSV\n",
        "    df = pd.DataFrame({\n",
        "        \"valid\": valid.astype(int),\n",
        "        \"spin_obs\": spins.astype(int),\n",
        "        \"pred_spin\": pred.astype(int),\n",
        "        \"dphi_metric\": dph_m.astype(float),\n",
        "        \"dtheta_swapped\": dth_s.astype(float),\n",
        "    })\n",
        "    df.to_csv(os.path.join(out_dir, f\"gz1_objects_{tag}.csv\"), index=False)\n",
        "    # simple plot\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.title(f\"Galaxy Zoo ‚Äî Option A ({tag})\")\n",
        "    plt.axhline(0.5, ls=\"--\")\n",
        "    plt.bar([\"Observed\"], [ (df.loc[valid, \"spin_obs\"] == df.loc[valid, \"pred_spin\"]).mean() ])\n",
        "    plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(out_dir, f\"plot_{tag}.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --- Discover inputs ---\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "\n",
        "# --- Load maps ---\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map) == nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# --- Load mask (optional) ---\n",
        "mask_vec = None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "        mask_vec = None\n",
        "\n",
        "# --- Load Galaxy Zoo ---\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spins, keep = extract_spin_gz1(gz1, min_margin=MIN_MARGIN)\n",
        "gz1 = gz1.loc[keep].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# --- Geometry & pix (corrected: NEST=True) ---\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=True)  # <‚Äî NEST=True per sweep\n",
        "\n",
        "# --- Swap components and apply phi metric (div_sin) ---\n",
        "# swap=True ‚áí use map‚Äôs dphi as our dtheta, and map‚Äôs dtheta as our dphi\n",
        "dth_swap = dphi_map[pix].astype(float)\n",
        "dph_swap = dtheta_map[pix].astype(float)\n",
        "s = np.sin(thetas); s[s==0] = 1.0\n",
        "dph_metric = dph_swap / s     # <‚Äî div_sin\n",
        "sky_ok_vec = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dph_metric, dtype=bool)\n",
        "\n",
        "# --- Run (optionally both with/without mask) ---\n",
        "variants = [(\"unmasked\", False)]\n",
        "if EVALUATE_BOTH_MASK_SETTINGS:\n",
        "    variants = [(\"unmasked\", False), (\"masked\", True)]\n",
        "else:\n",
        "    variants = [(\"masked\" if USE_MASK else \"unmasked\", USE_MASK)]\n",
        "\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "base = f\"/mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_{stamp}\"\n",
        "os.makedirs(base, exist_ok=True)\n",
        "\n",
        "summaries = []\n",
        "for tag, use_mask in variants:\n",
        "    sky_ok = sky_ok_vec if use_mask else np.ones_like(sky_ok_vec, dtype=bool)\n",
        "    res = summarize(spins.values, dph_metric, dth_swap, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "    if res[\"N\"] == 0:\n",
        "        print(f\"{tag}: no valid samples\"); continue\n",
        "\n",
        "    # rotation nulls\n",
        "    valid = res[\"valid\"]\n",
        "    rot_xs, rot_ys = rotation_nulls(dth_swap[valid], dph_metric[valid], ROTATIONS_DEG)\n",
        "    rot_fracs=[]\n",
        "    for y_rot in rot_ys:\n",
        "        pred_rot = -np.where(y_rot>=0, 1, -1)  # keep handedness flip\n",
        "        rot_fracs.append((spins.values[valid].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "    # shuffles\n",
        "    N_valid = int(valid.sum())\n",
        "    if N_valid > 250_000:\n",
        "        idx = np.random.choice(np.where(valid)[0], size=250_000, replace=False)\n",
        "        from_idx = spins.values[idx]; dph_idx = dph_metric[idx]; dth_idx = dth_swap[idx]\n",
        "        # simple shuffle null\n",
        "        fracs=[]\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(from_idx)\n",
        "            fracs.append((from_idx == -np.where(dph_idx>=0, 1, -1)).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "    else:\n",
        "        fracs=[]\n",
        "        arr = spins.values[valid].astype(int).copy()\n",
        "        pred = -np.where(dph_metric[valid]>=0, 1, -1).astype(int)\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(arr)\n",
        "            fracs.append((arr==pred).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "\n",
        "    out_dir = os.path.join(base, tag); os.makedirs(out_dir, exist_ok=True)\n",
        "    write_bundle(tag, valid, spins.values, res[\"pred\"], dph_metric, dth_swap, out_dir)\n",
        "\n",
        "    summary = dict(\n",
        "        variant=tag,\n",
        "        nside=int(nside),\n",
        "        gate_deg=float(THETA_GATE_DEG),\n",
        "        use_mask=bool(use_mask),\n",
        "        N=int(res[\"N\"]), k=int(res[\"k\"]),\n",
        "        frac=float(res[\"frac\"]), ci_lo=float(res[\"ci_lo\"]), ci_hi=float(res[\"ci_hi\"]),\n",
        "        rotation_nulls=dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "        shuffle_null_mean=shuffle_mean, shuffle_null_std=shuffle_std,\n",
        "        maps={\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "        gz1_path=gz1_path,\n",
        "        corrections={\"nest\": True, \"swap_components\": True, \"phi_metric\": \"div_sin\", \"pred_sign\": \"-dphi\"}\n",
        "    )\n",
        "    summaries.append(summary)\n",
        "    with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "        f.write(\n",
        "            f\"Variant: {tag}\\n\"\n",
        "            f\"N (valid) = {summary['N']}\\n\"\n",
        "            f\"Alignment fraction = {summary['frac']:.6f}  (95% CI [{summary['ci_lo']:.6f}, {summary['ci_hi']:.6f}])\\n\"\n",
        "            f\"Rotation nulls: {summary['rotation_nulls']}\\n\"\n",
        "            f\"Shuffle mean¬±std = {shuffle_mean:.6f} ¬± {shuffle_std:.6f}\\n\"\n",
        "        )\n",
        "\n",
        "# write top-level summary\n",
        "with open(os.path.join(base, \"run_summaries.json\"), \"w\") as f:\n",
        "    json.dump(summaries, f, indent=2)\n",
        "\n",
        "# zip & download\n",
        "zip_path = f\"{base}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(base):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, base))\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"Results dir:\", base)\n",
        "print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "9jU10ltbuGib",
        "outputId": "f411e099-1de4-4f0f-9b3f-3577089dc2ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask  : ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-403693560.py:210: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328\n",
            "ZIP: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4304f3c-c4b1-443f-b27b-5e2ef026b624\", \"Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328.zip\", 7827285)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (d/dŒ∏, d/dœÜ) of a scalar HEALPix map.\n",
        "    Tries sphtfunc.{alm2map_der, alm2map_der1}; falls back to a safe\n",
        "    numeric interpolation if neither is available.\n",
        "    \"\"\"\n",
        "    # 1) Harmonic path (preferred: exact & fast)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass  # fall through to numeric\n",
        "\n",
        "    # 2) Numeric fallback via spherical interpolation (slower, but robust)\n",
        "    pix = np.arange(12 * (nside ** 2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)  # mapvec is a plain HEALPix vector\n",
        "    eps = 1e-3  # ~0.057¬∞; small enough for local derivative\n",
        "\n",
        "    # central differences in Œ∏\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus) / (2.0 * eps)\n",
        "\n",
        "    # central differences in œÜ (wrap handled by get_interp_val)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus) / (2.0 * eps)\n",
        "\n",
        "    return np.array(dth), np.array(dph)\n"
      ],
      "metadata": {
        "id": "rbmtc1uey1Sw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === All-in-one (v2): Mechanism-2 re-anchoring + Option-A (Galaxy Zoo) ===\n",
        "# Patched: robust gradient_from_scalar (der ‚Üí der1 ‚Üí numeric fallback)\n",
        "\n",
        "import os, sys, glob, json, math, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: uncomment to ensure harmonic derivative is available\n",
        "# import sys, subprocess; subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy>=1.16.0\"])\n",
        "\n",
        "THETA_GATE_DEG = 20.0\n",
        "MIN_MARGIN = 0.05\n",
        "ALPHA_DENS = 1.0\n",
        "ALPHA_KAPPA = 1.0\n",
        "SMOOTH_FWHM_DEG = 0.0\n",
        "LMAX = None\n",
        "USE_MASK_FOR_GZ1 = False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# ---------- Patched gradient ----------\n",
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (‚àÇ/‚àÇŒ∏, ‚àÇ/‚àÇœÜ) of a scalar HEALPix map.\n",
        "    Try harmonic route, else robust numeric fallback via interpolation.\n",
        "    \"\"\"\n",
        "    # Harmonic (preferred)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Numeric fallback\n",
        "    pix = np.arange(12*(nside**2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus)/(2*eps)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus)/(2*eps)\n",
        "    return np.array(dth), np.array(dph)\n",
        "\n",
        "# ---------- Discovery ----------\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "def discover_map(kind):\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "def discover_overlay_candidates():\n",
        "    dens = autodiscover([\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*scalar_density*.npy\",\"*density*.npz\"])\n",
        "    kappa = autodiscover([\"*kappa*.npy\",\"*convergence*.npy\",\"*mech2*.npy\",\"*kappa*.npz\"])\n",
        "    return (dens[0] if dens else None), (kappa[0] if kappa else None)\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "def discover_jwst():\n",
        "    c = autodiscover([\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*.xlsx\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\"])\n",
        "    return c[0] if c else None\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def infer_nside(vec):\n",
        "    n=int(vec.size); ns=int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2)!=n: raise ValueError(f\"Length {n} != 12*nside^2\")\n",
        "    return ns\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num=pd.to_numeric(ra_s, errors=\"coerce\"); dec_num=pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc=SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle,u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw=next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")),None)\n",
        "    p_acw=next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")),None)\n",
        "    if p_cw and p_acw:\n",
        "        pc=pd.to_numeric(df[p_cw],errors=\"coerce\").astype(float)\n",
        "        pa=pd.to_numeric(df[p_acw],errors=\"coerce\").astype(float)\n",
        "        keep=(pc-pa).abs()>=min_margin\n",
        "        spin=np.where(pc>pa,1,-1).astype(int)\n",
        "        return pd.Series(spin,index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            v=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(v.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(v.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s=np.sin(thetas).copy(); s[s==0]=1.0\n",
        "    return dph/s\n",
        "def smooth_if_needed(mapvec, fwhm_deg):\n",
        "    if not fwhm_deg or fwhm_deg<=0: return mapvec\n",
        "    return hp.sphtfunc.smoothing(mapvec, fwhm=math.radians(fwhm_deg), verbose=False)\n",
        "def fit_linear_M(Lx,Ly,Ox,Oy):\n",
        "    A1=np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2=np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A=np.vstack([A1,A2]); b=np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A+lam*np.eye(4); ATb=A.T@b\n",
        "    m=np.linalg.solve(ATA,ATb); return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "def optionA_stats(spins, dph_metric, dth, thetas, gate_deg, sky_ok=None):\n",
        "    pred = -np.where(dph_metric>=0,1,-1)\n",
        "    alpha=np.arctan2(dth,dph_metric)\n",
        "    gate=np.abs(alpha)<=np.deg2rad(gate_deg)\n",
        "    valid=gate & np.isfinite(dph_metric) & np.isfinite(dth)\n",
        "    if sky_ok is not None: valid&=sky_ok\n",
        "    N=int(valid.sum())\n",
        "    if N==0: return dict(N=0, frac=np.nan, ci_lo=np.nan, ci_hi=np.nan, valid=valid, pred=pred)\n",
        "    k=int((spins[valid].astype(int)==pred[valid].astype(int)).sum())\n",
        "    frac=k/N; se=(frac*(1-frac)/N)**0.5; lo=max(0.0,frac-1.96*se); hi=min(1.0,frac+1.96*se)\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=lo,ci_hi=hi,valid=valid,pred=pred)\n",
        "\n",
        "def load_scalar_map_any(path, target_nside=None, name_hint=\"\"):\n",
        "    if path is None or not os.path.exists(path): return None\n",
        "    arr=np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr=arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr,np.ndarray) and arr.dtype==object:\n",
        "        try:\n",
        "            obj=arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj,dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr=np.asarray(obj[k]); break\n",
        "                else: arr=np.asarray(next(iter(obj.values())))\n",
        "            else: arr=np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr=np.asarray(arr)\n",
        "    arr=np.asarray(arr,dtype=float).ravel()\n",
        "    src_nside=infer_nside(arr)\n",
        "    if target_nside is not None and src_nside!=target_nside:\n",
        "        arr=hp.ud_grade(arr, target_nside, power=0)\n",
        "    return arr\n",
        "\n",
        "# ---------- Load inputs ----------\n",
        "dtheta_path=discover_map(\"dtheta\")\n",
        "dphi_path  =discover_map(\"dphi\")\n",
        "gz1_path   =discover_gz1()\n",
        "jwst_path  =discover_jwst()\n",
        "mask_path  =discover_mask()\n",
        "dens_path,kappa_path=discover_overlay_candidates()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  jwst  :\", jwst_path or \"(not found; all-sky calibration)\")\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "print(\"  density overlay:\", dens_path or \"(none)\")\n",
        "print(\"  kappa overlay  :\", kappa_path or \"(none)\")\n",
        "\n",
        "dtheta_map=np.load(dtheta_path)\n",
        "dphi_map  =np.load(dphi_path)\n",
        "nside=infer_nside(dtheta_map); assert infer_nside(dphi_map)==nside\n",
        "\n",
        "dens_map=load_scalar_map_any(dens_path,  target_nside=nside, name_hint=\"density\")\n",
        "kmap    =load_scalar_map_any(kappa_path, target_nside=nside, name_hint=\"kappa\")\n",
        "\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data=hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec=np.array(data).astype(float).ravel()\n",
        "        ns_mask=infer_nside(vec)\n",
        "        mask_vec=vec if ns_mask==nside else hp.ud_grade(vec, nside, power=0)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e); mask_vec=None\n",
        "\n",
        "# ---------- Mechanism-2 composite & gradient ----------\n",
        "mech2_comp=None\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    parts=[]\n",
        "    if dens_map is not None:\n",
        "        dm=(dens_map-np.nanmean(dens_map))/(np.nanstd(dens_map)+1e-12); parts.append(ALPHA_DENS*dm)\n",
        "    if kmap is not None:\n",
        "        km=(kmap-np.nanmean(kmap))/(np.nanstd(kmap)+1e-12); parts.append(ALPHA_KAPPA*km)\n",
        "    mech2_comp=np.sum(parts,axis=0); mech2_comp=smooth_if_needed(mech2_comp, SMOOTH_FWHM_DEG)\n",
        "    dth_M2, dph_M2 = gradient_from_scalar(mech2_comp, nside, lmax=LMAX)\n",
        "else:\n",
        "    dth_M2, dph_M2 = None, None\n",
        "\n",
        "# ---------- Calibration set ----------\n",
        "cal_pix=None\n",
        "if jwst_path and os.path.exists(jwst_path):\n",
        "    try:\n",
        "        jw=pd.read_excel(jwst_path)\n",
        "        ra_j,dec_j=detect_ra_dec_columns(jw)\n",
        "        ra_deg_j,dec_deg_j=parse_ra_dec_mixed(jw[ra_j],jw[dec_j])\n",
        "        th_j=(np.pi/2.0)-np.deg2rad(dec_deg_j); ph_j=np.deg2rad(ra_deg_j)%(2*np.pi)\n",
        "        cal_pix=hp.ang2pix(nside, th_j, ph_j, nest=True)\n",
        "        zcol=next((c for c in jw.columns if c.lower() in (\"z\",\"redshift\",\"photoz\",\"z_phot\",\"z_spec\")),None)\n",
        "        if zcol is not None:\n",
        "            z=pd.to_numeric(jw[zcol],errors=\"coerce\")\n",
        "            if np.isfinite(z).any():\n",
        "                highz = z >= np.nanmedian(z)\n",
        "                if len(highz)==len(cal_pix): cal_pix=cal_pix[highz.values]\n",
        "    except Exception as e:\n",
        "        print(\"JWST calibration fallback (all-sky):\", e); cal_pix=None\n",
        "if cal_pix is None: cal_pix=np.arange(12*(nside**2))\n",
        "\n",
        "# ---------- Logosfield gradients with corrections ----------\n",
        "pix_all=np.arange(12*(nside**2))\n",
        "th_all, ph_all = hp.pix2ang(nside, pix_all, nest=True)\n",
        "dthL_all = dphi_map[pix_all].astype(float)   # swap\n",
        "dphL_all = dtheta_map[pix_all].astype(float) # swap\n",
        "\n",
        "M=np.eye(2); cal_report={}\n",
        "if (dth_M2 is not None) and (dph_M2 is not None):\n",
        "    sel=np.unique(cal_pix)\n",
        "    ok=np.isfinite(dthL_all[sel])&np.isfinite(dphL_all[sel])&np.isfinite(dth_M2[sel])&np.isfinite(dph_M2[sel])\n",
        "    idx=sel[ok]\n",
        "    if idx.size>=100:\n",
        "        M=fit_linear_M(dthL_all[idx], dphL_all[idx], dth_M2[idx], dph_M2[idx])\n",
        "        predx=M[0,0]*dthL_all[idx]+M[0,1]*dphL_all[idx]\n",
        "        predy=M[1,0]*dthL_all[idx]+M[1,1]*dphL_all[idx]\n",
        "        cal_report={\"num_cal_pix\":int(idx.size),\n",
        "                    \"M\":M.tolist(),\n",
        "                    \"corr_x\":float(np.corrcoef(predx,dth_M2[idx])[0,1]),\n",
        "                    \"corr_y\":float(np.corrcoef(predy,dph_M2[idx])[0,1])}\n",
        "    else:\n",
        "        print(\"Not enough calibration pixels; using identity M.\")\n",
        "\n",
        "dthL_adj_all = M[0,0]*dthL_all + M[0,1]*dphL_all\n",
        "dphL_adj_all = M[1,0]*dthL_all + M[1,1]*dphL_all\n",
        "\n",
        "# ---------- Galaxy Zoo Option-A ----------\n",
        "try:\n",
        "    gz1=pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1=pd.read_csv(gz1_path)\n",
        "ra_col,dec_col=detect_ra_dec_columns(gz1)\n",
        "spins,keep=extract_spin_gz1(gz1, MIN_MARGIN)\n",
        "gz1=gz1.loc[keep].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg,dec_deg=parse_ra_dec_mixed(gz1[ra_col],gz1[dec_col])\n",
        "ok=np.isfinite(ra_deg)&np.isfinite(dec_deg)\n",
        "gz1=gz1.loc[ok].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg=ra_deg[ok]; dec_deg=dec_deg[ok]\n",
        "\n",
        "thetas=(np.pi/2.0)-np.deg2rad(dec_deg); phis=np.deg2rad(ra_deg)%(2*np.pi)\n",
        "pix_gz=hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "dth_gz=dthL_adj_all[pix_gz]\n",
        "dph_gz=dphL_adj_all[pix_gz]\n",
        "dph_metric=phi_metric_divsin(dph_gz, thetas)\n",
        "\n",
        "sky_ok=np.ones_like(dph_gz, bool)\n",
        "if USE_MASK_FOR_GZ1 and ('mask_vec' in locals()) and (mask_vec is not None):\n",
        "    sky_ok = (mask_vec[pix_gz] > 0)\n",
        "\n",
        "stats=optionA_stats(spins.values, dph_metric, dth_gz, thetas, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "\n",
        "# ---------- Save & download ----------\n",
        "stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir=f\"/mnt/data/Step3_AllInOne_GZ1_v2_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "summary={\n",
        "    \"nside\":int(nside),\n",
        "    \"theta_gate_deg\":THETA_GATE_DEG,\n",
        "    \"min_margin\":MIN_MARGIN,\n",
        "    \"use_mask\":bool(USE_MASK_FOR_GZ1),\n",
        "    \"inputs\":{\"dtheta\":dtheta_path,\"dphi\":dphi_path,\"gz1\":gz1_path,\"jwst_for_cal\":jwst_path,\n",
        "              \"density\":dens_path,\"kappa\":kappa_path,\"mask\":mask_path},\n",
        "    \"mechanism2\":{\"alpha_density\":ALPHA_DENS,\"alpha_kappa\":ALPHA_KAPPA,\n",
        "                  \"smooth_fwhm_deg\":SMOOTH_FWHM_DEG,\"lmax\":LMAX,\n",
        "                  \"available\": bool((dens_map is not None) or (kmap is not None))},\n",
        "    \"calibration\":cal_report,\n",
        "    \"transform_M\":M.tolist(),\n",
        "    \"optionA_result\":{k:(float(v) if isinstance(v,(int,float,np.floating)) else v)\n",
        "                      for k,v in stats.items() if k not in (\"valid\",\"pred\")},\n",
        "}\n",
        "with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(summary,f,indent=2)\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"valid\":stats[\"valid\"].astype(int),\n",
        "    \"spin_obs\":spins.values.astype(int),\n",
        "    \"pred_spin\":stats[\"pred\"].astype(int),\n",
        "    \"dtheta_reanchored\":dth_gz.astype(float),\n",
        "    \"dphi_metric_reanchored\":dph_metric.astype(float),\n",
        "}).to_csv(os.path.join(out_dir,\"gz1_objects_reanchored.csv\"), index=False)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A (Re-anchored by Mechanism-2)\")\n",
        "plt.axhline(0.5, ls=\"--\"); plt.bar([\"Observed\"], [stats[\"frac\"] if stats[\"N\"]>0 else 0.0])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45,0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir,\"plot_alignment_reanchored.png\"), dpi=160); plt.close()\n",
        "\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    if 'mech2_comp' in locals() and mech2_comp is not None:\n",
        "        np.save(os.path.join(out_dir,\"mech2_composite.npy\"), mech2_comp.astype(np.float32))\n",
        "\n",
        "zip_path=f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root,_,files in os.walk(out_dir):\n",
        "        for fn in files: zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), out_dir))\n",
        "\n",
        "print(\"DONE.\"); print(\"Results dir:\", out_dir); print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files; files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qjb4-uuqzzSr",
        "outputId": "147f9a9c-89ff-4be9-9962-677db422e43c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  jwst  : ./master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "  mask  : ./glimpse_mask.fits\n",
            "  density overlay: ./Logosfield_scalar_density_map.npy\n",
            "  kappa overlay  : (none)\n",
            "Not enough calibration pixels; using identity M.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-241384773.py:291: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_014834\n",
            "ZIP: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_014834.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b3b6254-100c-45ac-b6e0-8854aea42e78\", \"Step3_AllInOne_GZ1_v2_20250831_014834.zip\", 3652683)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}