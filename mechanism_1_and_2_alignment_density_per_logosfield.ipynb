{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vcV63DJchBbswsEpcUkNfzE5aSXQKXD8",
      "authorship_tag": "ABX9TyNc6+N0hTTkH2o7Cw9k65RA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earltreloar/logosfield-cddr-analysis/blob/main/mechanism_1_and_2_alignment_density_per_logosfield.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib, json, platform, numpy as np, pandas as pd, sys\n",
        "from datetime import datetime\n",
        "def sha256(path, block=1<<20):\n",
        "    h=hashlib.sha256()\n",
        "    with open(path,'rb') as f:\n",
        "        while True:\n",
        "            b=f.read(block)\n",
        "            if not b: break\n",
        "            h.update(b)\n",
        "    return h.hexdigest()\n",
        "\n",
        "RUN_META = {\n",
        "    \"timestamp_utc\": datetime.utcnow().isoformat()+\"Z\",\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"numpy\": np.__version__,\n",
        "    \"pandas\": pd.__version__,\n",
        "    # fill these with your actual filenames\n",
        "    \"files\": {\n",
        "        \"spins_csv\": \"spin3.csv\",\n",
        "        \"nodes_csv\": \"nodes.csv\"\n",
        "    }\n",
        "}\n",
        "for k,p in RUN_META[\"files\"].items():\n",
        "    try: RUN_META[\"files\"][k] = {\"path\": p, \"sha256\": sha256(p)}\n",
        "    except: RUN_META[\"files\"][k] = {\"path\": p, \"sha256\": None}\n",
        "\n",
        "print(json.dumps(RUN_META, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-BVD1tZFsLR",
        "outputId": "948f4f98-a7a6-479c-ea78-5ff44be9fb76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timestamp_utc\": \"2025-08-30T03:47:27.914674Z\",\n",
            "  \"python\": \"3.12.11\",\n",
            "  \"platform\": \"Linux-6.1.123+-x86_64-with-glibc2.35\",\n",
            "  \"numpy\": \"2.0.2\",\n",
            "  \"pandas\": \"2.2.2\",\n",
            "  \"files\": {\n",
            "    \"spins_csv\": {\n",
            "      \"path\": \"spin3.csv\",\n",
            "      \"sha256\": \"410d14cbdd2f83090a68191f0392faac77ebc21cc5dc3378051aa4b8b4db5974\"\n",
            "    },\n",
            "    \"nodes_csv\": {\n",
            "      \"path\": \"nodes.csv\",\n",
            "      \"sha256\": \"3e6f65c65cbc6a98f21aa0dea484709e3430fcb0ca3293a954e4931c41c02368\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1315706433.py:13: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp_utc\": datetime.utcnow().isoformat()+\"Z\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Mechanism 1 — Scalar–Spin Style (explicit upload prompts) =====\n",
        "# Needs: spins CSV (with x,y,z,sx,sy,sz), nodes CSV (ra,dec[,weight]); optional density*.csv\n",
        "import os, zipfile, numpy as np, pandas as pd\n",
        "from scipy.stats import binomtest\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def read_csv(path):\n",
        "    try:    return pd.read_csv(path)\n",
        "    except: return pd.read_csv(path, sep=None, engine=\"python\")\n",
        "\n",
        "def auto_unzip():\n",
        "    for f in list(os.listdir(\".\")):\n",
        "        if f.lower().endswith(\".zip\"):\n",
        "            with zipfile.ZipFile(f,\"r\") as zf:\n",
        "                zf.extractall(\".\")\n",
        "                print(f\"📦 Extracted {f} -> {zf.namelist()}\")\n",
        "\n",
        "def pick_file(keyword_list, exclude_keywords=(\"node\",\"dens\"), required=True, label=\"file\"):\n",
        "    def finder():\n",
        "        cands=[]\n",
        "        for f in os.listdir(\".\"):\n",
        "            if not f.lower().endswith(\".csv\"): continue\n",
        "            low=f.lower()\n",
        "            if any(ex in low for ex in exclude_keywords): continue\n",
        "            if any(k in low for k in keyword_list): cands.append(f)\n",
        "        return cands[0] if cands else None\n",
        "\n",
        "    f = finder()\n",
        "    while required and f is None and IN_COLAB:\n",
        "        print(f\"📤 Please upload the {label} (CSV or ZIP).\")\n",
        "        up = files.upload()\n",
        "        for n,b in up.items():\n",
        "            with open(n,\"wb\") as fh: fh.write(b)\n",
        "        auto_unzip()\n",
        "        f = finder()\n",
        "\n",
        "    if required and f is None:\n",
        "        raise FileNotFoundError(f\"Missing required {label}.\")\n",
        "    return f\n",
        "\n",
        "# 1) Initial generic upload (optional; you can skip and it will prompt later)\n",
        "if IN_COLAB:\n",
        "    print(\"📤 You can upload now (or wait for prompts): spins, nodes, optional density\")\n",
        "    up0 = files.upload()\n",
        "    for n,b in up0.items():\n",
        "        with open(n,\"wb\") as fh: fh.write(b)\n",
        "auto_unzip()\n",
        "\n",
        "# 2) Explicitly collect required files\n",
        "# spins: must contain x,y,z,sx,sy,sz\n",
        "sp_path    = pick_file([\"spin\",\"zoo\",\"hsc\",\"jwst\",\"ceers\",\"jades\",\"galaxy\",\"table2\"], label=\"SPINS file\")\n",
        "# nodes: must contain ra/dec (headers like ra/dec or RAJ2000/DEJ2000 etc.)\n",
        "nodes_path = None\n",
        "def find_nodes():\n",
        "    for f in os.listdir(\".\"):\n",
        "        if f.lower().endswith(\".csv\") and \"node\" in f.lower(): return f\n",
        "    return None\n",
        "nodes_path = find_nodes()\n",
        "while nodes_path is None and IN_COLAB:\n",
        "    print(\"📤 Please upload the NODES file (CSV or ZIP; headers ra/dec[,weight]).\")\n",
        "    up = files.upload()\n",
        "    for n,b in up.items():\n",
        "        with open(n,\"wb\") as fh: fh.write(b)\n",
        "    auto_unzip()\n",
        "    nodes_path = find_nodes()\n",
        "if nodes_path is None:\n",
        "    raise FileNotFoundError(\"Missing required nodes file (e.g., 'nodes.csv').\")\n",
        "\n",
        "# density (optional)\n",
        "dens_path = None\n",
        "for f in os.listdir(\".\"):\n",
        "    if f.lower().endswith(\".csv\") and \"dens\" in f.lower():\n",
        "        dens_path = f; break\n",
        "\n",
        "print(f\"🧾 Using spins:   {sp_path}\")\n",
        "print(f\"🧾 Using nodes:   {nodes_path}\")\n",
        "if dens_path: print(f\"🧾 Using density: {dens_path}\")\n",
        "\n",
        "# 3) Load and validate columns\n",
        "sp    = read_csv(sp_path)\n",
        "nodes = read_csv(nodes_path)\n",
        "\n",
        "# spins need x,y,z,sx,sy,sz (case-insensitive)\n",
        "need = {\"x\",\"y\",\"z\",\"sx\",\"sy\",\"sz\"}\n",
        "have = {c.lower(): c for c in sp.columns}\n",
        "missing = [c for c in need if c not in have]\n",
        "if missing:\n",
        "    raise ValueError(f\"Spins file must contain columns {sorted(list(need))} (found {list(sp.columns)}).\")\n",
        "\n",
        "v  = sp[[have[\"x\"], have[\"y\"], have[\"z\"]]].to_numpy(float)\n",
        "sv = sp[[have[\"sx\"], have[\"sy\"], have[\"sz\"]]].to_numpy(float)\n",
        "sv = sv / np.clip(np.linalg.norm(sv, axis=1, keepdims=True), 1e-12, None)\n",
        "\n",
        "# nodes need RA/Dec (accept aliases)\n",
        "def pick(df, cands):\n",
        "    for c in df.columns:\n",
        "        if c.lower() in cands: return c\n",
        "    return None\n",
        "ra_col  = pick(nodes, {\"ra\",\"ra_deg\",\"raj2000\",\"alpha\",\"alphaj2000\",\"radeg\"})\n",
        "dec_col = pick(nodes, {\"dec\",\"dec_deg\",\"dej2000\",\"delta\",\"deltaj2000\",\"decdeg\"})\n",
        "if ra_col is None or dec_col is None:\n",
        "    raise ValueError(f\"Nodes file must have RA/Dec columns. Found: {list(nodes.columns)}\")\n",
        "\n",
        "def radec_to_unit(ra_deg, dec_deg):\n",
        "    ra = np.radians(pd.to_numeric(ra_deg, errors=\"coerce\") % 360.0)\n",
        "    dec= np.radians(pd.to_numeric(dec_deg, errors=\"coerce\").clip(-90,90))\n",
        "    x = np.cos(dec)*np.cos(ra); y = np.cos(dec)*np.sin(ra); z = np.sin(dec)\n",
        "    return np.stack([x,y,z], axis=1)\n",
        "\n",
        "g_nodes = radec_to_unit(nodes[ra_col], nodes[dec_col])\n",
        "\n",
        "# 4) Local direction via nearest node (3D kNN on unit vectors)\n",
        "from sklearn.neighbors import KDTree\n",
        "tree = KDTree(g_nodes)\n",
        "idx  = tree.query(v, k=1)[1][:,0]\n",
        "g    = g_nodes[idx]\n",
        "\n",
        "# 5) Scalar–spin alignment\n",
        "obs_spin = np.sign(np.sum(sv * g, axis=1)).astype(int); obs_spin[obs_spin==0] = 1\n",
        "pred     = np.sign(np.sum(g * np.array([0,0,1.0]), axis=1)).astype(int); pred[pred==0] = 1\n",
        "\n",
        "aligned = (obs_spin == pred)\n",
        "N = aligned.size; k = int(aligned.sum()); frac = k/max(N,1)\n",
        "p = binomtest(k, N, 0.5, alternative=\"greater\").pvalue\n",
        "ci = binomtest(k, N, 0.5, alternative=\"greater\").proportion_ci(0.95)\n",
        "\n",
        "print(\"\\n✅ Scalar–spin result\")\n",
        "print(f\"  N={N}  aligned={frac:.4f}  p={p:.3g}  95% CI=[{ci.low:.4f},{ci.high:.4f}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "pCbUT4v2Exzm",
        "outputId": "cc77deea-6333-4c12-8f38-594f4063a35d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 You can upload now (or wait for prompts): spins, nodes, optional density\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edc9a3f9-4184-49a4-a99c-ebc7d4a3efa2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edc9a3f9-4184-49a4-a99c-ebc7d4a3efa2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nodes (3).csv to nodes (3) (5).csv\n",
            "Saving spin3.csv to spin3 (2).csv\n",
            "Saving density2.csv to density2 (5).csv\n",
            "📦 Extracted GalaxyZoo1_DR_table2.csv (1).zip -> ['GalaxyZoo1_DR_table2.csv']\n",
            "📦 Extracted GalaxyZoo1_DR_table2.csv.zip -> ['GalaxyZoo1_DR_table2.csv']\n",
            "🧾 Using spins:   spin3 (1).csv\n",
            "🧾 Using nodes:   nodes (3).csv\n",
            "🧾 Using density: density2 (2).csv\n",
            "\n",
            "✅ Scalar–spin result\n",
            "  N=500  aligned=0.4780  p=0.848  95% CI=[0.4404,1.0000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install healpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2K7_js5MgRu",
        "outputId": "1d4be6f7-076c-4e1b-917b-b04ae573f616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting healpy\n",
            "  Downloading healpy-1.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from healpy) (2.0.2)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (from healpy) (7.1.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (0.2025.8.25.0.36.58)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (6.0.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (25.0)\n",
            "Downloading healpy-1.18.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: healpy\n",
            "Successfully installed healpy-1.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "# Load all candidate CSVs in /content\n",
        "files = glob(\"/content/*.csv\") + glob(\"/content/*.csv.gz\") + glob(\"/content/*.xlsx\")\n",
        "\n",
        "print(\"📂 Checking all uploaded table files...\\n\")\n",
        "\n",
        "for f in files:\n",
        "    print(f\"\\n➡️  File: {f}\")\n",
        "    try:\n",
        "        df = pd.read_csv(f) if f.endswith('.csv') or f.endswith('.csv.gz') else pd.read_excel(f)\n",
        "        print(\"✅ Columns:\", list(df.columns))\n",
        "        missing = [col for col in ['ra', 'dec', 'spin'] if col not in df.columns]\n",
        "        if missing:\n",
        "            print(\"❌ Missing columns:\", missing)\n",
        "        else:\n",
        "            print(\"✅ All required columns present.\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Failed to read:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1CVm6D6P4N6",
        "outputId": "a83cfdf8-70c3-42c3-aea7-1f50b9aac97b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Checking all uploaded table files...\n",
            "\n",
            "\n",
            "➡️  File: /content/data_hsc.csv\n",
            "✅ Columns: ['RA', 'Dec', 'z', 'direction_cw_ccw']\n",
            "❌ Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "➡️  File: /content/GalaxyZoo1_DR_table2.csv.gz\n",
            "✅ Columns: ['OBJID', 'RA', 'DEC', 'NVOTE', 'P_EL', 'P_CW', 'P_ACW', 'P_EDGE', 'P_DK', 'P_MG', 'P_CS', 'P_EL_DEBIASED', 'P_CS_DEBIASED', 'SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
            "❌ Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "➡️  File: /content/HSC_STANDARDIZED copy.xlsx\n",
            "✅ Columns: ['ra', 'dec', 'spin']\n",
            "✅ All required columns present.\n",
            "\n",
            "➡️  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "✅ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "✅ All required columns present.\n",
            "\n",
            "➡️  File: /content/shamir_jades_proxy_zge10.xlsx\n",
            "✅ Columns: ['object_id', 'spin', 'dataset', 'z']\n",
            "❌ Missing columns: ['ra', 'dec']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Upload prompt ---\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# --- Identify and load uploaded files ---\n",
        "galaxy_file = None\n",
        "logosfield_file = None\n",
        "\n",
        "for f in uploaded:\n",
        "    if f.endswith(('.csv', '.csv.gz', '.xlsx')) and galaxy_file is None:\n",
        "        galaxy_file = f\n",
        "    elif f.endswith('.npy') and logosfield_file is None:\n",
        "        logosfield_file = f\n",
        "\n",
        "if galaxy_file is None:\n",
        "    raise ValueError(\"❌ No galaxy file (.csv/.xlsx) found.\")\n",
        "if logosfield_file is None:\n",
        "    raise ValueError(\"❌ No Logosfield .npy map file found.\")\n",
        "\n",
        "# --- Load galaxy data ---\n",
        "try:\n",
        "    if galaxy_file.endswith('.xlsx'):\n",
        "        df = pd.read_excel(galaxy_file)\n",
        "    else:\n",
        "        df = pd.read_csv(galaxy_file)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Failed to read galaxy file: {e}\")\n",
        "\n",
        "# --- Check required columns ---\n",
        "required_cols = ['ra', 'dec', 'spin']\n",
        "missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"❌ Galaxy file missing columns: {missing_cols}\")\n",
        "else:\n",
        "    print(f\"✅ Loaded galaxy file: {galaxy_file}\")\n",
        "    print(f\"  Columns: {list(df.columns)}\")\n",
        "    print(f\"✅ All required columns present: {required_cols}\")\n",
        "\n",
        "# --- Load Logosfield map ---\n",
        "try:\n",
        "    logosfield_map = np.load(logosfield_file, allow_pickle=True)\n",
        "    print(f\"✅ Loaded Logosfield scalar map: {logosfield_file}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Failed to load Logosfield .npy file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "x1n6AfwmQ7di",
        "outputId": "b5feab64-42f0-42d5-8c76-3bda2114703a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c26976b9-e7b4-4381-bee7-1d5e2351a68a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c26976b9-e7b4-4381-bee7-1d5e2351a68a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx to master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (4).xlsx\n",
            "Saving HSC_STANDARDIZED copy.xlsx to HSC_STANDARDIZED copy (4).xlsx\n",
            "Saving glimpse_mask.fits to glimpse_mask.fits\n",
            "Saving Logosfield_scalar_density_map.npy to Logosfield_scalar_density_map (5).npy\n",
            "✅ Loaded galaxy file: master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (4).xlsx\n",
            "  Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "✅ All required columns present: ['ra', 'dec', 'spin']\n",
            "✅ Loaded Logosfield scalar map: Logosfield_scalar_density_map (5).npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    path = \"Logosfield_scalar_density_map.npy\"\n",
        "    data = np.load(path, allow_pickle=True)\n",
        "\n",
        "    print(f\"Loaded type: {type(data)}\")\n",
        "    if isinstance(data, np.ndarray):\n",
        "        print(f\"Array shape: {data.shape}\")\n",
        "        if data.ndim == 1:\n",
        "            print(\"✅ Valid 1D HEALPix map.\")\n",
        "        elif data.ndim == 0:\n",
        "            print(\"⚠️ Zero-dimensional array. Inspecting contents...\")\n",
        "            obj = data.item()\n",
        "            print(f\"Item type: {type(obj)}\")\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                print(f\"Recovered array shape: {obj.shape}\")\n",
        "                if obj.ndim == 1:\n",
        "                    print(\"✅ Extracted valid 1D HEALPix map. Re-saving...\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", obj)\n",
        "                else:\n",
        "                    print(\"❌ Extracted array is not 1D. Manual inspection needed.\")\n",
        "            else:\n",
        "                print(\"❌ Object inside .npy is not an ndarray.\")\n",
        "        else:\n",
        "            print(\"❌ Map is not 1D. Reshape or fix required.\")\n",
        "    else:\n",
        "        print(\"❌ File content is not a NumPy array.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Error loading .npy:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNBOKvm6bS8e",
        "outputId": "2a9c5322-6cc1-4611-8d81-d555da3575a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "⚠️ Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "❌ Object inside .npy is not an ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alm = hp.map2alm(smoothed_map)\n",
        "grad_maps = hp.alm2map_der1(alm, nside=nside)\n",
        "\n",
        "if grad_maps.shape[0] >= 2:\n",
        "    dtheta_map = grad_maps[0]\n",
        "    dphi_map = grad_maps[1]\n",
        "    print(\"✅ Gradient maps computed successfully.\")\n",
        "    np.save(\"Logosfield_dtheta_map.npy\", dtheta_map)\n",
        "    np.save(\"Logosfield_dphi_map.npy\", dphi_map)\n",
        "    print(\"💾 Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\")\n",
        "else:\n",
        "    raise ValueError(\"Unexpected gradient output shape:\", grad_maps.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGdydggleDLe",
        "outputId": "e0f44632-472b-4953-e241-bfd8962e6e23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gradient maps computed successfully.\n",
            "💾 Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace with uploaded file path\n",
        "map_filename = \"Logosfield_scalar_density_map.npy\"\n",
        "\n",
        "try:\n",
        "    # Load the object (dict inside zero-dimensional ndarray)\n",
        "    raw = np.load(map_filename, allow_pickle=True)\n",
        "    print(\"🔍 Loaded type:\", type(raw))\n",
        "    print(\"Array shape:\", raw.shape)\n",
        "\n",
        "    if raw.ndim == 0:\n",
        "        print(\"⚠️ Zero-dimensional array. Inspecting contents...\")\n",
        "        obj = raw.item()\n",
        "        print(\"Item type:\", type(obj))\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            # Attempt to extract the first array from dict\n",
        "            for key, val in obj.items():\n",
        "                if isinstance(val, np.ndarray) and val.ndim == 1:\n",
        "                    print(f\"✅ Extracted key '{key}' with shape {val.shape}\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", val)\n",
        "                    print(\"💾 Saved as Logosfield_scalar_density_map_FIXED.npy\")\n",
        "                    break\n",
        "            else:\n",
        "                print(\"❌ No 1D ndarray found inside the dictionary.\")\n",
        "        else:\n",
        "            print(\"❌ Top-level object is not a dictionary.\")\n",
        "    else:\n",
        "        print(\"❌ Unexpected array shape — manual inspection needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Error occurred:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU3qx-mybpK2",
        "outputId": "2df8b535-4e0c-414b-8d9e-4ffef3f9f378"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "⚠️ Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "✅ Extracted key 'map' with shape (196608,)\n",
            "💾 Saved as Logosfield_scalar_density_map_FIXED.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 · Option A (Galaxy Zoo only) — AUTO-DISCOVER + SEXAGESIMAL-SAFE ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"\n",
        "    Returns (ra_deg, dec_deg) handling degrees or sexagesimal strings like '00:00:00.74' / '+12:34:56.7'.\n",
        "    Uses astropy SkyCoord; falls back to numeric if already deg.\n",
        "    \"\"\"\n",
        "    # Quick path: try numeric\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed: build strings and parse via SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "\n",
        "    # Heuristic: if many have \":\" or \" \" treat as sexagesimal\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Otherwise, last try: assume degrees but with stray strings\n",
        "    if ra_num.isna().any() or dec_num.isna().any():\n",
        "        # Attempt flexible parse row-by-row with SkyCoord accepting deg strings\n",
        "        out_ra, out_dec = [], []\n",
        "        for r, d in zip(ra_series, dec_series):\n",
        "            try:\n",
        "                rnum = float(r); dnum = float(d)\n",
        "                out_ra.append(rnum); out_dec.append(dnum); continue\n",
        "            except Exception:\n",
        "                try:\n",
        "                    sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                    out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "                except Exception:\n",
        "                    out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "        return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "    return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta →\", dtheta_path)\n",
        "print(\"  dphi   →\", dphi_path)\n",
        "print(\"  gz1    →\", gz1_path)\n",
        "print(\"  mask   →\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo + sexagesimal-safe RA/Dec ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "# robust RA/Dec parsing (deg or HMS/DMS)\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "\n",
        "# drop rows that failed to parse\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "# Rotation nulls\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "# Shuffle nulls\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 · Option A — Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"θ-gate = ±{THETA_GATE_DEG}° ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg→frac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean±std = {summary['shuffle_null_mean']:.6f} ± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo — Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(out_dir):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5wgq_JHo7zC",
        "outputId": "cf678c53-1e51-42fd-88ea-946d7d7d247f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta → ./Logosfield_dtheta_map.npy\n",
            "  dphi   → /content/Logosfield_dphi_map.npy\n",
            "  gz1    → ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   → ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1678358610.py:266: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_010057\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_010057.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 · Option A (Galaxy Zoo only) — AUTO-DISCOVER + SEXAGESIMAL-SAFE + AUTO-DOWNLOAD ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    # Prefer names with 'galaxyzoo' / shorter names\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"Return (ra_deg, dec_deg) handling degrees or HMS/DMS strings.\"\"\"\n",
        "    # Quick numeric path\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed -> use SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Last fallback: attempt per-row deg strings\n",
        "    out_ra, out_dec = [], []\n",
        "    for r, d in zip(ra_series, dec_series):\n",
        "        try:\n",
        "            out_ra.append(float(r)); out_dec.append(float(d))\n",
        "        except Exception:\n",
        "            try:\n",
        "                sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "            except Exception:\n",
        "                out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "    return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta →\", dtheta_path)\n",
        "print(\"  dphi   →\", dphi_path)\n",
        "print(\"  gz1    →\", gz1_path)\n",
        "print(\"  mask   →\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo (sexagesimal-safe RA/Dec) ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute alignment + nulls ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 · Option A — Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"θ-gate = ±{THETA_GATE_DEG}° ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg→frac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean±std = {summary['shuffle_null_mean']:.6f} ± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo — Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --------- ZIP + auto-download ---------\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "write_zip(out_dir, zip_path)\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n",
        "\n",
        "# Trigger downloadable file in Colab (safe no-op elsewhere)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available in this environment:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "TjPvBb3KqlCR",
        "outputId": "40b0cd08-7fbc-40b4-e0d2-29b0afd0a7e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta → ./Logosfield_dtheta_map.npy\n",
            "  dphi   → /content/Logosfield_dphi_map.npy\n",
            "  gz1    → ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   → ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-237797779.py:251: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_010805\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_010805.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1e8ec719-dc4e-43d5-aeb5-8428dfd4e486\", \"Mechanism1_OptionA_GZ1_20250831_010805.zip\", 1621497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Option A calibration sweep — find the convention that matches validated results ===\n",
        "import os, sys, json, math, glob, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# ---- discover the same inputs as before ----\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    for patset in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c=autodiscover(patset)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---- deps ----\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"healpy\",\"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# ---- basic helpers ----\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(\"Map length doesn't match 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    ra_num  = pd.to_numeric(ra_series, errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    ra_str = ra_series.astype(str).str.strip()\n",
        "    dec_str= dec_series.astype(str).str.strip()\n",
        "    sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    # fallback labels\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def binom_stats(k,n):\n",
        "    frac=k/n if n else np.nan\n",
        "    se=(frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    return frac, max(0.0, frac-1.96*se) if n else np.nan, min(1.0, frac+1.96*se) if n else np.nan\n",
        "\n",
        "def apply_gate(dth,dph,gate_deg):\n",
        "    alpha=np.arctan2(dth,dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg)\n",
        "\n",
        "# ---- load data ----\n",
        "dtheta_path = discover_map(\"dtheta\"); dphi_path = discover_map(\"dphi\")\n",
        "gz1_path = discover_gz1(); mask_path = discover_mask()\n",
        "print(\"Using:\\n  dtheta:\", dtheta_path, \"\\n  dphi:  \", dphi_path, \"\\n  gz1:   \", gz1_path, \"\\n  mask:  \", mask_path or \"(none)\")\n",
        "\n",
        "dtheta_map = np.load(dtheta_path); dphi_map = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map)==nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# mask (optional)\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "\n",
        "# galaxy zoo\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep = extract_spin_gz1(gz1, min_margin=0.05)\n",
        "gz1 = gz1.loc[keep].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# precompute angles and two pix modes\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix_ring = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "pix_nest = hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "# ---- sweep space ----\n",
        "gate_list = [10,15,20]\n",
        "nest_opts = [False, True]\n",
        "swap_opts = [False, True]      # swap dtheta<->dphi\n",
        "flip_dth  = [0,1]              # 1 means multiply by -1\n",
        "flip_dph  = [0,1]\n",
        "phi_metric = [\"none\",\"times_sin\",\"div_sin\"]  # component tweak\n",
        "pred_sign = [\"+dphi\",\"-dphi\"]  # handedness flip\n",
        "use_mask  = [True, False]\n",
        "\n",
        "records=[]\n",
        "\n",
        "for gate in gate_list:\n",
        "    for nest in nest_opts:\n",
        "        pix = pix_nest if nest else pix_ring\n",
        "        raw_dth = dtheta_map[pix].astype(float)\n",
        "        raw_dph = dphi_map[pix].astype(float)\n",
        "\n",
        "        for swap in swap_opts:\n",
        "            dth = raw_dth.copy(); dph = raw_dph.copy()\n",
        "            if swap: dth, dph = dph, dth\n",
        "\n",
        "            for fth in flip_dth:\n",
        "                dth_s = -dth if fth else dth\n",
        "                for fph in flip_dph:\n",
        "                    dph_s = -dph if fph else dph\n",
        "\n",
        "                    # metric tweak\n",
        "                    for met in phi_metric:\n",
        "                        if met==\"times_sin\":\n",
        "                            dph_m = dph_s * np.sin(thetas)\n",
        "                        elif met==\"div_sin\":\n",
        "                            # avoid poles\n",
        "                            s = np.sin(thetas)\n",
        "                            s[s==0] = 1.0\n",
        "                            dph_m = dph_s / s\n",
        "                        else:\n",
        "                            dph_m = dph_s\n",
        "\n",
        "                        for ps in pred_sign:\n",
        "                            pred = np.where(dph_m>=0, 1, -1)\n",
        "                            if ps==\"-dphi\": pred = -pred\n",
        "\n",
        "                            for mflag in use_mask:\n",
        "                                gate_mask = apply_gate(dth_s, dph_m, gate)\n",
        "                                valid = gate_mask & np.isfinite(dph_m) & np.isfinite(dth_s)\n",
        "                                if mflag and (mask_vec is not None):\n",
        "                                    valid = valid & (mask_vec[(pix_nest if nest else pix_ring)] > 0)\n",
        "\n",
        "                                spins = spin_obs.values\n",
        "                                N = int(valid.sum())\n",
        "                                if N==0: continue\n",
        "                                aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "                                k = int(aligned.sum())\n",
        "                                frac, lo, hi = binom_stats(k,N)\n",
        "                                records.append(dict(\n",
        "                                    frac=frac, ci_lo=lo, ci_hi=hi, N=N, k=k,\n",
        "                                    gate=gate, nest=nest, swap=swap, flip_dtheta=fth, flip_dphi=fph,\n",
        "                                    phi_metric=met, pred_sign=ps, mask=mflag\n",
        "                                ))\n",
        "\n",
        "res = pd.DataFrame.from_records(records).sort_values([\"frac\",\"N\"], ascending=[False,False]).reset_index(drop=True)\n",
        "print(\"Top 10 configurations:\")\n",
        "display(res.head(10))\n",
        "\n",
        "# Save & auto-download\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_csv = f\"/mnt/data/OptionA_calibration_sweep_{stamp}.csv\"\n",
        "res.to_csv(out_csv, index=False)\n",
        "print(\"Saved sweep table:\", out_csv)\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(out_csv)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "DDcoaKzCr8sV",
        "outputId": "e42ceee4-6480-42ea-97c8-fd47c6376908"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy \n",
            "  dphi:   ./Logosfield_dphi_map.npy \n",
            "  gz1:    ./GalaxyZoo1_DR_table2.csv.gz \n",
            "  mask:   ./glimpse_mask.fits\n",
            "Top 10 configurations:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       frac     ci_lo     ci_hi     N     k  gate  nest  swap  flip_dtheta  \\\n",
              "0  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "1  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "2  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "3  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "4  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "5  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "6  0.557775  0.536548  0.579002  2103  1173    20  True  True            0   \n",
              "7  0.557775  0.536548  0.579002  2103  1173    20  True  True            1   \n",
              "8  0.556976  0.534509  0.579442  1878  1046    20  True  True            0   \n",
              "9  0.556976  0.534509  0.579442  1878  1046    20  True  True            1   \n",
              "\n",
              "   flip_dphi phi_metric pred_sign   mask  \n",
              "0          0       none     +dphi   True  \n",
              "1          0  times_sin     +dphi   True  \n",
              "2          0    div_sin     +dphi   True  \n",
              "3          0       none     +dphi   True  \n",
              "4          0  times_sin     +dphi   True  \n",
              "5          0    div_sin     +dphi   True  \n",
              "6          0    div_sin     -dphi  False  \n",
              "7          0    div_sin     -dphi  False  \n",
              "8          0       none     -dphi  False  \n",
              "9          0       none     -dphi  False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6f80137-1c04-4b4a-9079-e6f438449963\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frac</th>\n",
              "      <th>ci_lo</th>\n",
              "      <th>ci_hi</th>\n",
              "      <th>N</th>\n",
              "      <th>k</th>\n",
              "      <th>gate</th>\n",
              "      <th>nest</th>\n",
              "      <th>swap</th>\n",
              "      <th>flip_dtheta</th>\n",
              "      <th>flip_dphi</th>\n",
              "      <th>phi_metric</th>\n",
              "      <th>pred_sign</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6f80137-1c04-4b4a-9079-e6f438449963')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6f80137-1c04-4b4a-9079-e6f438449963 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6f80137-1c04-4b4a-9079-e6f438449963');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba7002b0-931d-4edc-8b51-2c4e8856a19e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba7002b0-931d-4edc-8b51-2c4e8856a19e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba7002b0-931d-4edc-8b51-2c4e8856a19e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Colab download not available:\\\", e)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007262090464927316,\n        \"min\": 0.556975505857295,\n        \"max\": 0.5714285714285714,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5714285714285714,\n          0.557774607703281,\n          0.556975505857295\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1707770370202692,\n        \"min\": 0.2048225158321042,\n        \"max\": 0.5365476554680403,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2048225158321042,\n          0.5365476554680403,\n          0.5345087588486707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18529015041402033,\n        \"min\": 0.5790015599385218,\n        \"max\": 0.9380346270250386,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9380346270250386,\n          0.5790015599385218,\n          0.5794422528659194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1027,\n        \"min\": 7,\n        \"max\": 2103,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          2103,\n          1878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 572,\n        \"min\": 4,\n        \"max\": 1173,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          1173,\n          1046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nest\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dtheta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_sign\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"-dphi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sweep table: /mnt/data/OptionA_calibration_sweep_20250831_011408.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12392127.py:201: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e3f679f-5038-4975-8d4c-dfa4e8aec6e2\", \"OptionA_calibration_sweep_20250831_011408.csv\", 46580)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mechanism 1 · Option A (Galaxy Zoo) — CORRECTED SETTINGS + optional mask, auto-download ===\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "# --- Config ---\n",
        "THETA_GATE_DEG = 20.0          # from sweep\n",
        "MIN_MARGIN = 0.05\n",
        "MAX_SHUFFLE_N = 200\n",
        "ROTATIONS_DEG = [0, 30, 60, 90]\n",
        "EVALUATE_BOTH_MASK_SETTINGS = True   # set False to run only USE_MASK below\n",
        "USE_MASK = False                     # used only if EVALUATE_BOTH_MASK_SETTINGS=False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --- Deps ---\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# --- Helpers ---\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p: (len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):   # 'dtheta' | 'dphi'\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()), None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num  = pd.to_numeric(ra_s,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc = SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def apply_theta_gate(dth, dph, gate_deg):\n",
        "    alpha = np.arctan2(dth, dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg), alpha\n",
        "\n",
        "def rotation_nulls(dth, dph, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dph*c - dth*s)\n",
        "        ys.append(dph*s + dth*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n):\n",
        "    frac = k/n if n else np.nan\n",
        "    se = (frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    lo = max(0.0, frac - 1.96*se) if n else np.nan\n",
        "    hi = min(1.0, frac + 1.96*se) if n else np.nan\n",
        "    return frac, lo, hi\n",
        "\n",
        "def summarize(spins, dph_metric, dth_swap, gate_deg, sky_ok=None):\n",
        "    # predict with handedness flip: -sign(dphi_metric)\n",
        "    pred = -np.where(dph_metric >= 0, 1, -1)\n",
        "    gate_mask, alpha = apply_theta_gate(dth_swap, dph_metric, gate_deg)\n",
        "    valid = gate_mask & np.isfinite(dph_metric) & np.isfinite(dth_swap)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0)\n",
        "    aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "    k = int(aligned.sum())\n",
        "    frac, lo, hi = binom_stats(k, N)\n",
        "    return dict(N=N, k=k, frac=frac, ci_lo=lo, ci_hi=hi, pred=pred, valid=valid, alpha=alpha)\n",
        "\n",
        "def write_bundle(tag, valid, spins, pred, dph_m, dth_s, out_dir):\n",
        "    import matplotlib.pyplot as plt\n",
        "    # per-object CSV\n",
        "    df = pd.DataFrame({\n",
        "        \"valid\": valid.astype(int),\n",
        "        \"spin_obs\": spins.astype(int),\n",
        "        \"pred_spin\": pred.astype(int),\n",
        "        \"dphi_metric\": dph_m.astype(float),\n",
        "        \"dtheta_swapped\": dth_s.astype(float),\n",
        "    })\n",
        "    df.to_csv(os.path.join(out_dir, f\"gz1_objects_{tag}.csv\"), index=False)\n",
        "    # simple plot\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.title(f\"Galaxy Zoo — Option A ({tag})\")\n",
        "    plt.axhline(0.5, ls=\"--\")\n",
        "    plt.bar([\"Observed\"], [ (df.loc[valid, \"spin_obs\"] == df.loc[valid, \"pred_spin\"]).mean() ])\n",
        "    plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(out_dir, f\"plot_{tag}.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --- Discover inputs ---\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "\n",
        "# --- Load maps ---\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map) == nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# --- Load mask (optional) ---\n",
        "mask_vec = None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "        mask_vec = None\n",
        "\n",
        "# --- Load Galaxy Zoo ---\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spins, keep = extract_spin_gz1(gz1, min_margin=MIN_MARGIN)\n",
        "gz1 = gz1.loc[keep].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# --- Geometry & pix (corrected: NEST=True) ---\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=True)  # <— NEST=True per sweep\n",
        "\n",
        "# --- Swap components and apply phi metric (div_sin) ---\n",
        "# swap=True ⇒ use map’s dphi as our dtheta, and map’s dtheta as our dphi\n",
        "dth_swap = dphi_map[pix].astype(float)\n",
        "dph_swap = dtheta_map[pix].astype(float)\n",
        "s = np.sin(thetas); s[s==0] = 1.0\n",
        "dph_metric = dph_swap / s     # <— div_sin\n",
        "sky_ok_vec = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dph_metric, dtype=bool)\n",
        "\n",
        "# --- Run (optionally both with/without mask) ---\n",
        "variants = [(\"unmasked\", False)]\n",
        "if EVALUATE_BOTH_MASK_SETTINGS:\n",
        "    variants = [(\"unmasked\", False), (\"masked\", True)]\n",
        "else:\n",
        "    variants = [(\"masked\" if USE_MASK else \"unmasked\", USE_MASK)]\n",
        "\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "base = f\"/mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_{stamp}\"\n",
        "os.makedirs(base, exist_ok=True)\n",
        "\n",
        "summaries = []\n",
        "for tag, use_mask in variants:\n",
        "    sky_ok = sky_ok_vec if use_mask else np.ones_like(sky_ok_vec, dtype=bool)\n",
        "    res = summarize(spins.values, dph_metric, dth_swap, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "    if res[\"N\"] == 0:\n",
        "        print(f\"{tag}: no valid samples\"); continue\n",
        "\n",
        "    # rotation nulls\n",
        "    valid = res[\"valid\"]\n",
        "    rot_xs, rot_ys = rotation_nulls(dth_swap[valid], dph_metric[valid], ROTATIONS_DEG)\n",
        "    rot_fracs=[]\n",
        "    for y_rot in rot_ys:\n",
        "        pred_rot = -np.where(y_rot>=0, 1, -1)  # keep handedness flip\n",
        "        rot_fracs.append((spins.values[valid].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "    # shuffles\n",
        "    N_valid = int(valid.sum())\n",
        "    if N_valid > 250_000:\n",
        "        idx = np.random.choice(np.where(valid)[0], size=250_000, replace=False)\n",
        "        from_idx = spins.values[idx]; dph_idx = dph_metric[idx]; dth_idx = dth_swap[idx]\n",
        "        # simple shuffle null\n",
        "        fracs=[]\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(from_idx)\n",
        "            fracs.append((from_idx == -np.where(dph_idx>=0, 1, -1)).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "    else:\n",
        "        fracs=[]\n",
        "        arr = spins.values[valid].astype(int).copy()\n",
        "        pred = -np.where(dph_metric[valid]>=0, 1, -1).astype(int)\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(arr)\n",
        "            fracs.append((arr==pred).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "\n",
        "    out_dir = os.path.join(base, tag); os.makedirs(out_dir, exist_ok=True)\n",
        "    write_bundle(tag, valid, spins.values, res[\"pred\"], dph_metric, dth_swap, out_dir)\n",
        "\n",
        "    summary = dict(\n",
        "        variant=tag,\n",
        "        nside=int(nside),\n",
        "        gate_deg=float(THETA_GATE_DEG),\n",
        "        use_mask=bool(use_mask),\n",
        "        N=int(res[\"N\"]), k=int(res[\"k\"]),\n",
        "        frac=float(res[\"frac\"]), ci_lo=float(res[\"ci_lo\"]), ci_hi=float(res[\"ci_hi\"]),\n",
        "        rotation_nulls=dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "        shuffle_null_mean=shuffle_mean, shuffle_null_std=shuffle_std,\n",
        "        maps={\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "        gz1_path=gz1_path,\n",
        "        corrections={\"nest\": True, \"swap_components\": True, \"phi_metric\": \"div_sin\", \"pred_sign\": \"-dphi\"}\n",
        "    )\n",
        "    summaries.append(summary)\n",
        "    with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "        f.write(\n",
        "            f\"Variant: {tag}\\n\"\n",
        "            f\"N (valid) = {summary['N']}\\n\"\n",
        "            f\"Alignment fraction = {summary['frac']:.6f}  (95% CI [{summary['ci_lo']:.6f}, {summary['ci_hi']:.6f}])\\n\"\n",
        "            f\"Rotation nulls: {summary['rotation_nulls']}\\n\"\n",
        "            f\"Shuffle mean±std = {shuffle_mean:.6f} ± {shuffle_std:.6f}\\n\"\n",
        "        )\n",
        "\n",
        "# write top-level summary\n",
        "with open(os.path.join(base, \"run_summaries.json\"), \"w\") as f:\n",
        "    json.dump(summaries, f, indent=2)\n",
        "\n",
        "# zip & download\n",
        "zip_path = f\"{base}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(base):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, base))\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"Results dir:\", base)\n",
        "print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "9jU10ltbuGib",
        "outputId": "f411e099-1de4-4f0f-9b3f-3577089dc2ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask  : ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-403693560.py:210: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328\n",
            "ZIP: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4304f3c-c4b1-443f-b27b-5e2ef026b624\", \"Mechanism1_OptionA_GZ1_CORRECTED_20250831_012328.zip\", 7827285)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (d/dθ, d/dφ) of a scalar HEALPix map.\n",
        "    Tries sphtfunc.{alm2map_der, alm2map_der1}; falls back to a safe\n",
        "    numeric interpolation if neither is available.\n",
        "    \"\"\"\n",
        "    # 1) Harmonic path (preferred: exact & fast)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass  # fall through to numeric\n",
        "\n",
        "    # 2) Numeric fallback via spherical interpolation (slower, but robust)\n",
        "    pix = np.arange(12 * (nside ** 2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)  # mapvec is a plain HEALPix vector\n",
        "    eps = 1e-3  # ~0.057°; small enough for local derivative\n",
        "\n",
        "    # central differences in θ\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus) / (2.0 * eps)\n",
        "\n",
        "    # central differences in φ (wrap handled by get_interp_val)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus) / (2.0 * eps)\n",
        "\n",
        "    return np.array(dth), np.array(dph)\n"
      ],
      "metadata": {
        "id": "rbmtc1uey1Sw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === All-in-one (v2): Mechanism-2 re-anchoring + Option-A (Galaxy Zoo) ===\n",
        "# Patched: robust gradient_from_scalar (der → der1 → numeric fallback)\n",
        "\n",
        "import os, sys, glob, json, math, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: uncomment to ensure harmonic derivative is available\n",
        "# import sys, subprocess; subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy>=1.16.0\"])\n",
        "\n",
        "THETA_GATE_DEG = 20.0\n",
        "MIN_MARGIN = 0.05\n",
        "ALPHA_DENS = 1.0\n",
        "ALPHA_KAPPA = 1.0\n",
        "SMOOTH_FWHM_DEG = 0.0\n",
        "LMAX = None\n",
        "USE_MASK_FOR_GZ1 = False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# ---------- Patched gradient ----------\n",
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (∂/∂θ, ∂/∂φ) of a scalar HEALPix map.\n",
        "    Try harmonic route, else robust numeric fallback via interpolation.\n",
        "    \"\"\"\n",
        "    # Harmonic (preferred)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Numeric fallback\n",
        "    pix = np.arange(12*(nside**2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus)/(2*eps)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus)/(2*eps)\n",
        "    return np.array(dth), np.array(dph)\n",
        "\n",
        "# ---------- Discovery ----------\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "def discover_map(kind):\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "def discover_overlay_candidates():\n",
        "    dens = autodiscover([\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*scalar_density*.npy\",\"*density*.npz\"])\n",
        "    kappa = autodiscover([\"*kappa*.npy\",\"*convergence*.npy\",\"*mech2*.npy\",\"*kappa*.npz\"])\n",
        "    return (dens[0] if dens else None), (kappa[0] if kappa else None)\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "def discover_jwst():\n",
        "    c = autodiscover([\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*.xlsx\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\"])\n",
        "    return c[0] if c else None\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def infer_nside(vec):\n",
        "    n=int(vec.size); ns=int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2)!=n: raise ValueError(f\"Length {n} != 12*nside^2\")\n",
        "    return ns\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num=pd.to_numeric(ra_s, errors=\"coerce\"); dec_num=pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc=SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle,u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw=next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")),None)\n",
        "    p_acw=next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")),None)\n",
        "    if p_cw and p_acw:\n",
        "        pc=pd.to_numeric(df[p_cw],errors=\"coerce\").astype(float)\n",
        "        pa=pd.to_numeric(df[p_acw],errors=\"coerce\").astype(float)\n",
        "        keep=(pc-pa).abs()>=min_margin\n",
        "        spin=np.where(pc>pa,1,-1).astype(int)\n",
        "        return pd.Series(spin,index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            v=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(v.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(v.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s=np.sin(thetas).copy(); s[s==0]=1.0\n",
        "    return dph/s\n",
        "def smooth_if_needed(mapvec, fwhm_deg):\n",
        "    if not fwhm_deg or fwhm_deg<=0: return mapvec\n",
        "    return hp.sphtfunc.smoothing(mapvec, fwhm=math.radians(fwhm_deg), verbose=False)\n",
        "def fit_linear_M(Lx,Ly,Ox,Oy):\n",
        "    A1=np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2=np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A=np.vstack([A1,A2]); b=np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A+lam*np.eye(4); ATb=A.T@b\n",
        "    m=np.linalg.solve(ATA,ATb); return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "def optionA_stats(spins, dph_metric, dth, thetas, gate_deg, sky_ok=None):\n",
        "    pred = -np.where(dph_metric>=0,1,-1)\n",
        "    alpha=np.arctan2(dth,dph_metric)\n",
        "    gate=np.abs(alpha)<=np.deg2rad(gate_deg)\n",
        "    valid=gate & np.isfinite(dph_metric) & np.isfinite(dth)\n",
        "    if sky_ok is not None: valid&=sky_ok\n",
        "    N=int(valid.sum())\n",
        "    if N==0: return dict(N=0, frac=np.nan, ci_lo=np.nan, ci_hi=np.nan, valid=valid, pred=pred)\n",
        "    k=int((spins[valid].astype(int)==pred[valid].astype(int)).sum())\n",
        "    frac=k/N; se=(frac*(1-frac)/N)**0.5; lo=max(0.0,frac-1.96*se); hi=min(1.0,frac+1.96*se)\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=lo,ci_hi=hi,valid=valid,pred=pred)\n",
        "\n",
        "def load_scalar_map_any(path, target_nside=None, name_hint=\"\"):\n",
        "    if path is None or not os.path.exists(path): return None\n",
        "    arr=np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr=arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr,np.ndarray) and arr.dtype==object:\n",
        "        try:\n",
        "            obj=arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj,dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr=np.asarray(obj[k]); break\n",
        "                else: arr=np.asarray(next(iter(obj.values())))\n",
        "            else: arr=np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr=np.asarray(arr)\n",
        "    arr=np.asarray(arr,dtype=float).ravel()\n",
        "    src_nside=infer_nside(arr)\n",
        "    if target_nside is not None and src_nside!=target_nside:\n",
        "        arr=hp.ud_grade(arr, target_nside, power=0)\n",
        "    return arr\n",
        "\n",
        "# ---------- Load inputs ----------\n",
        "dtheta_path=discover_map(\"dtheta\")\n",
        "dphi_path  =discover_map(\"dphi\")\n",
        "gz1_path   =discover_gz1()\n",
        "jwst_path  =discover_jwst()\n",
        "mask_path  =discover_mask()\n",
        "dens_path,kappa_path=discover_overlay_candidates()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  jwst  :\", jwst_path or \"(not found; all-sky calibration)\")\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "print(\"  density overlay:\", dens_path or \"(none)\")\n",
        "print(\"  kappa overlay  :\", kappa_path or \"(none)\")\n",
        "\n",
        "dtheta_map=np.load(dtheta_path)\n",
        "dphi_map  =np.load(dphi_path)\n",
        "nside=infer_nside(dtheta_map); assert infer_nside(dphi_map)==nside\n",
        "\n",
        "dens_map=load_scalar_map_any(dens_path,  target_nside=nside, name_hint=\"density\")\n",
        "kmap    =load_scalar_map_any(kappa_path, target_nside=nside, name_hint=\"kappa\")\n",
        "\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data=hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec=np.array(data).astype(float).ravel()\n",
        "        ns_mask=infer_nside(vec)\n",
        "        mask_vec=vec if ns_mask==nside else hp.ud_grade(vec, nside, power=0)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e); mask_vec=None\n",
        "\n",
        "# ---------- Mechanism-2 composite & gradient ----------\n",
        "mech2_comp=None\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    parts=[]\n",
        "    if dens_map is not None:\n",
        "        dm=(dens_map-np.nanmean(dens_map))/(np.nanstd(dens_map)+1e-12); parts.append(ALPHA_DENS*dm)\n",
        "    if kmap is not None:\n",
        "        km=(kmap-np.nanmean(kmap))/(np.nanstd(kmap)+1e-12); parts.append(ALPHA_KAPPA*km)\n",
        "    mech2_comp=np.sum(parts,axis=0); mech2_comp=smooth_if_needed(mech2_comp, SMOOTH_FWHM_DEG)\n",
        "    dth_M2, dph_M2 = gradient_from_scalar(mech2_comp, nside, lmax=LMAX)\n",
        "else:\n",
        "    dth_M2, dph_M2 = None, None\n",
        "\n",
        "# ---------- Calibration set ----------\n",
        "cal_pix=None\n",
        "if jwst_path and os.path.exists(jwst_path):\n",
        "    try:\n",
        "        jw=pd.read_excel(jwst_path)\n",
        "        ra_j,dec_j=detect_ra_dec_columns(jw)\n",
        "        ra_deg_j,dec_deg_j=parse_ra_dec_mixed(jw[ra_j],jw[dec_j])\n",
        "        th_j=(np.pi/2.0)-np.deg2rad(dec_deg_j); ph_j=np.deg2rad(ra_deg_j)%(2*np.pi)\n",
        "        cal_pix=hp.ang2pix(nside, th_j, ph_j, nest=True)\n",
        "        zcol=next((c for c in jw.columns if c.lower() in (\"z\",\"redshift\",\"photoz\",\"z_phot\",\"z_spec\")),None)\n",
        "        if zcol is not None:\n",
        "            z=pd.to_numeric(jw[zcol],errors=\"coerce\")\n",
        "            if np.isfinite(z).any():\n",
        "                highz = z >= np.nanmedian(z)\n",
        "                if len(highz)==len(cal_pix): cal_pix=cal_pix[highz.values]\n",
        "    except Exception as e:\n",
        "        print(\"JWST calibration fallback (all-sky):\", e); cal_pix=None\n",
        "if cal_pix is None: cal_pix=np.arange(12*(nside**2))\n",
        "\n",
        "# ---------- Logosfield gradients with corrections ----------\n",
        "pix_all=np.arange(12*(nside**2))\n",
        "th_all, ph_all = hp.pix2ang(nside, pix_all, nest=True)\n",
        "dthL_all = dphi_map[pix_all].astype(float)   # swap\n",
        "dphL_all = dtheta_map[pix_all].astype(float) # swap\n",
        "\n",
        "M=np.eye(2); cal_report={}\n",
        "if (dth_M2 is not None) and (dph_M2 is not None):\n",
        "    sel=np.unique(cal_pix)\n",
        "    ok=np.isfinite(dthL_all[sel])&np.isfinite(dphL_all[sel])&np.isfinite(dth_M2[sel])&np.isfinite(dph_M2[sel])\n",
        "    idx=sel[ok]\n",
        "    if idx.size>=100:\n",
        "        M=fit_linear_M(dthL_all[idx], dphL_all[idx], dth_M2[idx], dph_M2[idx])\n",
        "        predx=M[0,0]*dthL_all[idx]+M[0,1]*dphL_all[idx]\n",
        "        predy=M[1,0]*dthL_all[idx]+M[1,1]*dphL_all[idx]\n",
        "        cal_report={\"num_cal_pix\":int(idx.size),\n",
        "                    \"M\":M.tolist(),\n",
        "                    \"corr_x\":float(np.corrcoef(predx,dth_M2[idx])[0,1]),\n",
        "                    \"corr_y\":float(np.corrcoef(predy,dph_M2[idx])[0,1])}\n",
        "    else:\n",
        "        print(\"Not enough calibration pixels; using identity M.\")\n",
        "\n",
        "dthL_adj_all = M[0,0]*dthL_all + M[0,1]*dphL_all\n",
        "dphL_adj_all = M[1,0]*dthL_all + M[1,1]*dphL_all\n",
        "\n",
        "# ---------- Galaxy Zoo Option-A ----------\n",
        "try:\n",
        "    gz1=pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1=pd.read_csv(gz1_path)\n",
        "ra_col,dec_col=detect_ra_dec_columns(gz1)\n",
        "spins,keep=extract_spin_gz1(gz1, MIN_MARGIN)\n",
        "gz1=gz1.loc[keep].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg,dec_deg=parse_ra_dec_mixed(gz1[ra_col],gz1[dec_col])\n",
        "ok=np.isfinite(ra_deg)&np.isfinite(dec_deg)\n",
        "gz1=gz1.loc[ok].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg=ra_deg[ok]; dec_deg=dec_deg[ok]\n",
        "\n",
        "thetas=(np.pi/2.0)-np.deg2rad(dec_deg); phis=np.deg2rad(ra_deg)%(2*np.pi)\n",
        "pix_gz=hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "dth_gz=dthL_adj_all[pix_gz]\n",
        "dph_gz=dphL_adj_all[pix_gz]\n",
        "dph_metric=phi_metric_divsin(dph_gz, thetas)\n",
        "\n",
        "sky_ok=np.ones_like(dph_gz, bool)\n",
        "if USE_MASK_FOR_GZ1 and ('mask_vec' in locals()) and (mask_vec is not None):\n",
        "    sky_ok = (mask_vec[pix_gz] > 0)\n",
        "\n",
        "stats=optionA_stats(spins.values, dph_metric, dth_gz, thetas, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "\n",
        "# ---------- Save & download ----------\n",
        "stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir=f\"/mnt/data/Step3_AllInOne_GZ1_v2_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "summary={\n",
        "    \"nside\":int(nside),\n",
        "    \"theta_gate_deg\":THETA_GATE_DEG,\n",
        "    \"min_margin\":MIN_MARGIN,\n",
        "    \"use_mask\":bool(USE_MASK_FOR_GZ1),\n",
        "    \"inputs\":{\"dtheta\":dtheta_path,\"dphi\":dphi_path,\"gz1\":gz1_path,\"jwst_for_cal\":jwst_path,\n",
        "              \"density\":dens_path,\"kappa\":kappa_path,\"mask\":mask_path},\n",
        "    \"mechanism2\":{\"alpha_density\":ALPHA_DENS,\"alpha_kappa\":ALPHA_KAPPA,\n",
        "                  \"smooth_fwhm_deg\":SMOOTH_FWHM_DEG,\"lmax\":LMAX,\n",
        "                  \"available\": bool((dens_map is not None) or (kmap is not None))},\n",
        "    \"calibration\":cal_report,\n",
        "    \"transform_M\":M.tolist(),\n",
        "    \"optionA_result\":{k:(float(v) if isinstance(v,(int,float,np.floating)) else v)\n",
        "                      for k,v in stats.items() if k not in (\"valid\",\"pred\")},\n",
        "}\n",
        "with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(summary,f,indent=2)\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"valid\":stats[\"valid\"].astype(int),\n",
        "    \"spin_obs\":spins.values.astype(int),\n",
        "    \"pred_spin\":stats[\"pred\"].astype(int),\n",
        "    \"dtheta_reanchored\":dth_gz.astype(float),\n",
        "    \"dphi_metric_reanchored\":dph_metric.astype(float),\n",
        "}).to_csv(os.path.join(out_dir,\"gz1_objects_reanchored.csv\"), index=False)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo — Option A (Re-anchored by Mechanism-2)\")\n",
        "plt.axhline(0.5, ls=\"--\"); plt.bar([\"Observed\"], [stats[\"frac\"] if stats[\"N\"]>0 else 0.0])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45,0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir,\"plot_alignment_reanchored.png\"), dpi=160); plt.close()\n",
        "\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    if 'mech2_comp' in locals() and mech2_comp is not None:\n",
        "        np.save(os.path.join(out_dir,\"mech2_composite.npy\"), mech2_comp.astype(np.float32))\n",
        "\n",
        "zip_path=f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root,_,files in os.walk(out_dir):\n",
        "        for fn in files: zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), out_dir))\n",
        "\n",
        "print(\"DONE.\"); print(\"Results dir:\", out_dir); print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files; files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qjb4-uuqzzSr",
        "outputId": "147f9a9c-89ff-4be9-9962-677db422e43c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  jwst  : ./master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "  mask  : ./glimpse_mask.fits\n",
            "  density overlay: ./Logosfield_scalar_density_map.npy\n",
            "  kappa overlay  : (none)\n",
            "Not enough calibration pixels; using identity M.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-241384773.py:291: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_014834\n",
            "ZIP: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_014834.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b3b6254-100c-45ac-b6e0-8854aea42e78\", \"Step3_AllInOne_GZ1_v2_20250831_014834.zip\", 3652683)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}