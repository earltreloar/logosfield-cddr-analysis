{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vcV63DJchBbswsEpcUkNfzE5aSXQKXD8",
      "authorship_tag": "ABX9TyNIn6E17saZBLPwDd6KayJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earltreloar/logosfield-cddr-analysis/blob/main/mechanism_1_and_2_alignment_density_per_logosfield.ipynb%20update\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install healpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2K7_js5MgRu",
        "outputId": "b82267ea-db9d-4a9b-af1a-f94657756b22"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: healpy in /usr/local/lib/python3.12/dist-packages (1.18.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from healpy) (2.0.2)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (from healpy) (7.1.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (0.2025.8.25.0.36.58)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (6.0.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "# Load all candidate CSVs in /content\n",
        "files = glob(\"/content/*.csv\") + glob(\"/content/*.csv.gz\") + glob(\"/content/*.xlsx\")\n",
        "\n",
        "print(\"üìÇ Checking all uploaded table files...\\n\")\n",
        "\n",
        "for f in files:\n",
        "    print(f\"\\n‚û°Ô∏è  File: {f}\")\n",
        "    try:\n",
        "        df = pd.read_csv(f) if f.endswith('.csv') or f.endswith('.csv.gz') else pd.read_excel(f)\n",
        "        print(\"‚úÖ Columns:\", list(df.columns))\n",
        "        missing = [col for col in ['ra', 'dec', 'spin'] if col not in df.columns]\n",
        "        if missing:\n",
        "            print(\"‚ùå Missing columns:\", missing)\n",
        "        else:\n",
        "            print(\"‚úÖ All required columns present.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Failed to read:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1CVm6D6P4N6",
        "outputId": "96a82fbb-0ad8-4f79-c8e0-be3f6fda7b54"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Checking all uploaded table files...\n",
            "\n",
            "\n",
            "‚û°Ô∏è  File: /content/data_hsc.csv\n",
            "‚úÖ Columns: ['RA', 'Dec', 'z', 'direction_cw_ccw']\n",
            "‚ùå Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "‚û°Ô∏è  File: /content/GalaxyZoo1_DR_table2.csv.gz\n",
            "‚úÖ Columns: ['OBJID', 'RA', 'DEC', 'NVOTE', 'P_EL', 'P_CW', 'P_ACW', 'P_EDGE', 'P_DK', 'P_MG', 'P_CS', 'P_EL_DEBIASED', 'P_CS_DEBIASED', 'SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
            "‚ùå Missing columns: ['ra', 'dec', 'spin']\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy (4).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (4).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy.xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (1).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy (3).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (2).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (3).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin', 'p_cw', 'p_ccw']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/shamir_jades_proxy_zge10.xlsx\n",
            "‚úÖ Columns: ['object_id', 'spin', 'dataset', 'z']\n",
            "‚ùå Missing columns: ['ra', 'dec']\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy (2).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n",
            "\n",
            "‚û°Ô∏è  File: /content/HSC_STANDARDIZED copy (1).xlsx\n",
            "‚úÖ Columns: ['ra', 'dec', 'spin']\n",
            "‚úÖ All required columns present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    path = \"Logosfield_scalar_density_map.npy\"\n",
        "    data = np.load(path, allow_pickle=True)\n",
        "\n",
        "    print(f\"Loaded type: {type(data)}\")\n",
        "    if isinstance(data, np.ndarray):\n",
        "        print(f\"Array shape: {data.shape}\")\n",
        "        if data.ndim == 1:\n",
        "            print(\"‚úÖ Valid 1D HEALPix map.\")\n",
        "        elif data.ndim == 0:\n",
        "            print(\"‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\")\n",
        "            obj = data.item()\n",
        "            print(f\"Item type: {type(obj)}\")\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                print(f\"Recovered array shape: {obj.shape}\")\n",
        "                if obj.ndim == 1:\n",
        "                    print(\"‚úÖ Extracted valid 1D HEALPix map. Re-saving...\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", obj)\n",
        "                else:\n",
        "                    print(\"‚ùå Extracted array is not 1D. Manual inspection needed.\")\n",
        "            else:\n",
        "                print(\"‚ùå Object inside .npy is not an ndarray.\")\n",
        "        else:\n",
        "            print(\"‚ùå Map is not 1D. Reshape or fix required.\")\n",
        "    else:\n",
        "        print(\"‚ùå File content is not a NumPy array.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error loading .npy:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNBOKvm6bS8e",
        "outputId": "b120949b-e7b1-42b6-ca6d-60e75b840d5f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "‚ùå Object inside .npy is not an ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alm = hp.map2alm(smoothed_map)\n",
        "grad_maps = hp.alm2map_der1(alm, nside=nside)\n",
        "\n",
        "if grad_maps.shape[0] >= 2:\n",
        "    dtheta_map = grad_maps[0]\n",
        "    dphi_map = grad_maps[1]\n",
        "    print(\"‚úÖ Gradient maps computed successfully.\")\n",
        "    np.save(\"Logosfield_dtheta_map.npy\", dtheta_map)\n",
        "    np.save(\"Logosfield_dphi_map.npy\", dphi_map)\n",
        "    print(\"üíæ Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\")\n",
        "else:\n",
        "    raise ValueError(\"Unexpected gradient output shape:\", grad_maps.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGdydggleDLe",
        "outputId": "8ec8fff2-192d-4622-c545-57fff2cae839"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gradient maps computed successfully.\n",
            "üíæ Saved: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace with uploaded file path\n",
        "map_filename = \"Logosfield_scalar_density_map.npy\"\n",
        "\n",
        "try:\n",
        "    # Load the object (dict inside zero-dimensional ndarray)\n",
        "    raw = np.load(map_filename, allow_pickle=True)\n",
        "    print(\"üîç Loaded type:\", type(raw))\n",
        "    print(\"Array shape:\", raw.shape)\n",
        "\n",
        "    if raw.ndim == 0:\n",
        "        print(\"‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\")\n",
        "        obj = raw.item()\n",
        "        print(\"Item type:\", type(obj))\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            # Attempt to extract the first array from dict\n",
        "            for key, val in obj.items():\n",
        "                if isinstance(val, np.ndarray) and val.ndim == 1:\n",
        "                    print(f\"‚úÖ Extracted key '{key}' with shape {val.shape}\")\n",
        "                    np.save(\"Logosfield_scalar_density_map_FIXED.npy\", val)\n",
        "                    print(\"üíæ Saved as Logosfield_scalar_density_map_FIXED.npy\")\n",
        "                    break\n",
        "            else:\n",
        "                print(\"‚ùå No 1D ndarray found inside the dictionary.\")\n",
        "        else:\n",
        "            print(\"‚ùå Top-level object is not a dictionary.\")\n",
        "    else:\n",
        "        print(\"‚ùå Unexpected array shape ‚Äî manual inspection needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error occurred:\", type(e).__name__, \"-\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU3qx-mybpK2",
        "outputId": "9be9cda2-6e93-4109-9097-208083b2cc14"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Loaded type: <class 'numpy.ndarray'>\n",
            "Array shape: ()\n",
            "‚ö†Ô∏è Zero-dimensional array. Inspecting contents...\n",
            "Item type: <class 'dict'>\n",
            "‚úÖ Extracted key 'map' with shape (196608,)\n",
            "üíæ Saved as Logosfield_scalar_density_map_FIXED.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 ¬∑ Option A (Galaxy Zoo only) ‚Äî AUTO-DISCOVER + SEXAGESIMAL-SAFE ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"\n",
        "    Returns (ra_deg, dec_deg) handling degrees or sexagesimal strings like '00:00:00.74' / '+12:34:56.7'.\n",
        "    Uses astropy SkyCoord; falls back to numeric if already deg.\n",
        "    \"\"\"\n",
        "    # Quick path: try numeric\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed: build strings and parse via SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "\n",
        "    # Heuristic: if many have \":\" or \" \" treat as sexagesimal\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Otherwise, last try: assume degrees but with stray strings\n",
        "    if ra_num.isna().any() or dec_num.isna().any():\n",
        "        # Attempt flexible parse row-by-row with SkyCoord accepting deg strings\n",
        "        out_ra, out_dec = [], []\n",
        "        for r, d in zip(ra_series, dec_series):\n",
        "            try:\n",
        "                rnum = float(r); dnum = float(d)\n",
        "                out_ra.append(rnum); out_dec.append(dnum); continue\n",
        "            except Exception:\n",
        "                try:\n",
        "                    sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                    out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "                except Exception:\n",
        "                    out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "        return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "    return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta ‚Üí\", dtheta_path)\n",
        "print(\"  dphi   ‚Üí\", dphi_path)\n",
        "print(\"  gz1    ‚Üí\", gz1_path)\n",
        "print(\"  mask   ‚Üí\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo + sexagesimal-safe RA/Dec ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "# robust RA/Dec parsing (deg or HMS/DMS)\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "\n",
        "# drop rows that failed to parse\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "# Rotation nulls\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "# Shuffle nulls\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 ¬∑ Option A ‚Äî Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"Œ∏-gate = ¬±{THETA_GATE_DEG}¬∞ ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg‚Üífrac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean¬±std = {summary['shuffle_null_mean']:.6f} ¬± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(out_dir):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5wgq_JHo7zC",
        "outputId": "c0345fad-3aba-449f-ed4a-2d22fe25c3e3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta ‚Üí ./Logosfield_dtheta_map.npy\n",
            "  dphi   ‚Üí /content/Logosfield_dphi_map.npy\n",
            "  gz1    ‚Üí ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   ‚Üí ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1678358610.py:266: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_021754\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_021754.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Mechanism 1 ¬∑ Option A (Galaxy Zoo only) ‚Äî AUTO-DISCOVER + SEXAGESIMAL-SAFE + AUTO-DOWNLOAD ====\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "THETA_GATE_DEG = 15.0\n",
        "MIN_MARGIN = 0.05\n",
        "ROTATIONS_DEG = [0,30,60,90]\n",
        "MAX_SHUFFLE_N = 200\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --------- Deps ---------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(patterns, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    cands=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for pat in patterns:\n",
        "            cands += glob.glob(os.path.join(r, pat))\n",
        "    # Prefer names with 'galaxyzoo' / shorter names\n",
        "    cands = sorted(set(cands), key=lambda p: (0 if \"galaxyzoo\" in p.lower() else 1, len(os.path.basename(p))))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def discover_gz1():\n",
        "    return autodiscover([\n",
        "        \"GalaxyZoo*table2*.csv*\",\"GalaxyZoo*DR*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"\n",
        "    ])\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    return autodiscover([f\"*{kind}*.npy\", f\"*Logosfield*{kind}*.npy\", f\"*{kind}_map*.npy\", f\"*{kind} map*.npy\"])\n",
        "\n",
        "def discover_mask():\n",
        "    return autodiscover([\"*mask*.fits\"])\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra = next((L[k] for k in (\"ra\",\"ra_deg\",\"ra (deg)\",\"ra_deg_j2000\",\"ra_j2000\") if k in L),\n",
        "              next((c for c in df.columns if \"ra\" in c.lower()), None))\n",
        "    dec = next((L[k] for k in (\"dec\",\"dec_deg\",\"dec (deg)\",\"dec_deg_j2000\",\"dec_j2000\",\"de\") if k in L),\n",
        "               next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None))\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    \"\"\"Return (ra_deg, dec_deg) handling degrees or HMS/DMS strings.\"\"\"\n",
        "    # Quick numeric path\n",
        "    ra_num  = pd.to_numeric(ra_series,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "\n",
        "    # Sexagesimal or mixed -> use SkyCoord\n",
        "    ra_str  = ra_series.astype(str).str.strip()\n",
        "    dec_str = dec_series.astype(str).str.strip()\n",
        "    if (ra_str.str.contains(\":\").mean() > 0.05) or (dec_str.str.contains(\":\").mean() > 0.05):\n",
        "        sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "        return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "    # Last fallback: attempt per-row deg strings\n",
        "    out_ra, out_dec = [], []\n",
        "    for r, d in zip(ra_series, dec_series):\n",
        "        try:\n",
        "            out_ra.append(float(r)); out_dec.append(float(d))\n",
        "        except Exception:\n",
        "            try:\n",
        "                sc = SkyCoord(str(r), str(d), unit=(u.deg, u.deg), frame=\"icrs\")\n",
        "                out_ra.append(float(sc.ra.deg)); out_dec.append(float(sc.dec.deg))\n",
        "            except Exception:\n",
        "                out_ra.append(np.nan); out_dec.append(np.nan)\n",
        "    return np.array(out_ra), np.array(out_dec)\n",
        "\n",
        "def extract_spin_gz1(df):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw = next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= MIN_MARGIN\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    cw_flag = next((c for c in df.columns if \"cw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    ccw_flag = next((c for c in df.columns if \"ccw\" in c.lower() and \"flag\" in c.lower()), None)\n",
        "    if cw_flag and ccw_flag:\n",
        "        spin = np.where(df[cw_flag].astype(int)==1, 1,\n",
        "                        np.where(df[ccw_flag].astype(int)==1, -1, np.nan))\n",
        "        keep = ~np.isnan(spin)\n",
        "        return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin labels).\")\n",
        "\n",
        "def try_load_mask(mask_path, nside_maps):\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "    except Exception:\n",
        "        print(\"astropy not present; continuing without mask.\")\n",
        "        return None\n",
        "    if not mask_path or not os.path.exists(mask_path): return None\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns = infer_nside(vec)\n",
        "        return vec if ns==nside_maps else hp.ud_grade(vec, nside_maps, power=-2)\n",
        "    except Exception as e:\n",
        "        print(f\"Mask load/resample failed: {e}; proceeding without mask.\")\n",
        "        return None\n",
        "\n",
        "def apply_theta_gate(dtheta, dphi, gate_deg):\n",
        "    alpha = np.arctan2(dtheta, dphi)\n",
        "    return (np.abs(alpha) <= np.deg2rad(gate_deg)), alpha\n",
        "\n",
        "def rotation_nulls(dtheta, dphi, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dphi*c - dtheta*s)\n",
        "        ys.append(dphi*s + dtheta*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n, p0=0.5):\n",
        "    frac = k/n if n>0 else np.nan\n",
        "    se = math.sqrt(frac*(1-frac)/n) if n>0 else np.nan\n",
        "    ci_lo = max(0.0, frac - 1.96*se) if n>0 else np.nan\n",
        "    ci_hi = min(1.0, frac + 1.96*se) if n>0 else np.nan\n",
        "    try:\n",
        "        from scipy.stats import binomtest\n",
        "        pval = binomtest(k, n, p=p0, alternative=\"greater\").pvalue\n",
        "    except Exception:\n",
        "        pval = np.nan\n",
        "    z = (frac - p0)/math.sqrt(p0*(1-p0)/n) if n>0 else np.nan\n",
        "    return dict(frac=frac, n=n, k=k, ci_lo=ci_lo, ci_hi=ci_hi, z=z, p_one_sided=pval)\n",
        "\n",
        "def summarize_alignment(spins, dphi, dtheta, theta_gate_deg, sky_ok=None):\n",
        "    gate_mask, _ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    pred = np.where(dphi >= 0, 1, -1)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(stats=None, valid_mask=valid, pred_spin=pred)\n",
        "    k = int((spins[valid].astype(int) == pred[valid].astype(int)).sum())\n",
        "    return dict(stats=binom_stats(k, N), valid_mask=valid, pred_spin=pred)\n",
        "\n",
        "def run_spin_shuffle_nulls(spins, dphi, dtheta, theta_gate_deg, n_iter=200):\n",
        "    gate_mask,_ = apply_theta_gate(dtheta, dphi, theta_gate_deg)\n",
        "    valid = gate_mask & np.isfinite(spins) & np.isfinite(dphi)\n",
        "    if valid.sum()==0: return np.array([])\n",
        "    s = spins[valid].astype(int).copy()\n",
        "    p = np.where(dphi[valid]>=0, 1, -1).astype(int)\n",
        "    out=[]\n",
        "    for _ in range(int(n_iter)):\n",
        "        np.random.shuffle(s)\n",
        "        out.append((s==p).mean())\n",
        "    return np.array(out)\n",
        "\n",
        "def write_zip(out_dir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "# --------- Discover inputs ---------\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Auto-discovery:\")\n",
        "print(\"  dtheta ‚Üí\", dtheta_path)\n",
        "print(\"  dphi   ‚Üí\", dphi_path)\n",
        "print(\"  gz1    ‚Üí\", gz1_path)\n",
        "print(\"  mask   ‚Üí\", mask_path if mask_path else \"(none)\")\n",
        "\n",
        "if not dtheta_path or not dphi_path: raise FileNotFoundError(\"Missing gradient maps.\")\n",
        "if not gz1_path: raise FileNotFoundError(\"Could not find Galaxy Zoo file (table2).\")\n",
        "\n",
        "# --------- Load maps ---------\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "if infer_nside(dphi_map) != nside: raise ValueError(\"dtheta/dphi NSIDEs differ.\")\n",
        "mask_vec = try_load_mask(mask_path, nside)\n",
        "\n",
        "# --------- Load Galaxy Zoo (sexagesimal-safe RA/Dec) ---------\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep  = extract_spin_gz1(gz1)\n",
        "gz1 = gz1.loc[keep].copy()\n",
        "spin_obs = spin_obs.loc[gz1.index]\n",
        "\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "dtheta = dtheta_map[pix]\n",
        "dphi   = dphi_map[pix]\n",
        "sky_ok = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dphi, dtype=bool)\n",
        "\n",
        "# --------- Compute alignment + nulls ---------\n",
        "res = summarize_alignment(spin_obs.values, dphi, dtheta, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "stats = res[\"stats\"]; valid_mask = res[\"valid_mask\"]; pred_spin = res[\"pred_spin\"]\n",
        "\n",
        "rot_xs, rot_ys = rotation_nulls(dtheta[valid_mask], dphi[valid_mask], ROTATIONS_DEG)\n",
        "rot_fracs = []\n",
        "for y_rot in rot_ys:\n",
        "    pred_rot = np.where(y_rot>=0, 1, -1)\n",
        "    rot_fracs.append((spin_obs.values[valid_mask].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "N_valid = int(valid_mask.sum())\n",
        "if N_valid > 250_000:\n",
        "    idx = np.random.choice(np.where(valid_mask)[0], size=250_000, replace=False)\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[idx], dphi[idx], dtheta[idx], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "else:\n",
        "    shuffle_fracs = run_spin_shuffle_nulls(spin_obs.values[valid_mask], dphi[valid_mask], dtheta[valid_mask], THETA_GATE_DEG, n_iter=MAX_SHUFFLE_N)\n",
        "\n",
        "# --------- Save outputs ---------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/Mechanism1_OptionA_GZ1_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": \"GalaxyZoo1\",\n",
        "    \"maps\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "    \"gz1_path\": gz1_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"rotations_deg\": ROTATIONS_DEG,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"N_after_filters\": int(N_valid),\n",
        "    \"alignment\": stats,\n",
        "    \"rotation_nulls\": dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "    \"shuffle_null_mean\": float(np.mean(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_std\": float(np.std(shuffle_fracs)) if shuffle_fracs.size else None,\n",
        "    \"shuffle_null_iters\": int(shuffle_fracs.size),\n",
        "}\n",
        "pd.DataFrame({\n",
        "    \"valid\": valid_mask.astype(int),\n",
        "    \"spin_obs\": spin_obs.values.astype(int),\n",
        "    \"pred_spin\": pred_spin.astype(int),\n",
        "    \"dphi\": dphi.astype(float),\n",
        "    \"dtheta\": dtheta.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, \"gz1_per_object_vectors.csv\"), index=False)\n",
        "pd.DataFrame({\"rotation_deg\": ROTATIONS_DEG, \"rot_frac\": rot_fracs}).to_csv(\n",
        "    os.path.join(out_dir, \"rotation_nulls.csv\"), index=False)\n",
        "if shuffle_fracs.size:\n",
        "    pd.DataFrame({\"shuffle_frac\": shuffle_fracs}).to_csv(\n",
        "        os.path.join(out_dir, \"shuffle_nulls.csv\"), index=False)\n",
        "with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "    s = summary[\"alignment\"]\n",
        "    f.write(\n",
        "        \"Mechanism 1 ¬∑ Option A ‚Äî Galaxy Zoo (sexagesimal-safe)\\n\"\n",
        "        f\"GZ1 file: {gz1_path}\\n\"\n",
        "        f\"Maps: dtheta={dtheta_path}\\n      dphi  ={dphi_path}\\n\"\n",
        "        f\"NSIDE={summary['nside']}\\n\"\n",
        "        f\"Œ∏-gate = ¬±{THETA_GATE_DEG}¬∞ ; MIN_MARGIN={MIN_MARGIN}\\n\"\n",
        "        f\"N (valid) = {summary['N_after_filters']}\\n\"\n",
        "        f\"Alignment fraction = {s['frac']:.6f}  (95% CI [{s['ci_lo']:.6f}, {s['ci_hi']:.6f}])\\n\"\n",
        "        f\"z vs 0.5 = {s['z']:.3f} ; one-sided p = {s['p_one_sided']:.3e}\\n\"\n",
        "        f\"Rotation nulls (deg‚Üífrac): {summary['rotation_nulls']}\\n\"\n",
        "        f\"Shuffle null mean¬±std = {summary['shuffle_null_mean']:.6f} ¬± {summary['shuffle_null_std']:.6f} \"\n",
        "        f\"(iters={summary['shuffle_null_iters']})\\n\"\n",
        "    )\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A alignment\")\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.bar([\"Observed\"], [summary[\"alignment\"][\"frac\"]])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"plot_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --------- ZIP + auto-download ---------\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "write_zip(out_dir, zip_path)\n",
        "\n",
        "print(\"\\nDONE.\")\n",
        "print(f\"Results folder: {out_dir}\")\n",
        "print(f\"ZIP bundle:     {zip_path}\")\n",
        "\n",
        "# Trigger downloadable file in Colab (safe no-op elsewhere)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available in this environment:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "TjPvBb3KqlCR",
        "outputId": "2c27e713-f27c-4a93-e1b4-a6702f8b7d5d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  dtheta ‚Üí ./Logosfield_dtheta_map.npy\n",
            "  dphi   ‚Üí /content/Logosfield_dphi_map.npy\n",
            "  gz1    ‚Üí ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask   ‚Üí ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-237797779.py:251: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE.\n",
            "Results folder: /mnt/data/Mechanism1_OptionA_GZ1_20250831_021919\n",
            "ZIP bundle:     /mnt/data/Mechanism1_OptionA_GZ1_20250831_021919.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcd7b60b-e1a9-494f-b0fc-a9964e4d8402\", \"Mechanism1_OptionA_GZ1_20250831_021919.zip\", 1621497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Option A calibration sweep ‚Äî find the convention that matches validated results ===\n",
        "import os, sys, json, math, glob, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# ---- discover the same inputs as before ----\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):  # 'dtheta'|'dphi'\n",
        "    for patset in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c=autodiscover(patset)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---- deps ----\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"healpy\",\"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "# ---- basic helpers ----\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(\"Map length doesn't match 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_series, dec_series):\n",
        "    ra_num  = pd.to_numeric(ra_series, errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_series, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    ra_str = ra_series.astype(str).str.strip()\n",
        "    dec_str= dec_series.astype(str).str.strip()\n",
        "    sc = SkyCoord(ra=ra_str.values, dec=dec_str.values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    # fallback labels\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def binom_stats(k,n):\n",
        "    frac=k/n if n else np.nan\n",
        "    se=(frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    return frac, max(0.0, frac-1.96*se) if n else np.nan, min(1.0, frac+1.96*se) if n else np.nan\n",
        "\n",
        "def apply_gate(dth,dph,gate_deg):\n",
        "    alpha=np.arctan2(dth,dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg)\n",
        "\n",
        "# ---- load data ----\n",
        "dtheta_path = discover_map(\"dtheta\"); dphi_path = discover_map(\"dphi\")\n",
        "gz1_path = discover_gz1(); mask_path = discover_mask()\n",
        "print(\"Using:\\n  dtheta:\", dtheta_path, \"\\n  dphi:  \", dphi_path, \"\\n  gz1:   \", gz1_path, \"\\n  mask:  \", mask_path or \"(none)\")\n",
        "\n",
        "dtheta_map = np.load(dtheta_path); dphi_map = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map)==nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# mask (optional)\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        from astropy.io import fits\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "\n",
        "# galaxy zoo\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spin_obs, keep = extract_spin_gz1(gz1, min_margin=0.05)\n",
        "gz1 = gz1.loc[keep].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spin_obs = spin_obs.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# precompute angles and two pix modes\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix_ring = hp.ang2pix(nside, thetas, phis, nest=False)\n",
        "pix_nest = hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "# ---- sweep space ----\n",
        "gate_list = [10,15,20]\n",
        "nest_opts = [False, True]\n",
        "swap_opts = [False, True]      # swap dtheta<->dphi\n",
        "flip_dth  = [0,1]              # 1 means multiply by -1\n",
        "flip_dph  = [0,1]\n",
        "phi_metric = [\"none\",\"times_sin\",\"div_sin\"]  # component tweak\n",
        "pred_sign = [\"+dphi\",\"-dphi\"]  # handedness flip\n",
        "use_mask  = [True, False]\n",
        "\n",
        "records=[]\n",
        "\n",
        "for gate in gate_list:\n",
        "    for nest in nest_opts:\n",
        "        pix = pix_nest if nest else pix_ring\n",
        "        raw_dth = dtheta_map[pix].astype(float)\n",
        "        raw_dph = dphi_map[pix].astype(float)\n",
        "\n",
        "        for swap in swap_opts:\n",
        "            dth = raw_dth.copy(); dph = raw_dph.copy()\n",
        "            if swap: dth, dph = dph, dth\n",
        "\n",
        "            for fth in flip_dth:\n",
        "                dth_s = -dth if fth else dth\n",
        "                for fph in flip_dph:\n",
        "                    dph_s = -dph if fph else dph\n",
        "\n",
        "                    # metric tweak\n",
        "                    for met in phi_metric:\n",
        "                        if met==\"times_sin\":\n",
        "                            dph_m = dph_s * np.sin(thetas)\n",
        "                        elif met==\"div_sin\":\n",
        "                            # avoid poles\n",
        "                            s = np.sin(thetas)\n",
        "                            s[s==0] = 1.0\n",
        "                            dph_m = dph_s / s\n",
        "                        else:\n",
        "                            dph_m = dph_s\n",
        "\n",
        "                        for ps in pred_sign:\n",
        "                            pred = np.where(dph_m>=0, 1, -1)\n",
        "                            if ps==\"-dphi\": pred = -pred\n",
        "\n",
        "                            for mflag in use_mask:\n",
        "                                gate_mask = apply_gate(dth_s, dph_m, gate)\n",
        "                                valid = gate_mask & np.isfinite(dph_m) & np.isfinite(dth_s)\n",
        "                                if mflag and (mask_vec is not None):\n",
        "                                    valid = valid & (mask_vec[(pix_nest if nest else pix_ring)] > 0)\n",
        "\n",
        "                                spins = spin_obs.values\n",
        "                                N = int(valid.sum())\n",
        "                                if N==0: continue\n",
        "                                aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "                                k = int(aligned.sum())\n",
        "                                frac, lo, hi = binom_stats(k,N)\n",
        "                                records.append(dict(\n",
        "                                    frac=frac, ci_lo=lo, ci_hi=hi, N=N, k=k,\n",
        "                                    gate=gate, nest=nest, swap=swap, flip_dtheta=fth, flip_dphi=fph,\n",
        "                                    phi_metric=met, pred_sign=ps, mask=mflag\n",
        "                                ))\n",
        "\n",
        "res = pd.DataFrame.from_records(records).sort_values([\"frac\",\"N\"], ascending=[False,False]).reset_index(drop=True)\n",
        "print(\"Top 10 configurations:\")\n",
        "display(res.head(10))\n",
        "\n",
        "# Save & auto-download\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_csv = f\"/mnt/data/OptionA_calibration_sweep_{stamp}.csv\"\n",
        "res.to_csv(out_csv, index=False)\n",
        "print(\"Saved sweep table:\", out_csv)\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(out_csv)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "DDcoaKzCr8sV",
        "outputId": "b471b75f-03a7-46ed-c3b1-0ae757d0c78f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy \n",
            "  dphi:   ./Logosfield_dphi_map.npy \n",
            "  gz1:    ./GalaxyZoo1_DR_table2.csv.gz \n",
            "  mask:   ./glimpse_mask.fits\n",
            "Top 10 configurations:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       frac     ci_lo     ci_hi     N     k  gate  nest  swap  flip_dtheta  \\\n",
              "0  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "1  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "2  0.571429  0.204823  0.938035     7     4    20  True  True            0   \n",
              "3  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "4  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "5  0.571429  0.204823  0.938035     7     4    20  True  True            1   \n",
              "6  0.557775  0.536548  0.579002  2103  1173    20  True  True            0   \n",
              "7  0.557775  0.536548  0.579002  2103  1173    20  True  True            1   \n",
              "8  0.556976  0.534509  0.579442  1878  1046    20  True  True            0   \n",
              "9  0.556976  0.534509  0.579442  1878  1046    20  True  True            1   \n",
              "\n",
              "   flip_dphi phi_metric pred_sign   mask  \n",
              "0          0       none     +dphi   True  \n",
              "1          0  times_sin     +dphi   True  \n",
              "2          0    div_sin     +dphi   True  \n",
              "3          0       none     +dphi   True  \n",
              "4          0  times_sin     +dphi   True  \n",
              "5          0    div_sin     +dphi   True  \n",
              "6          0    div_sin     -dphi  False  \n",
              "7          0    div_sin     -dphi  False  \n",
              "8          0       none     -dphi  False  \n",
              "9          0       none     -dphi  False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be1a50af-c3c9-4cef-b193-7552516269da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frac</th>\n",
              "      <th>ci_lo</th>\n",
              "      <th>ci_hi</th>\n",
              "      <th>N</th>\n",
              "      <th>k</th>\n",
              "      <th>gate</th>\n",
              "      <th>nest</th>\n",
              "      <th>swap</th>\n",
              "      <th>flip_dtheta</th>\n",
              "      <th>flip_dphi</th>\n",
              "      <th>phi_metric</th>\n",
              "      <th>pred_sign</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>times_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.938035</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>+dphi</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.557775</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.579002</td>\n",
              "      <td>2103</td>\n",
              "      <td>1173</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>div_sin</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.556976</td>\n",
              "      <td>0.534509</td>\n",
              "      <td>0.579442</td>\n",
              "      <td>1878</td>\n",
              "      <td>1046</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "      <td>-dphi</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be1a50af-c3c9-4cef-b193-7552516269da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be1a50af-c3c9-4cef-b193-7552516269da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be1a50af-c3c9-4cef-b193-7552516269da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5c6b2cc9-a2dd-4aee-b096-4200690ce4ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c6b2cc9-a2dd-4aee-b096-4200690ce4ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5c6b2cc9-a2dd-4aee-b096-4200690ce4ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Colab download not available:\\\", e)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007262090464927316,\n        \"min\": 0.556975505857295,\n        \"max\": 0.5714285714285714,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5714285714285714,\n          0.557774607703281,\n          0.556975505857295\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1707770370202692,\n        \"min\": 0.2048225158321042,\n        \"max\": 0.5365476554680403,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2048225158321042,\n          0.5365476554680403,\n          0.5345087588486707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ci_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18529015041402033,\n        \"min\": 0.5790015599385218,\n        \"max\": 0.9380346270250386,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9380346270250386,\n          0.5790015599385218,\n          0.5794422528659194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1027,\n        \"min\": 7,\n        \"max\": 2103,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          2103,\n          1878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 572,\n        \"min\": 4,\n        \"max\": 1173,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          1173,\n          1046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nest\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dtheta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flip_dphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_sign\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"-dphi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sweep table: /mnt/data/OptionA_calibration_sweep_20250831_022044.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12392127.py:201: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c41301c4-e85d-4787-bbc5-c18cb84d4304\", \"OptionA_calibration_sweep_20250831_022044.csv\", 46580)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mechanism 1 ¬∑ Option A (Galaxy Zoo) ‚Äî CORRECTED SETTINGS + optional mask, auto-download ===\n",
        "import os, sys, json, math, zipfile, random, glob\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "# --- Config ---\n",
        "THETA_GATE_DEG = 20.0          # from sweep\n",
        "MIN_MARGIN = 0.05\n",
        "MAX_SHUFFLE_N = 200\n",
        "ROTATIONS_DEG = [0, 30, 60, 90]\n",
        "EVALUATE_BOTH_MASK_SETTINGS = True   # set False to run only USE_MASK below\n",
        "USE_MASK = False                     # used only if EVALUATE_BOTH_MASK_SETTINGS=False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# --- Deps ---\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# --- Helpers ---\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} not 12*nside^2.\")\n",
        "    return ns\n",
        "\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p: (len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def discover_map(kind):   # 'dtheta' | 'dphi'\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()), None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num  = pd.to_numeric(ra_s,  errors=\"coerce\")\n",
        "    dec_num = pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc = SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "\n",
        "def apply_theta_gate(dth, dph, gate_deg):\n",
        "    alpha = np.arctan2(dth, dph)\n",
        "    return np.abs(alpha) <= np.deg2rad(gate_deg), alpha\n",
        "\n",
        "def rotation_nulls(dth, dph, angles_deg):\n",
        "    xs, ys = [], []\n",
        "    for ang in angles_deg:\n",
        "        r = np.deg2rad(ang); c, s = np.cos(r), np.sin(r)\n",
        "        xs.append(dph*c - dth*s)\n",
        "        ys.append(dph*s + dth*c)\n",
        "    return xs, ys\n",
        "\n",
        "def binom_stats(k, n):\n",
        "    frac = k/n if n else np.nan\n",
        "    se = (frac*(1-frac)/n)**0.5 if n else np.nan\n",
        "    lo = max(0.0, frac - 1.96*se) if n else np.nan\n",
        "    hi = min(1.0, frac + 1.96*se) if n else np.nan\n",
        "    return frac, lo, hi\n",
        "\n",
        "def summarize(spins, dph_metric, dth_swap, gate_deg, sky_ok=None):\n",
        "    # predict with handedness flip: -sign(dphi_metric)\n",
        "    pred = -np.where(dph_metric >= 0, 1, -1)\n",
        "    gate_mask, alpha = apply_theta_gate(dth_swap, dph_metric, gate_deg)\n",
        "    valid = gate_mask & np.isfinite(dph_metric) & np.isfinite(dth_swap)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0)\n",
        "    aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "    k = int(aligned.sum())\n",
        "    frac, lo, hi = binom_stats(k, N)\n",
        "    return dict(N=N, k=k, frac=frac, ci_lo=lo, ci_hi=hi, pred=pred, valid=valid, alpha=alpha)\n",
        "\n",
        "def write_bundle(tag, valid, spins, pred, dph_m, dth_s, out_dir):\n",
        "    import matplotlib.pyplot as plt\n",
        "    # per-object CSV\n",
        "    df = pd.DataFrame({\n",
        "        \"valid\": valid.astype(int),\n",
        "        \"spin_obs\": spins.astype(int),\n",
        "        \"pred_spin\": pred.astype(int),\n",
        "        \"dphi_metric\": dph_m.astype(float),\n",
        "        \"dtheta_swapped\": dth_s.astype(float),\n",
        "    })\n",
        "    df.to_csv(os.path.join(out_dir, f\"gz1_objects_{tag}.csv\"), index=False)\n",
        "    # simple plot\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.title(f\"Galaxy Zoo ‚Äî Option A ({tag})\")\n",
        "    plt.axhline(0.5, ls=\"--\")\n",
        "    plt.bar([\"Observed\"], [ (df.loc[valid, \"spin_obs\"] == df.loc[valid, \"pred_spin\"]).mean() ])\n",
        "    plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45, 0.75); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(out_dir, f\"plot_{tag}.png\"), dpi=160); plt.close()\n",
        "\n",
        "# --- Discover inputs ---\n",
        "dtheta_path = discover_map(\"dtheta\")\n",
        "dphi_path   = discover_map(\"dphi\")\n",
        "gz1_path    = discover_gz1()\n",
        "mask_path   = discover_mask()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "\n",
        "# --- Load maps ---\n",
        "dtheta_map = np.load(dtheta_path)\n",
        "dphi_map   = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map)\n",
        "assert infer_nside(dphi_map) == nside, \"NSIDE mismatch.\"\n",
        "\n",
        "# --- Load mask (optional) ---\n",
        "mask_vec = None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=-2)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e)\n",
        "        mask_vec = None\n",
        "\n",
        "# --- Load Galaxy Zoo ---\n",
        "try:\n",
        "    gz1 = pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1 = pd.read_csv(gz1_path)\n",
        "ra_col, dec_col = detect_ra_dec_columns(gz1)\n",
        "spins, keep = extract_spin_gz1(gz1, min_margin=MIN_MARGIN)\n",
        "gz1 = gz1.loc[keep].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(gz1[ra_col], gz1[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "gz1 = gz1.loc[ok].copy(); spins = spins.loc[gz1.index]\n",
        "ra_deg = ra_deg[ok]; dec_deg = dec_deg[ok]\n",
        "\n",
        "# --- Geometry & pix (corrected: NEST=True) ---\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix = hp.ang2pix(nside, thetas, phis, nest=True)  # <‚Äî NEST=True per sweep\n",
        "\n",
        "# --- Swap components and apply phi metric (div_sin) ---\n",
        "# swap=True ‚áí use map‚Äôs dphi as our dtheta, and map‚Äôs dtheta as our dphi\n",
        "dth_swap = dphi_map[pix].astype(float)\n",
        "dph_swap = dtheta_map[pix].astype(float)\n",
        "s = np.sin(thetas); s[s==0] = 1.0\n",
        "dph_metric = dph_swap / s     # <‚Äî div_sin\n",
        "sky_ok_vec = (mask_vec[pix] > 0) if mask_vec is not None else np.ones_like(dph_metric, dtype=bool)\n",
        "\n",
        "# --- Run (optionally both with/without mask) ---\n",
        "variants = [(\"unmasked\", False)]\n",
        "if EVALUATE_BOTH_MASK_SETTINGS:\n",
        "    variants = [(\"unmasked\", False), (\"masked\", True)]\n",
        "else:\n",
        "    variants = [(\"masked\" if USE_MASK else \"unmasked\", USE_MASK)]\n",
        "\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "base = f\"/mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_{stamp}\"\n",
        "os.makedirs(base, exist_ok=True)\n",
        "\n",
        "summaries = []\n",
        "for tag, use_mask in variants:\n",
        "    sky_ok = sky_ok_vec if use_mask else np.ones_like(sky_ok_vec, dtype=bool)\n",
        "    res = summarize(spins.values, dph_metric, dth_swap, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "    if res[\"N\"] == 0:\n",
        "        print(f\"{tag}: no valid samples\"); continue\n",
        "\n",
        "    # rotation nulls\n",
        "    valid = res[\"valid\"]\n",
        "    rot_xs, rot_ys = rotation_nulls(dth_swap[valid], dph_metric[valid], ROTATIONS_DEG)\n",
        "    rot_fracs=[]\n",
        "    for y_rot in rot_ys:\n",
        "        pred_rot = -np.where(y_rot>=0, 1, -1)  # keep handedness flip\n",
        "        rot_fracs.append((spins.values[valid].astype(int) == pred_rot.astype(int)).mean())\n",
        "\n",
        "    # shuffles\n",
        "    N_valid = int(valid.sum())\n",
        "    if N_valid > 250_000:\n",
        "        idx = np.random.choice(np.where(valid)[0], size=250_000, replace=False)\n",
        "        from_idx = spins.values[idx]; dph_idx = dph_metric[idx]; dth_idx = dth_swap[idx]\n",
        "        # simple shuffle null\n",
        "        fracs=[]\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(from_idx)\n",
        "            fracs.append((from_idx == -np.where(dph_idx>=0, 1, -1)).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "    else:\n",
        "        fracs=[]\n",
        "        arr = spins.values[valid].astype(int).copy()\n",
        "        pred = -np.where(dph_metric[valid]>=0, 1, -1).astype(int)\n",
        "        for _ in range(MAX_SHUFFLE_N):\n",
        "            np.random.shuffle(arr)\n",
        "            fracs.append((arr==pred).mean())\n",
        "        shuffle_mean, shuffle_std = float(np.mean(fracs)), float(np.std(fracs))\n",
        "\n",
        "    out_dir = os.path.join(base, tag); os.makedirs(out_dir, exist_ok=True)\n",
        "    write_bundle(tag, valid, spins.values, res[\"pred\"], dph_metric, dth_swap, out_dir)\n",
        "\n",
        "    summary = dict(\n",
        "        variant=tag,\n",
        "        nside=int(nside),\n",
        "        gate_deg=float(THETA_GATE_DEG),\n",
        "        use_mask=bool(use_mask),\n",
        "        N=int(res[\"N\"]), k=int(res[\"k\"]),\n",
        "        frac=float(res[\"frac\"]), ci_lo=float(res[\"ci_lo\"]), ci_hi=float(res[\"ci_hi\"]),\n",
        "        rotation_nulls=dict(zip([str(x) for x in ROTATIONS_DEG], [float(x) for x in rot_fracs])),\n",
        "        shuffle_null_mean=shuffle_mean, shuffle_null_std=shuffle_std,\n",
        "        maps={\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"mask\": mask_path},\n",
        "        gz1_path=gz1_path,\n",
        "        corrections={\"nest\": True, \"swap_components\": True, \"phi_metric\": \"div_sin\", \"pred_sign\": \"-dphi\"}\n",
        "    )\n",
        "    summaries.append(summary)\n",
        "    with open(os.path.join(out_dir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    with open(os.path.join(out_dir, \"alignment_summary.txt\"), \"w\") as f:\n",
        "        f.write(\n",
        "            f\"Variant: {tag}\\n\"\n",
        "            f\"N (valid) = {summary['N']}\\n\"\n",
        "            f\"Alignment fraction = {summary['frac']:.6f}  (95% CI [{summary['ci_lo']:.6f}, {summary['ci_hi']:.6f}])\\n\"\n",
        "            f\"Rotation nulls: {summary['rotation_nulls']}\\n\"\n",
        "            f\"Shuffle mean¬±std = {shuffle_mean:.6f} ¬± {shuffle_std:.6f}\\n\"\n",
        "        )\n",
        "\n",
        "# write top-level summary\n",
        "with open(os.path.join(base, \"run_summaries.json\"), \"w\") as f:\n",
        "    json.dump(summaries, f, indent=2)\n",
        "\n",
        "# zip & download\n",
        "zip_path = f\"{base}.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(base):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root, fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, base))\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"Results dir:\", base)\n",
        "print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "9jU10ltbuGib",
        "outputId": "56db5769-eac8-4cdf-dffa-26624c0d968e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  mask  : ./glimpse_mask.fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-403693560.py:210: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_022353\n",
            "ZIP: /mnt/data/Mechanism1_OptionA_GZ1_CORRECTED_20250831_022353.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_794b00aa-fec6-4a96-8b56-8bb5fd3d646e\", \"Mechanism1_OptionA_GZ1_CORRECTED_20250831_022353.zip\", 7827285)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (d/dŒ∏, d/dœÜ) of a scalar HEALPix map.\n",
        "    Tries sphtfunc.{alm2map_der, alm2map_der1}; falls back to a safe\n",
        "    numeric interpolation if neither is available.\n",
        "    \"\"\"\n",
        "    # 1) Harmonic path (preferred: exact & fast)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass  # fall through to numeric\n",
        "\n",
        "    # 2) Numeric fallback via spherical interpolation (slower, but robust)\n",
        "    pix = np.arange(12 * (nside ** 2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)  # mapvec is a plain HEALPix vector\n",
        "    eps = 1e-3  # ~0.057¬∞; small enough for local derivative\n",
        "\n",
        "    # central differences in Œ∏\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus) / (2.0 * eps)\n",
        "\n",
        "    # central differences in œÜ (wrap handled by get_interp_val)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus) / (2.0 * eps)\n",
        "\n",
        "    return np.array(dth), np.array(dph)\n"
      ],
      "metadata": {
        "id": "rbmtc1uey1Sw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === All-in-one (v2): Mechanism-2 re-anchoring + Option-A (Galaxy Zoo) ===\n",
        "# Patched: robust gradient_from_scalar (der ‚Üí der1 ‚Üí numeric fallback)\n",
        "\n",
        "import os, sys, glob, json, math, zipfile, random\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: uncomment to ensure harmonic derivative is available\n",
        "# import sys, subprocess; subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy>=1.16.0\"])\n",
        "\n",
        "THETA_GATE_DEG = 20.0\n",
        "MIN_MARGIN = 0.05\n",
        "ALPHA_DENS = 1.0\n",
        "ALPHA_KAPPA = 1.0\n",
        "SMOOTH_FWHM_DEG = 0.0\n",
        "LMAX = None\n",
        "USE_MASK_FOR_GZ1 = False\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# ---------- Patched gradient ----------\n",
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    \"\"\"\n",
        "    Return (‚àÇ/‚àÇŒ∏, ‚àÇ/‚àÇœÜ) of a scalar HEALPix map.\n",
        "    Try harmonic route, else robust numeric fallback via interpolation.\n",
        "    \"\"\"\n",
        "    # Harmonic (preferred)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax)\n",
        "            return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Numeric fallback\n",
        "    pix = np.arange(12*(nside**2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus)/(2*eps)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus)/(2*eps)\n",
        "    return np.array(dth), np.array(dph)\n",
        "\n",
        "# ---------- Discovery ----------\n",
        "def autodiscover(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "def discover_map(kind):\n",
        "    for pats in [[f\"*{kind}*.npy\"], [f\"*Logosfield*{kind}*.npy\"], [f\"*{kind}_map*.npy\"], [f\"*{kind} map*.npy\"]]:\n",
        "        c = autodiscover(pats)\n",
        "        if c: return c[0]\n",
        "    return None\n",
        "def discover_overlay_candidates():\n",
        "    dens = autodiscover([\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*scalar_density*.npy\",\"*density*.npz\"])\n",
        "    kappa = autodiscover([\"*kappa*.npy\",\"*convergence*.npy\",\"*mech2*.npy\",\"*kappa*.npz\"])\n",
        "    return (dens[0] if dens else None), (kappa[0] if kappa else None)\n",
        "def discover_gz1():\n",
        "    c = autodiscover([\"GalaxyZoo*table2*.csv*\",\"*GZ*table2*.csv*\",\"*galaxy*zoo*table2*.csv*\"])\n",
        "    return c[0] if c else None\n",
        "def discover_jwst():\n",
        "    c = autodiscover([\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*.xlsx\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\"])\n",
        "    return c[0] if c else None\n",
        "def discover_mask():\n",
        "    c = autodiscover([\"*mask*.fits\"])\n",
        "    return c[0] if c else None\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def infer_nside(vec):\n",
        "    n=int(vec.size); ns=int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2)!=n: raise ValueError(f\"Length {n} != 12*nside^2\")\n",
        "    return ns\n",
        "def detect_ra_dec_columns(df):\n",
        "    L={c.lower():c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()),None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"),None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num=pd.to_numeric(ra_s, errors=\"coerce\"); dec_num=pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc=SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle,u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "def extract_spin_gz1(df, min_margin=0.05):\n",
        "    p_cw=next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\")),None)\n",
        "    p_acw=next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\")),None)\n",
        "    if p_cw and p_acw:\n",
        "        pc=pd.to_numeric(df[p_cw],errors=\"coerce\").astype(float)\n",
        "        pa=pd.to_numeric(df[p_acw],errors=\"coerce\").astype(float)\n",
        "        keep=(pc-pa).abs()>=min_margin\n",
        "        spin=np.where(pc>pa,1,-1).astype(int)\n",
        "        return pd.Series(spin,index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\"):\n",
        "            v=df[c].astype(str).str.lower().str.strip()\n",
        "            spin=np.where(v.isin([\"cw\",\"+1\",\"1\",\"clockwise\"]),1,\n",
        "                          np.where(v.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\"]),-1,np.nan))\n",
        "            keep=~np.isnan(spin); return pd.Series(spin,index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found.\")\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s=np.sin(thetas).copy(); s[s==0]=1.0\n",
        "    return dph/s\n",
        "def smooth_if_needed(mapvec, fwhm_deg):\n",
        "    if not fwhm_deg or fwhm_deg<=0: return mapvec\n",
        "    return hp.sphtfunc.smoothing(mapvec, fwhm=math.radians(fwhm_deg), verbose=False)\n",
        "def fit_linear_M(Lx,Ly,Ox,Oy):\n",
        "    A1=np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2=np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A=np.vstack([A1,A2]); b=np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A+lam*np.eye(4); ATb=A.T@b\n",
        "    m=np.linalg.solve(ATA,ATb); return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "def optionA_stats(spins, dph_metric, dth, thetas, gate_deg, sky_ok=None):\n",
        "    pred = -np.where(dph_metric>=0,1,-1)\n",
        "    alpha=np.arctan2(dth,dph_metric)\n",
        "    gate=np.abs(alpha)<=np.deg2rad(gate_deg)\n",
        "    valid=gate & np.isfinite(dph_metric) & np.isfinite(dth)\n",
        "    if sky_ok is not None: valid&=sky_ok\n",
        "    N=int(valid.sum())\n",
        "    if N==0: return dict(N=0, frac=np.nan, ci_lo=np.nan, ci_hi=np.nan, valid=valid, pred=pred)\n",
        "    k=int((spins[valid].astype(int)==pred[valid].astype(int)).sum())\n",
        "    frac=k/N; se=(frac*(1-frac)/N)**0.5; lo=max(0.0,frac-1.96*se); hi=min(1.0,frac+1.96*se)\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=lo,ci_hi=hi,valid=valid,pred=pred)\n",
        "\n",
        "def load_scalar_map_any(path, target_nside=None, name_hint=\"\"):\n",
        "    if path is None or not os.path.exists(path): return None\n",
        "    arr=np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr=arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr,np.ndarray) and arr.dtype==object:\n",
        "        try:\n",
        "            obj=arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj,dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr=np.asarray(obj[k]); break\n",
        "                else: arr=np.asarray(next(iter(obj.values())))\n",
        "            else: arr=np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr=np.asarray(arr)\n",
        "    arr=np.asarray(arr,dtype=float).ravel()\n",
        "    src_nside=infer_nside(arr)\n",
        "    if target_nside is not None and src_nside!=target_nside:\n",
        "        arr=hp.ud_grade(arr, target_nside, power=0)\n",
        "    return arr\n",
        "\n",
        "# ---------- Load inputs ----------\n",
        "dtheta_path=discover_map(\"dtheta\")\n",
        "dphi_path  =discover_map(\"dphi\")\n",
        "gz1_path   =discover_gz1()\n",
        "jwst_path  =discover_jwst()\n",
        "mask_path  =discover_mask()\n",
        "dens_path,kappa_path=discover_overlay_candidates()\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  gz1   :\", gz1_path)\n",
        "print(\"  jwst  :\", jwst_path or \"(not found; all-sky calibration)\")\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "print(\"  density overlay:\", dens_path or \"(none)\")\n",
        "print(\"  kappa overlay  :\", kappa_path or \"(none)\")\n",
        "\n",
        "dtheta_map=np.load(dtheta_path)\n",
        "dphi_map  =np.load(dphi_path)\n",
        "nside=infer_nside(dtheta_map); assert infer_nside(dphi_map)==nside\n",
        "\n",
        "dens_map=load_scalar_map_any(dens_path,  target_nside=nside, name_hint=\"density\")\n",
        "kmap    =load_scalar_map_any(kappa_path, target_nside=nside, name_hint=\"kappa\")\n",
        "\n",
        "mask_vec=None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data=hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec=np.array(data).astype(float).ravel()\n",
        "        ns_mask=infer_nside(vec)\n",
        "        mask_vec=vec if ns_mask==nside else hp.ud_grade(vec, nside, power=0)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e); mask_vec=None\n",
        "\n",
        "# ---------- Mechanism-2 composite & gradient ----------\n",
        "mech2_comp=None\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    parts=[]\n",
        "    if dens_map is not None:\n",
        "        dm=(dens_map-np.nanmean(dens_map))/(np.nanstd(dens_map)+1e-12); parts.append(ALPHA_DENS*dm)\n",
        "    if kmap is not None:\n",
        "        km=(kmap-np.nanmean(kmap))/(np.nanstd(kmap)+1e-12); parts.append(ALPHA_KAPPA*km)\n",
        "    mech2_comp=np.sum(parts,axis=0); mech2_comp=smooth_if_needed(mech2_comp, SMOOTH_FWHM_DEG)\n",
        "    dth_M2, dph_M2 = gradient_from_scalar(mech2_comp, nside, lmax=LMAX)\n",
        "else:\n",
        "    dth_M2, dph_M2 = None, None\n",
        "\n",
        "# ---------- Calibration set ----------\n",
        "cal_pix=None\n",
        "if jwst_path and os.path.exists(jwst_path):\n",
        "    try:\n",
        "        jw=pd.read_excel(jwst_path)\n",
        "        ra_j,dec_j=detect_ra_dec_columns(jw)\n",
        "        ra_deg_j,dec_deg_j=parse_ra_dec_mixed(jw[ra_j],jw[dec_j])\n",
        "        th_j=(np.pi/2.0)-np.deg2rad(dec_deg_j); ph_j=np.deg2rad(ra_deg_j)%(2*np.pi)\n",
        "        cal_pix=hp.ang2pix(nside, th_j, ph_j, nest=True)\n",
        "        zcol=next((c for c in jw.columns if c.lower() in (\"z\",\"redshift\",\"photoz\",\"z_phot\",\"z_spec\")),None)\n",
        "        if zcol is not None:\n",
        "            z=pd.to_numeric(jw[zcol],errors=\"coerce\")\n",
        "            if np.isfinite(z).any():\n",
        "                highz = z >= np.nanmedian(z)\n",
        "                if len(highz)==len(cal_pix): cal_pix=cal_pix[highz.values]\n",
        "    except Exception as e:\n",
        "        print(\"JWST calibration fallback (all-sky):\", e); cal_pix=None\n",
        "if cal_pix is None: cal_pix=np.arange(12*(nside**2))\n",
        "\n",
        "# ---------- Logosfield gradients with corrections ----------\n",
        "pix_all=np.arange(12*(nside**2))\n",
        "th_all, ph_all = hp.pix2ang(nside, pix_all, nest=True)\n",
        "dthL_all = dphi_map[pix_all].astype(float)   # swap\n",
        "dphL_all = dtheta_map[pix_all].astype(float) # swap\n",
        "\n",
        "M=np.eye(2); cal_report={}\n",
        "if (dth_M2 is not None) and (dph_M2 is not None):\n",
        "    sel=np.unique(cal_pix)\n",
        "    ok=np.isfinite(dthL_all[sel])&np.isfinite(dphL_all[sel])&np.isfinite(dth_M2[sel])&np.isfinite(dph_M2[sel])\n",
        "    idx=sel[ok]\n",
        "    if idx.size>=100:\n",
        "        M=fit_linear_M(dthL_all[idx], dphL_all[idx], dth_M2[idx], dph_M2[idx])\n",
        "        predx=M[0,0]*dthL_all[idx]+M[0,1]*dphL_all[idx]\n",
        "        predy=M[1,0]*dthL_all[idx]+M[1,1]*dphL_all[idx]\n",
        "        cal_report={\"num_cal_pix\":int(idx.size),\n",
        "                    \"M\":M.tolist(),\n",
        "                    \"corr_x\":float(np.corrcoef(predx,dth_M2[idx])[0,1]),\n",
        "                    \"corr_y\":float(np.corrcoef(predy,dph_M2[idx])[0,1])}\n",
        "    else:\n",
        "        print(\"Not enough calibration pixels; using identity M.\")\n",
        "\n",
        "dthL_adj_all = M[0,0]*dthL_all + M[0,1]*dphL_all\n",
        "dphL_adj_all = M[1,0]*dthL_all + M[1,1]*dphL_all\n",
        "\n",
        "# ---------- Galaxy Zoo Option-A ----------\n",
        "try:\n",
        "    gz1=pd.read_csv(gz1_path, compression=\"infer\")\n",
        "except Exception:\n",
        "    gz1=pd.read_csv(gz1_path)\n",
        "ra_col,dec_col=detect_ra_dec_columns(gz1)\n",
        "spins,keep=extract_spin_gz1(gz1, MIN_MARGIN)\n",
        "gz1=gz1.loc[keep].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg,dec_deg=parse_ra_dec_mixed(gz1[ra_col],gz1[dec_col])\n",
        "ok=np.isfinite(ra_deg)&np.isfinite(dec_deg)\n",
        "gz1=gz1.loc[ok].copy(); spins=spins.loc[gz1.index]\n",
        "ra_deg=ra_deg[ok]; dec_deg=dec_deg[ok]\n",
        "\n",
        "thetas=(np.pi/2.0)-np.deg2rad(dec_deg); phis=np.deg2rad(ra_deg)%(2*np.pi)\n",
        "pix_gz=hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "dth_gz=dthL_adj_all[pix_gz]\n",
        "dph_gz=dphL_adj_all[pix_gz]\n",
        "dph_metric=phi_metric_divsin(dph_gz, thetas)\n",
        "\n",
        "sky_ok=np.ones_like(dph_gz, bool)\n",
        "if USE_MASK_FOR_GZ1 and ('mask_vec' in locals()) and (mask_vec is not None):\n",
        "    sky_ok = (mask_vec[pix_gz] > 0)\n",
        "\n",
        "stats=optionA_stats(spins.values, dph_metric, dth_gz, thetas, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "\n",
        "# ---------- Save & download ----------\n",
        "stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir=f\"/mnt/data/Step3_AllInOne_GZ1_v2_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "summary={\n",
        "    \"nside\":int(nside),\n",
        "    \"theta_gate_deg\":THETA_GATE_DEG,\n",
        "    \"min_margin\":MIN_MARGIN,\n",
        "    \"use_mask\":bool(USE_MASK_FOR_GZ1),\n",
        "    \"inputs\":{\"dtheta\":dtheta_path,\"dphi\":dphi_path,\"gz1\":gz1_path,\"jwst_for_cal\":jwst_path,\n",
        "              \"density\":dens_path,\"kappa\":kappa_path,\"mask\":mask_path},\n",
        "    \"mechanism2\":{\"alpha_density\":ALPHA_DENS,\"alpha_kappa\":ALPHA_KAPPA,\n",
        "                  \"smooth_fwhm_deg\":SMOOTH_FWHM_DEG,\"lmax\":LMAX,\n",
        "                  \"available\": bool((dens_map is not None) or (kmap is not None))},\n",
        "    \"calibration\":cal_report,\n",
        "    \"transform_M\":M.tolist(),\n",
        "    \"optionA_result\":{k:(float(v) if isinstance(v,(int,float,np.floating)) else v)\n",
        "                      for k,v in stats.items() if k not in (\"valid\",\"pred\")},\n",
        "}\n",
        "with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(summary,f,indent=2)\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"valid\":stats[\"valid\"].astype(int),\n",
        "    \"spin_obs\":spins.values.astype(int),\n",
        "    \"pred_spin\":stats[\"pred\"].astype(int),\n",
        "    \"dtheta_reanchored\":dth_gz.astype(float),\n",
        "    \"dphi_metric_reanchored\":dph_metric.astype(float),\n",
        "}).to_csv(os.path.join(out_dir,\"gz1_objects_reanchored.csv\"), index=False)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(\"Galaxy Zoo ‚Äî Option A (Re-anchored by Mechanism-2)\")\n",
        "plt.axhline(0.5, ls=\"--\"); plt.bar([\"Observed\"], [stats[\"frac\"] if stats[\"N\"]>0 else 0.0])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45,0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir,\"plot_alignment_reanchored.png\"), dpi=160); plt.close()\n",
        "\n",
        "if (dens_map is not None) or (kmap is not None):\n",
        "    if 'mech2_comp' in locals() and mech2_comp is not None:\n",
        "        np.save(os.path.join(out_dir,\"mech2_composite.npy\"), mech2_comp.astype(np.float32))\n",
        "\n",
        "zip_path=f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root,_,files in os.walk(out_dir):\n",
        "        for fn in files: zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), out_dir))\n",
        "\n",
        "print(\"DONE.\"); print(\"Results dir:\", out_dir); print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files; files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qjb4-uuqzzSr",
        "outputId": "c6b4939d-aecb-4cd6-8e33-6c428abbd347"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "  dtheta: ./Logosfield_dtheta_map.npy\n",
            "  dphi  : ./Logosfield_dphi_map.npy\n",
            "  gz1   : ./GalaxyZoo1_DR_table2.csv.gz\n",
            "  jwst  : ./master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1).xlsx\n",
            "  mask  : ./glimpse_mask.fits\n",
            "  density overlay: ./Logosfield_scalar_density_map.npy\n",
            "  kappa overlay  : (none)\n",
            "Not enough calibration pixels; using identity M.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-241384773.py:291: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_022533\n",
            "ZIP: /mnt/data/Step3_AllInOne_GZ1_v2_20250831_022533.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27e37920-c53e-463d-a7b5-9c680dd9634d\", \"Step3_AllInOne_GZ1_v2_20250831_022533.zip\", 3652683)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Single-dataset runner (Mechanism-2 anchored ‚àáL ‚Üí Mechanism-1 Option-A) ===\n",
        "# Use this for HSC first, then rerun for JWST. It will prompt for uploads if files are missing.\n",
        "\n",
        "import os, sys, glob, json, math, zipfile, random, inspect\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "THETA_GATE_DEG = 20.0\n",
        "MIN_MARGIN = 0.05\n",
        "ALPHA_DENS = 1.0\n",
        "ALPHA_KAPPA = 1.0\n",
        "SMOOTH_FWHM_DEG = 0.0\n",
        "LMAX = None\n",
        "USE_MASK = True  # For HSC & JWST, a mask is usually helpful. You can flip to False if it shrinks too hard.\n",
        "\n",
        "# --- Deps ---\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# --- Robust gradient_from_scalar (der ‚Üí der1 ‚Üí numeric fallback) ---\n",
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax); return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax); return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    pix = np.arange(12*(nside**2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus)/(2*eps)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus)/(2*eps)\n",
        "    return np.array(dth), np.array(dph)\n",
        "\n",
        "# --- Helpers ---\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Map length {n} != 12*nside^2\")\n",
        "    return ns\n",
        "\n",
        "def autodisc(pats, roots=(\"/mnt/data\",\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def load_scalar_map_any(path, target_nside=None, name_hint=\"\"):\n",
        "    if path is None or not os.path.exists(path): return None\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile): arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr = np.asarray(obj[k]); break\n",
        "                else: arr = np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr = np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    arr = np.asarray(arr, dtype=float).ravel()\n",
        "    src_nside = infer_nside(arr)\n",
        "    if target_nside is not None and src_nside != target_nside:\n",
        "        arr = hp.ud_grade(arr, target_nside, power=0)\n",
        "    return arr\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()), None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num = pd.to_numeric(ra_s, errors=\"coerce\"); dec_num = pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc = SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_generic(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\",\"pcw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"prob_ccw\",\"pccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\",\"cw-ccw\",\"chirality\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\",\"right\",\"r\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\",\"left\",\"l\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"Could not find spins (P_CW/P_ACW or spin/handedness labels).\")\n",
        "\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s = np.sin(thetas).copy(); s[s==0] = 1.0\n",
        "    return dph / s\n",
        "\n",
        "def optionA_stats(spins, dph_metric, dth, thetas, gate_deg, sky_ok=None):\n",
        "    pred = -np.where(dph_metric >= 0, 1, -1)  # validated handedness flip\n",
        "    alpha = np.arctan2(dth, dph_metric)\n",
        "    gate = np.abs(alpha) <= np.deg2rad(gate_deg)\n",
        "    valid = gate & np.isfinite(dph_metric) & np.isfinite(dth)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N = int(valid.sum())\n",
        "    if N == 0: return dict(N=0, k=0, frac=np.nan, ci_lo=np.nan, ci_hi=np.nan, valid=valid, pred=pred)\n",
        "    aligned = (spins[valid].astype(int) == pred[valid].astype(int))\n",
        "    k = int(aligned.sum()); frac = k/N\n",
        "    se = (frac*(1-frac)/N)**0.5\n",
        "    return dict(N=N, k=k, frac=frac, ci_lo=max(0.0, frac-1.96*se), ci_hi=min(1.0, frac+1.96*se),\n",
        "                valid=valid, pred=pred)\n",
        "\n",
        "# --- Resolve or upload required files ---\n",
        "BASE = \"/mnt/data\"\n",
        "def need_upload(label):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(f\"\\nUpload {label} now‚Ä¶\")\n",
        "        up = files.upload()\n",
        "        for fn in up.keys():\n",
        "            src = fn; dst = os.path.join(BASE, os.path.basename(fn))\n",
        "            if os.path.abspath(src) != dst: import shutil; shutil.move(src, dst)\n",
        "        return True\n",
        "    except Exception:\n",
        "        print(f\"(If not in Colab, please place {label} under /mnt/data and rerun.)\")\n",
        "        return False\n",
        "\n",
        "def pick_one(pats):\n",
        "    hits=[]\n",
        "    for pat in pats:\n",
        "        for root in (BASE, \".\", \"/content\"):\n",
        "            hits += glob.glob(os.path.join(root, pat))\n",
        "    hits = sorted(set(hits))\n",
        "    return hits[0] if hits else None\n",
        "\n",
        "# 1) Gradients\n",
        "dtheta_path = pick_one([\"*Logosfield*dtheta*map*.npy\",\"*dtheta_map*.npy\",\"*theta*map*.npy\"])\n",
        "dphi_path   = pick_one([\"*Logosfield*dphi*map*.npy\",  \"*dphi_map*.npy\",  \"*phi*map*.npy\"])\n",
        "if not dtheta_path or not dphi_path:\n",
        "    need_upload(\"gradient maps: Logosfield_dtheta_map.npy and Logosfield_dphi_map.npy\")\n",
        "    dtheta_path = pick_one([\"*Logosfield*dtheta*map*.npy\",\"*dtheta_map*.npy\",\"*theta*map*.npy\"])\n",
        "    dphi_path   = pick_one([\"*Logosfield*dphi*map*.npy\",  \"*dphi_map*.npy\",  \"*phi*map*.npy\"])\n",
        "\n",
        "# 2) Overlays (density and/or kappa)\n",
        "dens_path = pick_one([\"*scalar*density*.npy\",\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*density*.npz\"])\n",
        "kappa_path= pick_one([\"*kappa*.npy\",\"*convergence*.npy\",\"*mech2*.npy\",\"*kappa*.npz\"])\n",
        "if not dens_path and not kappa_path:\n",
        "    need_upload(\"an overlay map (density and/or kappa). Prefer a scalar density .npy\")\n",
        "    dens_path = pick_one([\"*scalar*density*.npy\",\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*density*.npz\"])\n",
        "    kappa_path= pick_one([\"*kappa*.npy\",\"*convergence*.npy\",\"*mech2*.npy\",\"*kappa*.npz\"])\n",
        "\n",
        "# 3) Mask (optional; helpful for HSC/JWST)\n",
        "mask_path = pick_one([\"*mask*.fits\"])\n",
        "if USE_MASK and not mask_path:\n",
        "    print(\"No mask found; you can upload one (e.g., glimpse_mask.fits) or continue without.\")\n",
        "    # not strictly required; skip upload prompt here\n",
        "\n",
        "# 4) Catalog (HSC first, then rerun for JWST)\n",
        "cat_path = pick_one([\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\",\"*highz*.xlsx\",\"*jwst*.csv*\"])\n",
        "if not cat_path:\n",
        "    need_upload(\"the catalog file (HSC first). Accepts .xlsx or .csv\")\n",
        "    cat_path = pick_one([\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\",\"*highz*.xlsx\",\"*jwst*.csv*\"])\n",
        "if not cat_path:\n",
        "    raise FileNotFoundError(\"Catalog not found. Please upload HSC (or JWST) and rerun this cell.\")\n",
        "\n",
        "label = \"HSC_or_JWST\"\n",
        "for key in [\"HSC\",\"JWST\",\"GOODS\",\"highz\"]:\n",
        "    if key.lower() in os.path.basename(cat_path).lower(): label = key\n",
        "\n",
        "print(\"\\nUsing:\")\n",
        "print(\"  dtheta:\", dtheta_path)\n",
        "print(\"  dphi  :\", dphi_path)\n",
        "print(\"  dens  :\", dens_path or \"(none)\")\n",
        "print(\"  kappa :\", kappa_path or \"(none)\")\n",
        "print(\"  mask  :\", mask_path or \"(none)\")\n",
        "print(\"  catalog:\", cat_path, f\"‚Üí label = {label}\")\n",
        "\n",
        "# --- Load maps ---\n",
        "dtheta_map = np.load(dtheta_path); dphi_map = np.load(dphi_path)\n",
        "nside = infer_nside(dtheta_map); assert infer_nside(dphi_map) == nside\n",
        "\n",
        "dens_map = load_scalar_map_any(dens_path,  target_nside=nside, name_hint=\"density\")\n",
        "kmap     = load_scalar_map_any(kappa_path, target_nside=nside, name_hint=\"kappa\")\n",
        "\n",
        "mask_vec = None\n",
        "if mask_path:\n",
        "    try:\n",
        "        with fits.open(mask_path) as hdul:\n",
        "            data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "            vec = np.array(data).astype(float).ravel()\n",
        "        ns_mask = infer_nside(vec)\n",
        "        mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=0)\n",
        "    except Exception as e:\n",
        "        print(\"Mask not used:\", e); mask_vec=None\n",
        "\n",
        "# --- Mechanism-2 composite & gradient ---\n",
        "if (dens_map is None) and (kmap is None):\n",
        "    raise RuntimeError(\"Need at least one overlay (density or kappa) to anchor.\")\n",
        "parts=[]\n",
        "if dens_map is not None:\n",
        "    dm = (dens_map - np.nanmean(dens_map))/(np.nanstd(dens_map)+1e-12); parts.append(ALPHA_DENS*dm)\n",
        "if kmap is not None:\n",
        "    km = (kmap - np.nanmean(kmap))/(np.nanstd(kmap)+1e-12); parts.append(ALPHA_KAPPA*km)\n",
        "mech2_comp = np.sum(parts, axis=0)\n",
        "if SMOOTH_FWHM_DEG>0: mech2_comp = hp.sphtfunc.smoothing(mech2_comp, fwhm=np.deg2rad(SMOOTH_FWHM_DEG), verbose=False)\n",
        "dth_M2, dph_M2 = gradient_from_scalar(mech2_comp, nside, lmax=LMAX)\n",
        "\n",
        "# --- Corrected Logosfield gradients (nest=True, swap components) ---\n",
        "pix_all = np.arange(12*(nside**2))\n",
        "th_all, ph_all = hp.pix2ang(nside, pix_all, nest=True)\n",
        "dthL_all = dphi_map[pix_all].astype(float)   # swap\n",
        "dphL_all = dtheta_map[pix_all].astype(float) # swap\n",
        "\n",
        "# Fit linear M: M¬∑[dthL, dphL] ‚âà [dth_M2, dph_M2]\n",
        "def fit_linear_M(Lx, Ly, Ox, Oy):\n",
        "    A1=np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2=np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A=np.vstack([A1,A2]); b=np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A+lam*np.eye(4); ATb=A.T@b\n",
        "    m=np.linalg.solve(ATA,ATb); return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "\n",
        "sel = np.arange(pix_all.size)\n",
        "ok  = np.isfinite(dthL_all[sel]) & np.isfinite(dphL_all[sel]) & np.isfinite(dth_M2[sel]) & np.isfinite(dph_M2[sel])\n",
        "idx = sel[ok]\n",
        "if idx.size < 100: raise RuntimeError(\"Not enough calibration pixels for anchoring.\")\n",
        "M = fit_linear_M(dthL_all[idx], dphL_all[idx], dth_M2[idx], dph_M2[idx])\n",
        "\n",
        "dthL_adj_all = M[0,0]*dthL_all + M[0,1]*dphL_all\n",
        "dphL_adj_all = M[1,0]*dthL_all + M[1,1]*dphL_all\n",
        "\n",
        "# --- Load catalog & run Option-A ---\n",
        "ext = os.path.splitext(cat_path)[1].lower()\n",
        "if ext in [\".xlsx\",\".xls\"]:\n",
        "    df = pd.read_excel(cat_path)\n",
        "else:\n",
        "    try: df = pd.read_csv(cat_path, compression=\"infer\")\n",
        "    except Exception: df = pd.read_csv(cat_path)\n",
        "\n",
        "ra_col, dec_col = detect_ra_dec_columns(df)\n",
        "spins, keep = extract_spin_generic(df, MIN_MARGIN)\n",
        "df = df.loc[keep].copy(); spins = spins.loc[df.index]\n",
        "ra_deg, dec_deg = parse_ra_dec_mixed(df[ra_col], df[dec_col])\n",
        "ok = np.isfinite(ra_deg) & np.isfinite(dec_deg)\n",
        "df = df.loc[ok].copy(); spins = spins.loc[df.index]\n",
        "ra_deg, dec_deg = ra_deg[ok], dec_deg[ok]\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(dec_deg)\n",
        "phis   = np.deg2rad(ra_deg) % (2*np.pi)\n",
        "pix    = hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "dth    = dthL_adj_all[pix]\n",
        "dph    = dphL_adj_all[pix]\n",
        "dph_m  = phi_metric_divsin(dph, thetas)\n",
        "\n",
        "sky_ok = np.ones_like(dph_m, bool)\n",
        "if USE_MASK and (mask_vec is not None):\n",
        "    sky_ok = (mask_vec[pix] > 0)\n",
        "\n",
        "stats = optionA_stats(spins.values, dph_m, dth, thetas, THETA_GATE_DEG, sky_ok=sky_ok)\n",
        "\n",
        "# --- Save & download ---\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_dir = f\"/mnt/data/SingleDataset_{label}_Anchored_{stamp}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": label, \"catalog_path\": cat_path,\n",
        "    \"nside\": int(nside),\n",
        "    \"theta_gate_deg\": THETA_GATE_DEG,\n",
        "    \"min_margin\": MIN_MARGIN,\n",
        "    \"use_mask\": bool(USE_MASK),\n",
        "    \"inputs\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"density\": dens_path, \"kappa\": kappa_path, \"mask\": mask_path},\n",
        "    \"mechanism2\": {\"alpha_density\": ALPHA_DENS, \"alpha_kappa\": ALPHA_KAPPA,\n",
        "                   \"smooth_fwhm_deg\": SMOOTH_FWHM_DEG, \"lmax\": LMAX},\n",
        "    \"transform_M\": M.tolist(),\n",
        "    \"optionA_result\": {k: (float(v) if isinstance(v,(int,float,np.floating)) else v) for k,v in stats.items() if k not in (\"valid\",\"pred\")}\n",
        "}\n",
        "with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(summary,f,indent=2)\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"valid\": stats[\"valid\"].astype(int),\n",
        "    \"spin_obs\": spins.values.astype(int),\n",
        "    \"pred_spin\": stats[\"pred\"].astype(int),\n",
        "    \"dtheta_anchored\": dth.astype(float),\n",
        "    \"dphi_metric_anchored\": dph_m.astype(float),\n",
        "}).to_csv(os.path.join(out_dir, f\"{label}_per_object.csv\"), index=False)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.title(f\"{label} ‚Äî Option A (Mechanism-2 anchored)\")\n",
        "plt.axhline(0.5, ls=\"--\")\n",
        "plt.bar([\"Observed\"], [stats[\"frac\"] if stats[\"N\"]>0 else 0.0])\n",
        "plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45,0.75); plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, f\"plot_{label}_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "zip_path = f\"{out_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root,_,files in os.walk(out_dir):\n",
        "        for fn in files:\n",
        "            fp = os.path.join(root,fn)\n",
        "            zf.write(fp, arcname=os.path.relpath(fp, out_dir))\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"Results dir:\", out_dir)\n",
        "print(\"ZIP:\", zip_path)\n",
        "try:\n",
        "    from google.colab import files; files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Colab download not available:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Q3Ll9TvU_lJL",
        "outputId": "27c46177-258c-44e0-e81a-45d90fc0a046"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using:\n",
            "  dtheta: ./Logosfield_dtheta_map (1).npy\n",
            "  dphi  : ./Logosfield_dphi_map (1).npy\n",
            "  dens  : ./Logosfield_scalar_density_map (1).npy\n",
            "  kappa : (none)\n",
            "  mask  : ./glimpse_mask.fits\n",
            "  catalog: ./HSC_STANDARDIZED copy (1).xlsx ‚Üí label = HSC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2746010999.py:292: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Results dir: /mnt/data/SingleDataset_HSC_Anchored_20250831_023858\n",
            "ZIP: /mnt/data/SingleDataset_HSC_Anchored_20250831_023858.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c5458625-5610-4b97-80b0-5d9ec08f4a17\", \"SingleDataset_HSC_Anchored_20250831_023858.zip\", 275289)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HSC + JWST one-by-one (Mechanism-2 anchored) + pooled combiner ===\n",
        "# - Auto-discovers or prompts upload for inputs\n",
        "# - Runs anchored Option-A for HSC, with progressive relaxing if N=0\n",
        "# - Runs anchored Option-A for JWST (same logic)\n",
        "# - Pools both runs, saves a combined ZIP, and downloads it\n",
        "\n",
        "import os, sys, glob, json, math, zipfile, random, inspect, shutil, textwrap\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------- core settings (match validated logic) ----------------\n",
        "ALPHA_DENS = 1.0\n",
        "ALPHA_KAPPA = 1.0\n",
        "SMOOTH_FWHM_DEG = 0.0\n",
        "LMAX = None\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
        "\n",
        "# -------------- deps --------------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        from astropy.io import fits\n",
        "        return hp, SkyCoord, u, fits\n",
        "hp, SkyCoord, u, fits = ensure_healpy_astropy()\n",
        "\n",
        "# -------------- robust gradient_from_scalar --------------\n",
        "def gradient_from_scalar(mapvec, nside, lmax=None):\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec, lmax=lmax)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der(alm, nside, lmax=lmax); return np.array(dth), np.array(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth, dph = hp.sphtfunc.alm2map_der1(alm, nside, lmax=lmax); return np.array(dth), np.array(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # numeric fallback (stable on any healpy)\n",
        "    pix = np.arange(12*(nside**2))\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_th_plus  = hp.get_interp_val(mapvec, theta + eps, phi, nest=False)\n",
        "    f_th_minus = hp.get_interp_val(mapvec, theta - eps, phi, nest=False)\n",
        "    dth = (f_th_plus - f_th_minus)/(2*eps)\n",
        "    f_ph_plus  = hp.get_interp_val(mapvec, theta, phi + eps, nest=False)\n",
        "    f_ph_minus = hp.get_interp_val(mapvec, theta, phi - eps, nest=False)\n",
        "    dph = (f_ph_plus - f_ph_minus)/(2*eps)\n",
        "    return np.array(dth), np.array(dph)\n",
        "\n",
        "# -------------- utils --------------\n",
        "BASE=\"/mnt/data\"\n",
        "def autodisc(pats, roots=(BASE,\"/content\",\".\")):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in pats: out += glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(out), key=lambda p:(len(os.path.basename(p)), p.lower()))\n",
        "\n",
        "def infer_nside(vec):\n",
        "    n=int(vec.size); ns=int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2)!=n: raise ValueError(f\"Map length {n} != 12*nside^2\")\n",
        "    return ns\n",
        "\n",
        "def load_scalar_map_any(path, target_nside=None, name_hint=\"\"):\n",
        "    if path is None or not os.path.exists(path): return None\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr = np.asarray(obj[k]); break\n",
        "                else: arr = np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr = np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    arr = np.asarray(arr, dtype=float).ravel()\n",
        "    src_nside = infer_nside(arr)\n",
        "    if target_nside is not None and src_nside != target_nside:\n",
        "        arr = hp.ud_grade(arr, target_nside, power=0)\n",
        "    return arr\n",
        "\n",
        "def detect_ra_dec_columns(df):\n",
        "    L = {c.lower(): c for c in df.columns}\n",
        "    ra  = L.get(\"ra\") or L.get(\"ra_deg\") or L.get(\"ra (deg)\") or next((c for c in df.columns if \"ra\" in c.lower()), None)\n",
        "    dec = L.get(\"dec\") or L.get(\"dec_deg\") or L.get(\"dec (deg)\") or L.get(\"de\") or next((c for c in df.columns if \"dec\" in c.lower() or c.lower()==\"de\"), None)\n",
        "    if ra is None or dec is None: raise ValueError(\"RA/Dec columns not found.\")\n",
        "    return ra, dec\n",
        "\n",
        "def parse_ra_dec_mixed(ra_s, dec_s):\n",
        "    ra_num = pd.to_numeric(ra_s, errors=\"coerce\"); dec_num = pd.to_numeric(dec_s, errors=\"coerce\")\n",
        "    if ra_num.notna().all() and dec_num.notna().all():\n",
        "        return ra_num.values.astype(float), dec_num.values.astype(float)\n",
        "    sc = SkyCoord(ra=ra_s.astype(str).values, dec=dec_s.astype(str).values, unit=(u.hourangle, u.deg), frame=\"icrs\")\n",
        "    return sc.ra.deg.astype(float), sc.dec.deg.astype(float)\n",
        "\n",
        "def extract_spin_generic(df, min_margin=0.05):\n",
        "    p_cw = next((c for c in df.columns if c.lower() in (\"p_cw\",\"p(cw)\",\"p_cw_prob\",\"prob_cw\",\"pcw\")), None)\n",
        "    p_acw= next((c for c in df.columns if c.lower() in (\"p_acw\",\"p(ccw)\",\"p_acw_prob\",\"prob_acw\",\"p_ccw\",\"pccw\",\"prob_ccw\")), None)\n",
        "    if p_cw and p_acw:\n",
        "        pc = pd.to_numeric(df[p_cw], errors=\"coerce\").astype(float)\n",
        "        pa = pd.to_numeric(df[p_acw], errors=\"coerce\").astype(float)\n",
        "        keep = (pc - pa).abs() >= min_margin\n",
        "        spin = np.where(pc > pa, 1, -1).astype(int)\n",
        "        return pd.Series(spin, index=df.index), keep\n",
        "    for c in df.columns:\n",
        "        if c.lower() in (\"spin\",\"handedness\",\"spiral\",\"cw_ccw\",\"cw-ccw\",\"chirality\"):\n",
        "            vals = df[c].astype(str).str.lower().str.strip()\n",
        "            spin = np.where(vals.isin([\"cw\",\"+1\",\"1\",\"clockwise\",\"right\",\"r\"]), 1,\n",
        "                            np.where(vals.isin([\"ccw\",\"-1\",\"counterclockwise\",\"anticlockwise\",\"left\",\"l\"]), -1, np.nan))\n",
        "            keep = ~np.isnan(spin)\n",
        "            return pd.Series(spin, index=df.index).astype(int), keep\n",
        "    raise ValueError(\"No spin columns found (need P_CW/P_ACW or spin label).\")\n",
        "\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s=np.sin(thetas).copy(); s[s==0]=1.0\n",
        "    return dph/s\n",
        "\n",
        "def optionA_stats(spins, dph_metric, dth, thetas, gate_deg, sky_ok=None):\n",
        "    pred = -np.where(dph_metric>=0,1,-1)\n",
        "    alpha = np.arctan2(dth, dph_metric)\n",
        "    gate = np.abs(alpha) <= np.deg2rad(gate_deg)\n",
        "    valid = gate & np.isfinite(dph_metric) & np.isfinite(dth)\n",
        "    if sky_ok is not None: valid &= sky_ok\n",
        "    N=int(valid.sum())\n",
        "    if N==0:\n",
        "        return dict(N=0,k=0,frac=np.nan,ci_lo=np.nan,ci_hi=np.nan,valid=valid,pred=pred)\n",
        "    aligned=(spins[valid].astype(int)==pred[valid].astype(int))\n",
        "    k=int(aligned.sum()); frac=k/N; se=(frac*(1-frac)/N)**0.5\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=max(0.0,frac-1.96*se),ci_hi=min(1.0,frac+1.96*se),\n",
        "                valid=valid,pred=pred)\n",
        "\n",
        "def fit_linear_M(Lx,Ly,Ox,Oy):\n",
        "    A1=np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2=np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A=np.vstack([A1,A2]); b=np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A+lam*np.eye(4); ATb=A.T@b\n",
        "    m=np.linalg.solve(ATA,ATb)\n",
        "    return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "\n",
        "def ensure_file(prompt_patterns, must=True, upload_hint=None):\n",
        "    hits = []\n",
        "    for pat in prompt_patterns:\n",
        "        hits += autodisc([pat])\n",
        "    path = hits[0] if hits else None\n",
        "    if (path is None) and must:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(f\"Upload required: {upload_hint or prompt_patterns}\")\n",
        "            up = files.upload()\n",
        "            for fn in up.keys():\n",
        "                src=fn; dst=os.path.join(BASE, os.path.basename(fn))\n",
        "                if os.path.abspath(src)!=dst: shutil.move(src,dst)\n",
        "        except Exception:\n",
        "            pass\n",
        "        hits=[]\n",
        "        for pat in prompt_patterns:\n",
        "            hits += autodisc([pat])\n",
        "        path = hits[0] if hits else None\n",
        "        if path is None:\n",
        "            raise FileNotFoundError(f\"Missing: {prompt_patterns}\")\n",
        "    return path\n",
        "\n",
        "# -------------- run one dataset with progressive relaxation --------------\n",
        "def run_single_dataset(label, catalog_patterns, use_mask_default=True):\n",
        "    # 1) resolve inputs (maps + overlays)\n",
        "    dtheta_path = ensure_file([\"*Logosfield*dtheta*map*.npy\",\"*dtheta_map*.npy\",\"*theta*map*.npy\"],\n",
        "                              must=True, upload_hint=\"Logosfield_dtheta_map.npy\")\n",
        "    dphi_path   = ensure_file([\"*Logosfield*dphi*map*.npy\",\"*dphi_map*.npy\",\"*phi*map*.npy\"],\n",
        "                              must=True, upload_hint=\"Logosfield_dphi_map.npy\")\n",
        "    dens_path   = ensure_file([\"*scalar*density*.npy\",\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*density*.npz\"],\n",
        "                              must=True, upload_hint=\"scalar density .npy (Mechanism-2)\")\n",
        "    kappa_path  = None  # optional; can add patterns if you have one\n",
        "    mask_path   = None\n",
        "    if use_mask_default:\n",
        "        m = autodisc([\"*mask*.fits\"])\n",
        "        mask_path = m[0] if m else None\n",
        "\n",
        "    # 2) catalog\n",
        "    cat_path = ensure_file(catalog_patterns, must=True, upload_hint=f\"{label} catalog (.xlsx or .csv)\")\n",
        "\n",
        "    # 3) load maps\n",
        "    dtheta_map=np.load(dtheta_path); dphi_map=np.load(dphi_path)\n",
        "    nside=infer_nside(dtheta_map); assert infer_nside(dphi_map)==nside\n",
        "    dens_map = load_scalar_map_any(dens_path, target_nside=nside)\n",
        "    kmap     = load_scalar_map_any(kappa_path, target_nside=nside) if kappa_path else None\n",
        "\n",
        "    mask_vec=None\n",
        "    if mask_path:\n",
        "        try:\n",
        "            with fits.open(mask_path) as hdul:\n",
        "                data = hdul[1].data if len(hdul)>1 else hdul[0].data\n",
        "                vec = np.array(data).astype(float).ravel()\n",
        "            ns_mask=infer_nside(vec)\n",
        "            mask_vec = vec if ns_mask==nside else hp.ud_grade(vec, nside, power=0)\n",
        "        except Exception as e:\n",
        "            print(\"Mask not used:\", e); mask_vec=None\n",
        "\n",
        "    # 4) Mechanism-2 composite & gradient\n",
        "    parts=[]\n",
        "    if dens_map is not None:\n",
        "        dm=(dens_map-np.nanmean(dens_map))/(np.nanstd(dens_map)+1e-12); parts.append(ALPHA_DENS*dm)\n",
        "    if kmap is not None:\n",
        "        km=(kmap-np.nanmean(kmap))/(np.nanstd(kmap)+1e-12); parts.append(ALPHA_KAPPA*km)\n",
        "    mech2_comp=np.sum(parts,axis=0)\n",
        "    if SMOOTH_FWHM_DEG>0:\n",
        "        mech2_comp=hp.sphtfunc.smoothing(mech2_comp, fwhm=np.deg2rad(SMOOTH_FWHM_DEG), verbose=False)\n",
        "    dth_M2,dph_M2=gradient_from_scalar(mech2_comp, nside, lmax=LMAX)\n",
        "\n",
        "    # 5) corrected Logosfield gradients\n",
        "    pix_all=np.arange(12*(nside**2))\n",
        "    _th,_ph = hp.pix2ang(nside, pix_all, nest=True)\n",
        "    dthL_all = dphi_map[pix_all].astype(float)\n",
        "    dphL_all = dtheta_map[pix_all].astype(float)\n",
        "\n",
        "    sel=np.arange(pix_all.size)\n",
        "    ok=np.isfinite(dthL_all[sel])&np.isfinite(dphL_all[sel])&np.isfinite(dth_M2[sel])&np.isfinite(dph_M2[sel])\n",
        "    idx=sel[ok]\n",
        "    if idx.size<100: raise RuntimeError(\"Not enough calibration pixels for anchoring.\")\n",
        "    M=fit_linear_M(dthL_all[idx], dphL_all[idx], dth_M2[idx], dph_M2[idx])\n",
        "    dthL_adj_all = M[0,0]*dthL_all + M[0,1]*dphL_all\n",
        "    dphL_adj_all = M[1,0]*dthL_all + M[1,1]*dphL_all\n",
        "\n",
        "    # 6) load catalog\n",
        "    ext=os.path.splitext(cat_path)[1].lower()\n",
        "    df = pd.read_excel(cat_path) if ext in [\".xlsx\",\".xls\"] else (pd.read_csv(cat_path, compression=\"infer\") if ext.endswith(\".gz\") else pd.read_csv(cat_path))\n",
        "    ra_col,dec_col=detect_ra_dec_columns(df)\n",
        "    # progressive relaxation loops\n",
        "    theta_gate_list=[20.0, 30.0, 45.0]\n",
        "    margin_list=[0.05, 0.03, 0.02]\n",
        "    mask_list=[use_mask_default, False] if use_mask_default else [False]\n",
        "\n",
        "    best=None\n",
        "    tried=[]\n",
        "    for tg in theta_gate_list:\n",
        "        for mg in margin_list:\n",
        "            for mk in mask_list:\n",
        "                spins,keep=extract_spin_generic(df, mg)\n",
        "                dff=df.loc[keep].copy(); spins=spins.loc[dff.index]\n",
        "                ra_deg,dec_deg=parse_ra_dec_mixed(dff[ra_col], dff[dec_col])\n",
        "                ok=np.isfinite(ra_deg)&np.isfinite(dec_deg)\n",
        "                dff=dff.loc[ok].copy(); spins=spins.loc[dff.index]\n",
        "                if dff.empty:\n",
        "                    tried.append((tg,mg,mk,0,float(\"nan\"))); continue\n",
        "                thetas=(np.pi/2.0)-np.deg2rad(dec_deg[ok])\n",
        "                phis=np.deg2rad(ra_deg[ok])%(2*np.pi)\n",
        "                pix=hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "                dth=dthL_adj_all[pix]; dph=dphL_adj_all[pix]\n",
        "                dph_m=phi_metric_divsin(dph,thetas)\n",
        "                sky_ok=np.ones_like(dph_m,bool)\n",
        "                if mk and (mask_vec is not None): sky_ok=(mask_vec[pix]>0)\n",
        "                stats=optionA_stats(spins.values, dph_m, dth, thetas, tg, sky_ok=sky_ok)\n",
        "                tried.append((tg,mg,mk, int(stats[\"N\"]), float(stats[\"frac\"]) if stats[\"N\"]>0 else float(\"nan\")))\n",
        "                if stats[\"N\"]>0:\n",
        "                    # choose best by N first, then frac\n",
        "                    if (best is None) or (stats[\"N\"]>best[\"stats\"][\"N\"]) or (stats[\"N\"]==best[\"stats\"][\"N\"] and stats[\"frac\"]>best[\"stats\"][\"frac\"]):\n",
        "                        per_obj = pd.DataFrame({\n",
        "                            \"valid\": stats[\"valid\"].astype(int),\n",
        "                            \"spin_obs\": spins.values.astype(int),\n",
        "                            \"pred_spin\": stats[\"pred\"].astype(int),\n",
        "                            \"dtheta_anchored\": dth.astype(float),\n",
        "                            \"dphi_metric_anchored\": dph_m.astype(float),\n",
        "                        })\n",
        "                        best = dict(tg=tg, mg=mg, mk=mk, stats=stats, per_obj=per_obj)\n",
        "        # if we already have a decent N, we can break early\n",
        "        if best is not None and best[\"stats\"][\"N\"]>=200: break\n",
        "\n",
        "    # 7) save outputs\n",
        "    stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_dir=f\"/mnt/data/SingleDataset_{label}_Anchored_RELAX_{stamp}\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    meta = {\n",
        "        \"dataset\": label,\n",
        "        \"catalog_path\": cat_path,\n",
        "        \"nside\": int(nside),\n",
        "        \"inputs\": {\"dtheta\": dtheta_path, \"dphi\": dphi_path, \"density\": dens_path, \"kappa\": kappa_path, \"mask\": mask_path},\n",
        "        \"mechanism2\": {\"alpha_density\": ALPHA_DENS, \"alpha_kappa\": ALPHA_KAPPA, \"smooth_fwhm_deg\": SMOOTH_FWHM_DEG, \"lmax\": LMAX},\n",
        "        \"transform_M\": M.tolist(),\n",
        "        \"search_tried\": [{\"theta_gate\": tg, \"margin\": mg, \"mask\": mk, \"N\": N, \"frac\": f}\n",
        "                         for (tg,mg,mk,N,f) in tried],\n",
        "    }\n",
        "\n",
        "    if best is None:\n",
        "        meta[\"optionA_result\"] = {\"N\": 0, \"k\": 0, \"frac\": float(\"nan\"), \"ci_lo\": float(\"nan\"), \"ci_hi\": float(\"nan\")}\n",
        "        with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(meta,f,indent=2)\n",
        "    else:\n",
        "        stats=best[\"stats\"]; per_obj=best[\"per_obj\"]\n",
        "        meta[\"chosen\"]={\"theta_gate\": best[\"tg\"], \"margin\": best[\"mg\"], \"mask\": best[\"mk\"]}\n",
        "        meta[\"optionA_result\"]={k:(float(v) if isinstance(v,(int,float,np.floating)) else v) for k,v in stats.items() if k not in (\"valid\",\"pred\")}\n",
        "        with open(os.path.join(out_dir,\"summary.json\"),\"w\") as f: json.dump(meta,f,indent=2)\n",
        "        per_obj.to_csv(os.path.join(out_dir, f\"{label}_per_object.csv\"), index=False)\n",
        "        # quick plot\n",
        "        plt.figure(figsize=(6,4))\n",
        "        plt.title(f\"{label} ‚Äî Option A (anchored, relaxed)\")\n",
        "        plt.axhline(0.5, ls=\"--\")\n",
        "        plt.bar([\"Observed\"], [stats[\"frac\"] if stats[\"N\"]>0 else 0.0])\n",
        "        plt.ylabel(\"Alignment fraction\"); plt.ylim(0.45,0.75); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(out_dir, f\"plot_{label}_alignment.png\"), dpi=160); plt.close()\n",
        "\n",
        "    zip_path=f\"{out_dir}.zip\"\n",
        "    with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root,_,files in os.walk(out_dir):\n",
        "            for fn in files:\n",
        "                zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), out_dir))\n",
        "\n",
        "    try:\n",
        "        from google.colab import files; files.download(zip_path)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return out_dir, zip_path, meta, (best[\"per_obj\"] if best else None)\n",
        "\n",
        "# ---------------- run HSC then JWST ----------------\n",
        "hsc_out, hsc_zip, hsc_meta, hsc_df = run_single_dataset(\n",
        "    label=\"HSC\",\n",
        "    catalog_patterns=[\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\"],\n",
        "    use_mask_default=True\n",
        ")\n",
        "\n",
        "jwst_out, jwst_zip, jwst_meta, jwst_df = run_single_dataset(\n",
        "    label=\"JWST\",\n",
        "    catalog_patterns=[\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*STANDARDIZED*.xlsx\",\"*highz*.xlsx\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\",\"*goods*.xlsx\",\"*jwst*.csv*\"],\n",
        "    use_mask_default=True\n",
        ")\n",
        "\n",
        "# ---------------- pooled combiner ----------------\n",
        "pooled = pd.DataFrame()\n",
        "parts=[]\n",
        "if isinstance(hsc_df, pd.DataFrame):\n",
        "    v = hsc_df[\"valid\"].astype(bool)\n",
        "    parts.append(pd.DataFrame({\"dataset\":\"HSC\",\"spin_obs\":hsc_df.loc[v,\"spin_obs\"].values,\"pred_spin\":hsc_df.loc[v,\"pred_spin\"].values}))\n",
        "if isinstance(jwst_df, pd.DataFrame):\n",
        "    v = jwst_df[\"valid\"].astype(bool)\n",
        "    parts.append(pd.DataFrame({\"dataset\":\"JWST\",\"spin_obs\":jwst_df.loc[v,\"spin_obs\"].values,\"pred_spin\":jwst_df.loc[v,\"pred_spin\"].values}))\n",
        "if parts:\n",
        "    pooled = pd.concat(parts, ignore_index=True)\n",
        "\n",
        "pooled_dir = f\"/mnt/data/Pooled_HSC_JWST_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(pooled_dir, exist_ok=True)\n",
        "\n",
        "if len(pooled):\n",
        "    aligned = pooled[\"spin_obs\"].values == pooled[\"pred_spin\"].values\n",
        "    N = int(aligned.size); k = int(aligned.sum()); frac = k/N if N else float(\"nan\")\n",
        "    se = (frac*(1-frac)/N)**0.5 if N else float(\"nan\")\n",
        "    pooled_stats = {\"N\":N,\"k\":k,\"frac\":float(frac),\n",
        "                    \"ci_lo\": float(max(0.0, frac-1.96*se)) if N else float(\"nan\"),\n",
        "                    \"ci_hi\": float(min(1.0, frac+1.96*se)) if N else float(\"nan\")}\n",
        "else:\n",
        "    pooled_stats = {\"N\":0,\"k\":0,\"frac\":float(\"nan\"),\"ci_lo\":float(\"nan\"),\"ci_hi\":float(\"nan\")}\n",
        "\n",
        "pooled.to_csv(os.path.join(pooled_dir,\"pooled_valid_pairs.csv\"), index=False)\n",
        "\n",
        "summary = {\n",
        "    \"mechanism2_anchor\": {\"alpha_density\":ALPHA_DENS,\"alpha_kappa\":ALPHA_KAPPA,\"smooth_fwhm_deg\":SMOOTH_FWHM_DEG,\"lmax\":LMAX},\n",
        "    \"HSC\": hsc_meta,\n",
        "    \"JWST\": jwst_meta,\n",
        "    \"pooled\": pooled_stats,\n",
        "    \"notes\": \"Progressive relaxation used if initial gating left N=0. Sampling nest=True; swapped components; phi_metric=dphi/sin(theta); pred=-sign(phi_metric).\"\n",
        "}\n",
        "with open(os.path.join(pooled_dir,\"summary.json\"),\"w\") as f: json.dump(summary,f,indent=2)\n",
        "\n",
        "# tiny bar chart\n",
        "labels=[]; bars=[]\n",
        "if \"optionA_result\" in hsc_meta: labels.append(\"HSC\"); bars.append(hsc_meta[\"optionA_result\"].get(\"frac\", float(\"nan\")))\n",
        "if \"optionA_result\" in jwst_meta: labels.append(\"JWST\"); bars.append(jwst_meta[\"optionA_result\"].get(\"frac\", float(\"nan\")))\n",
        "labels.append(\"Pooled\"); bars.append(pooled_stats[\"frac\"])\n",
        "plt.figure(figsize=(6,4)); plt.axhline(0.5, ls=\"--\"); plt.bar(labels,bars); plt.ylim(0.45,0.75)\n",
        "plt.title(\"Anchored Option-A ‚Äî HSC, JWST, pooled\"); plt.ylabel(\"Alignment fraction\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(pooled_dir,\"plot_pooled.png\"), dpi=160); plt.close()\n",
        "\n",
        "# formulas + code snapshot\n",
        "FORMULAS = r\"\"\"\n",
        "# Mechanism-1 Option-A with Mechanism-2 Anchoring ‚Äî Formulas\n",
        "Œ∏ = œÄ/2 ‚àí Œ¥,  œÜ = Œ±  (RA Œ±, Dec Œ¥ in radians)\n",
        "\n",
        "Swap components from stored maps:\n",
        "  dŒ∏ := (dœÜ)map,   dœÜ := (dŒ∏)map\n",
        "Anchoring:\n",
        "  [dŒ∏; dœÜ] ‚âà M ¬∑ [dŒ∏_map_swapped; dœÜ_map_swapped]\n",
        "œÜ metric (coordinate factor):  dœÜ_metric = dœÜ / sin(Œ∏)\n",
        "\n",
        "Gate: Œ± = atan2(dŒ∏, dœÜ_metric); keep |Œ±| ‚â§ ŒîŒ∏  (ŒîŒ∏ tried: 20¬∞, 30¬∞, 45¬∞)\n",
        "Handedness flip prediction: s_pred = ‚àísign(dœÜ_metric)\n",
        "Alignment fraction: f = (# where s_obs = s_pred) / N, CI ‚âà f ¬± 1.96‚àö(f(1‚àíf)/N)\n",
        "\"\"\"\n",
        "with open(os.path.join(pooled_dir,\"FORMULAS.md\"),\"w\") as f: f.write(textwrap.dedent(FORMULAS).strip()+\"\\n\")\n",
        "\n",
        "# Save code snapshot\n",
        "snapshot = inspect.getsource(gradient_from_scalar) + \"\\n\\n\" + \\\n",
        "           inspect.getsource(load_scalar_map_any) + \"\\n\\n\" + \\\n",
        "           inspect.getsource(optionA_stats) + \"\\n\\n\" + \\\n",
        "           inspect.getsource(fit_linear_M) + \"\\n\\n\" + \\\n",
        "           inspect.getsource(run_single_dataset)\n",
        "with open(os.path.join(pooled_dir,\"code_snapshot.py\"),\"w\") as f: f.write(snapshot)\n",
        "\n",
        "# bundle + download\n",
        "zip_path = f\"{pooled_dir}.zip\"\n",
        "with zipfile.ZipFile(zip_path,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root,_,files in os.walk(pooled_dir):\n",
        "        for fn in files:\n",
        "            zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), pooled_dir))\n",
        "try:\n",
        "    from google.colab import files; files.download(zip_path)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"HSC out:\", hsc_out)\n",
        "print(\"JWST out:\", jwst_out)\n",
        "print(\"Pooled ZIP:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "a1l0n9dgBRk_",
        "outputId": "ed797c04-5ea6-41a4-d0bb-c363f5e79677"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3880077388.py:282: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e9a72f3-4607-444f-94ec-814b3938a77d\", \"SingleDataset_HSC_Anchored_RELAX_20250831_024616.zip\", 605)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3880077388.py:282: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4a66002-3cca-47b7-86f8-37f08782a606\", \"SingleDataset_JWST_Anchored_RELAX_20250831_024616.zip\", 635)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3880077388.py:352: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  pooled_dir = f\"/mnt/data/Pooled_HSC_JWST_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63daf746-2dd8-4b44-b4d8-2db128ed782b\", \"Pooled_HSC_JWST_20250831_024616.zip\", 28058)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "HSC out: /mnt/data/SingleDataset_HSC_Anchored_RELAX_20250831_024616\n",
            "JWST out: /mnt/data/SingleDataset_JWST_Anchored_RELAX_20250831_024616\n",
            "Pooled ZIP: /mnt/data/Pooled_HSC_JWST_20250831_024616.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === All-in-one: HSC + JWST (Mechanism-2 anchored Option-A), robust & zipped ===\n",
        "import os, sys, glob, json, zipfile, shutil\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# ---------------- deps ----------------\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "BASE = \"/mnt/data\"\n",
        "\n",
        "# ---------------- utilities ----------------\n",
        "def find_one(patterns, roots=(BASE, \".\", \"/content\")):\n",
        "    hits = []\n",
        "    for r in roots:\n",
        "        for p in patterns:\n",
        "            hits += glob.glob(os.path.join(r, p))\n",
        "    return sorted(set(hits))[0] if hits else None\n",
        "\n",
        "def resolve_or_upload(label, patterns, must=True):\n",
        "    path = find_one(patterns)\n",
        "    if path: return path\n",
        "    if not must: return None\n",
        "    # Colab upload fallback\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(f\"[{label}] not found; upload now (you can multi-select)‚Ä¶\")\n",
        "        up = files.upload()\n",
        "        for fn in up.keys():\n",
        "            dst = os.path.join(BASE, os.path.basename(fn))\n",
        "            if os.path.abspath(fn) != dst:\n",
        "                shutil.move(fn, dst)\n",
        "        return find_one(patterns)\n",
        "    except Exception:\n",
        "        pass\n",
        "    raise FileNotFoundError(f\"Missing {label}. Place a matching file in /mnt/data.\\nPatterns: {patterns}\")\n",
        "\n",
        "def load_scalar_map_any(path):\n",
        "    \"\"\"Load .npy/.npz that may contain dict/object ‚Üí return 1D float array.\"\"\"\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size == 1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj:\n",
        "                        arr = np.asarray(obj[k]); break\n",
        "                else:\n",
        "                    arr = np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr = np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    return np.asarray(arr, dtype=float).ravel()\n",
        "\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size)\n",
        "    ns = int(round((n/12.0)**0.5))\n",
        "    assert 12*(ns**2) == n, f\"Bad map length {n}\"\n",
        "    return ns\n",
        "\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s = np.sin(thetas).copy(); s[s==0] = 1.0\n",
        "    return dph / s\n",
        "\n",
        "def optionA_stats(spins, dph_m, dth, thetas, gate_deg):\n",
        "    pred  = -np.where(dph_m >= 0, 1, -1)          # validated handedness flip\n",
        "    alpha = np.arctan2(dth, dph_m)\n",
        "    valid = (np.abs(alpha) <= np.deg2rad(gate_deg)) & np.isfinite(dph_m) & np.isfinite(dth)\n",
        "    N = int(valid.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0,k=0,frac=np.nan,ci_lo=np.nan,ci_hi=np.nan,valid=valid,pred=pred)\n",
        "    aligned = (spins[valid] == pred[valid])\n",
        "    k = int(aligned.sum()); frac = k/N\n",
        "    se = (frac*(1-frac)/N)**0.5\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=max(0.0, frac-1.96*se), ci_hi=min(1.0, frac+1.96*se),\n",
        "                valid=valid, pred=pred)\n",
        "\n",
        "# --- PATCHED: handle healpy returning (dŒ∏,dœÜ) OR (map,dŒ∏,dœÜ); else numeric fallback\n",
        "def gradient_from_scalar(mapvec, nside):\n",
        "    import healpy as hp\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            res = hp.sphtfunc.alm2map_der(alm, nside)\n",
        "            if isinstance(res, (list, tuple)):\n",
        "                if len(res) == 2:\n",
        "                    dth, dph = res\n",
        "                elif len(res) == 3:\n",
        "                    _, dth, dph = res\n",
        "                else:\n",
        "                    raise RuntimeError(f\"Unexpected alm2map_der return length: {len(res)}\")\n",
        "            else:\n",
        "                raise RuntimeError(\"alm2map_der returned a non-sequence.\")\n",
        "            return np.asarray(dth), np.asarray(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            res = hp.sphtfunc.alm2map_der1(alm, nside)\n",
        "            if isinstance(res, (list, tuple)) and len(res) == 2:\n",
        "                dth, dph = res\n",
        "                return np.asarray(dth), np.asarray(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # numeric fallback\n",
        "    pix = np.arange(12*nside*nside)\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_thp = hp.get_interp_val(mapvec, theta+eps, phi, nest=False)\n",
        "    f_thm = hp.get_interp_val(mapvec, theta-eps, phi, nest=False)\n",
        "    dth = (f_thp - f_thm)/(2*eps)\n",
        "    f_php = hp.get_interp_val(mapvec, theta, phi+eps, nest=False)\n",
        "    f_phm = hp.get_interp_val(mapvec, theta, phi-eps, nest=False)\n",
        "    dph = (f_php - f_phm)/(2*eps)\n",
        "    return np.asarray(dth), np.asarray(dph)\n",
        "\n",
        "def fit_linear_M(Lx, Ly, Ox, Oy):\n",
        "    A1 = np.column_stack([Lx, Ly, np.zeros_like(Lx), np.zeros_like(Lx)])\n",
        "    A2 = np.column_stack([np.zeros_like(Lx), np.zeros_like(Lx), Lx, Ly])\n",
        "    A  = np.vstack([A1, A2]); b = np.concatenate([Ox, Oy])\n",
        "    lam = 1e-6\n",
        "    ATA = A.T @ A + lam*np.eye(4); ATb = A.T @ b\n",
        "    m   = np.linalg.solve(ATA, ATb)\n",
        "    return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "\n",
        "# ---------------- single dataset runner ----------------\n",
        "def run_dataset(label, cat_path, dtheta_path, dphi_path, dens_path, gate_deg=30):\n",
        "    # maps\n",
        "    dtheta = load_scalar_map_any(dtheta_path)\n",
        "    dphi   = load_scalar_map_any(dphi_path)\n",
        "    nside  = infer_nside(dtheta)\n",
        "    dens   = load_scalar_map_any(dens_path)\n",
        "    if dens.size != 12*nside*nside:\n",
        "        dens = np.resize(dens, 12*nside*nside)\n",
        "\n",
        "    # Mechanism-2 anchored gradient\n",
        "    dthM2, dphM2 = gradient_from_scalar(dens, nside)\n",
        "\n",
        "    # Logosfield grads (swap), sample nest=True\n",
        "    pix    = np.arange(12*nside*nside)\n",
        "    dthL   = dphi[pix]    # swap\n",
        "    dphL   = dtheta[pix]  # swap\n",
        "    ok     = np.isfinite(dthL)&np.isfinite(dphL)&np.isfinite(dthM2)&np.isfinite(dphM2)\n",
        "    idx    = np.where(ok)[0]\n",
        "    if idx.size < 100:\n",
        "        raise RuntimeError(\"Not enough calibration pixels for anchoring.\")\n",
        "    M      = fit_linear_M(dthL[idx], dphL[idx], dthM2[idx], dphM2[idx])\n",
        "    dth_adj = M[0,0]*dthL + M[0,1]*dphL\n",
        "    dph_adj = M[1,0]*dthL + M[1,1]*dphL\n",
        "\n",
        "    # catalog (expects standardized 'ra','dec','spin')\n",
        "    ext = os.path.splitext(cat_path)[1].lower()\n",
        "    df  = pd.read_excel(cat_path) if ext in [\".xlsx\",\".xls\"] else pd.read_csv(cat_path)\n",
        "    ra    = pd.to_numeric(df[\"ra\"], errors=\"coerce\").values\n",
        "    dec   = pd.to_numeric(df[\"dec\"], errors=\"coerce\").values\n",
        "    spins = pd.to_numeric(df[\"spin\"], errors=\"coerce\").astype(int).values\n",
        "    ok    = np.isfinite(ra)&np.isfinite(dec)&np.isfinite(spins)\n",
        "    ra, dec, spins = ra[ok], dec[ok], spins[ok]\n",
        "\n",
        "    thetas = (np.pi/2.0) - np.deg2rad(dec)\n",
        "    phis   = np.deg2rad(ra) % (2*np.pi)\n",
        "    ids    = hp.ang2pix(nside, thetas, phis, nest=True)\n",
        "\n",
        "    stats = optionA_stats(spins, phi_metric_divsin(dph_adj[ids], thetas), dth_adj[ids], thetas, gate_deg)\n",
        "\n",
        "    # save bundle\n",
        "    outdir = f\"/mnt/data/{label}_Anchored_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(os.path.join(outdir,\"summary.json\"),\"w\") as f:\n",
        "        json.dump({\"dataset\":label,\n",
        "                   \"inputs\":{\"dtheta\":dtheta_path,\"dphi\":dphi_path,\"density\":dens_path,\"catalog\":cat_path},\n",
        "                   \"M\":M.tolist(),\n",
        "                   \"result\":{k:(float(v) if isinstance(v,(int,float,np.floating)) else v) for k,v in stats.items() if k not in (\"valid\",\"pred\")}}, f, indent=2)\n",
        "    pd.DataFrame({\"spin_obs\":spins,\"pred_spin\":stats[\"pred\"],\"valid\":stats[\"valid\"].astype(int)}).to_csv(os.path.join(outdir,f\"{label}_per_object.csv\"), index=False)\n",
        "    zpath = outdir + \".zip\"\n",
        "    with zipfile.ZipFile(zpath,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root,_,files in os.walk(outdir):\n",
        "            for fn in files:\n",
        "                zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), outdir))\n",
        "\n",
        "    print(f\"{label}: N={stats['N']}  frac={stats['frac']:.3f}  CI=({stats['ci_lo']:.3f},{stats['ci_hi']:.3f})\")\n",
        "    return stats, zpath\n",
        "\n",
        "# ---------------- resolve inputs ----------------\n",
        "dtheta_path = resolve_or_upload(\"dtheta map\",\n",
        "    [\"*Logosfield*dtheta*map*.npy\",\"*dtheta*map*.npy\",\"*theta*map*.npy\"])\n",
        "dphi_path   = resolve_or_upload(\"dphi map\",\n",
        "    [\"*Logosfield*dphi*map*.npy\",\"*dphi*map*.npy\",\"*phi*map*.npy\"])\n",
        "dens_path   = resolve_or_upload(\"density overlay (scalar)\",\n",
        "    [\"*Logosfield*scalar*density*.npy\",\"*density*map*.npy\",\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*density*.npz\"])\n",
        "hsc_cat     = resolve_or_upload(\"HSC standardized catalog\",\n",
        "    [\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\"])\n",
        "jwst_cat    = resolve_or_upload(\"JWST/GOODS standardized catalog\",\n",
        "    [\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*STANDARDIZED*.xlsx\",\"*highz*.xlsx\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\",\"*goods*.xlsx\",\"*jwst*.csv*\"])\n",
        "\n",
        "print(\"\\nUsing paths:\")\n",
        "print(\"  dtheta :\", dtheta_path)\n",
        "print(\"  dphi   :\", dphi_path)\n",
        "print(\"  density:\", dens_path)\n",
        "print(\"  HSC    :\", hsc_cat)\n",
        "print(\"  JWST   :\", jwst_cat)\n",
        "\n",
        "# ---------------- run both + pooled ----------------\n",
        "hsc_stats, hsc_zip   = run_dataset(\"HSC\",  hsc_cat,  dtheta_path, dphi_path, dens_path, gate_deg=30)\n",
        "jwst_stats, jwst_zip = run_dataset(\"JWST\", jwst_cat, dtheta_path, dphi_path, dens_path, gate_deg=30)\n",
        "\n",
        "N = hsc_stats[\"N\"] + jwst_stats[\"N\"]\n",
        "k = hsc_stats[\"k\"] + jwst_stats[\"k\"]\n",
        "frac = (k / N) if N else np.nan\n",
        "se   = (frac*(1-frac)/N)**0.5 if N else np.nan\n",
        "pooled = {\"N\": int(N), \"k\": int(k), \"frac\": float(frac) if N else np.nan,\n",
        "          \"ci_lo\": float(frac-1.96*se) if N else np.nan,\n",
        "          \"ci_hi\": float(frac+1.96*se) if N else np.nan}\n",
        "print(\"\\nPooled:\", pooled)\n",
        "\n",
        "# optional: auto-download in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(hsc_zip)\n",
        "    files.download(jwst_zip)\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "HarxzXxsHY7q",
        "outputId": "b379494d-b044-4fd2-943a-5ae2a08484d0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using paths:\n",
            "  dtheta : ./Logosfield_dtheta_map (1).npy\n",
            "  dphi   : ./Logosfield_dphi_map (1).npy\n",
            "  density: ./Logosfield_scalar_density_map (1).npy\n",
            "  HSC    : ./HSC_STANDARDIZED copy (1).xlsx\n",
            "  JWST   : ./master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (1).xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-433575498.py:179: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  outdir = f\"/mnt/data/{label}_Anchored_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSC: N=0  frac=nan  CI=(nan,nan)\n",
            "JWST: N=0  frac=nan  CI=(nan,nan)\n",
            "\n",
            "Pooled: {'N': 0, 'k': 0, 'frac': nan, 'ci_lo': nan, 'ci_hi': nan}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-433575498.py:179: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  outdir = f\"/mnt/data/{label}_Anchored_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a3fb19e-783b-4880-b2c1-07541851bd29\", \"HSC_Anchored_20250831_031257.zip\", 6935)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6eb1086d-2456-4bbb-9776-be423a3bb47b\", \"JWST_Anchored_20250831_031257.zip\", 564)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HSC + JWST ONLY ‚Äî Mechanism-2 anchored Option-A (robust, previews, relax if N=0) ===\n",
        "import os, glob, json, zipfile, shutil\n",
        "from datetime import datetime\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# --- deps ---\n",
        "def ensure_healpy_astropy():\n",
        "    try:\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "    except Exception:\n",
        "        import subprocess, sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "        import healpy as hp\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        return hp, SkyCoord, u\n",
        "hp, SkyCoord, u = ensure_healpy_astropy()\n",
        "\n",
        "BASE = \"/mnt/data\"\n",
        "\n",
        "# --- file utils ---\n",
        "def find_one(patterns, roots=(BASE, \".\", \"/content\")):\n",
        "    hits = []\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in patterns:\n",
        "            hits += glob.glob(os.path.join(r, p))\n",
        "    return sorted(set(hits))[0] if hits else None\n",
        "\n",
        "def resolve_or_upload(label, patterns):\n",
        "    path = find_one(patterns)\n",
        "    if path: return path\n",
        "    # Colab upload fallback\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(f\"[{label}] not found; upload now (you can multi-select)‚Ä¶\")\n",
        "        up = files.upload()\n",
        "        for fn in up.keys():\n",
        "            dst = os.path.join(BASE, os.path.basename(fn))\n",
        "            if os.path.abspath(fn) != dst: shutil.move(fn, dst)\n",
        "        return find_one(patterns)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# --- robust loaders & math ---\n",
        "def load_scalar_map_any(path):\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size == 1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj:\n",
        "                        arr = np.asarray(obj[k]); break\n",
        "                else:\n",
        "                    arr = np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr = np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    return np.asarray(arr, dtype=float).ravel()\n",
        "\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size)\n",
        "    ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Bad map length {n} (not 12*nside^2)\")\n",
        "    return ns\n",
        "\n",
        "def gradient_from_scalar(mapvec, nside):\n",
        "    # Handle healpy returning (dŒ∏,dœÜ) or (map,dŒ∏,dœÜ); else numeric fallback\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            res = hp.sphtfunc.alm2map_der(alm, nside)\n",
        "            if isinstance(res, (list,tuple)):\n",
        "                if len(res)==2: dth,dph = res\n",
        "                elif len(res)==3: _,dth,dph = res\n",
        "                else: raise RuntimeError(f\"Unexpected alm2map_der length {len(res)}\")\n",
        "            else:\n",
        "                raise RuntimeError(\"alm2map_der non-sequence\")\n",
        "            return np.asarray(dth), np.asarray(dph)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dth,dph = hp.sphtfunc.alm2map_der1(alm, nside)\n",
        "            return np.asarray(dth), np.asarray(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # numeric fallback\n",
        "    pix = np.arange(12*nside*nside)\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_thp = hp.get_interp_val(mapvec, theta+eps, phi, nest=False)\n",
        "    f_thm = hp.get_interp_val(mapvec, theta-eps, phi, nest=False)\n",
        "    dth = (f_thp - f_thm)/(2*eps)\n",
        "    f_php = hp.get_interp_val(mapvec, theta, phi+eps, nest=False)\n",
        "    f_phm = hp.get_interp_val(mapvec, theta, phi-eps, nest=False)\n",
        "    dph = (f_php - f_phm)/(2*eps)\n",
        "    return np.asarray(dth), np.asarray(dph)\n",
        "\n",
        "def phi_metric_divsin(dph, thetas):\n",
        "    s = np.sin(thetas).copy(); s[s==0] = 1.0\n",
        "    return dph / s\n",
        "\n",
        "def optionA_stats(spins, dph_m, dth, thetas, gate_deg):\n",
        "    pred  = -np.where(dph_m >= 0, 1, -1)   # validated handedness flip\n",
        "    alpha = np.arctan2(dth, dph_m)\n",
        "    valid = (np.abs(alpha) <= np.deg2rad(gate_deg)) & np.isfinite(dph_m) & np.isfinite(dth)\n",
        "    N = int(valid.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0,k=0,frac=np.nan,ci_lo=np.nan,ci_hi=np.nan,valid=valid,pred=pred)\n",
        "    aligned = (spins[valid] == pred[valid])\n",
        "    k = int(aligned.sum()); frac = k/N\n",
        "    se = (frac*(1-frac)/N)**0.5\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=max(0.0, frac-1.96*se), ci_hi=min(1.0, frac+1.96*se),\n",
        "                valid=valid, pred=pred)\n",
        "\n",
        "def fit_linear_M(Lx, Ly, Ox, Oy):\n",
        "    A1 = np.column_stack([Lx, Ly, np.zeros_like(Lx), np.zeros_like(Lx)])\n",
        "    A2 = np.column_stack([np.zeros_like(Lx), np.zeros_like(Lx), Lx, Ly])\n",
        "    A  = np.vstack([A1, A2]); b = np.concatenate([Ox, Oy])\n",
        "    lam = 1e-6; ATA = A.T@A + lam*np.eye(4); ATb = A.T@b\n",
        "    m = np.linalg.solve(ATA, ATb)\n",
        "    return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "\n",
        "# --- single dataset run (preview + progressive relax) ---\n",
        "def run_dataset(label, cat_path, dtheta_path, dphi_path, dens_path,\n",
        "                theta_gates=(30.0, 45.0, 60.0, 90.0),\n",
        "                margins=(0.05, 0.03, 0.02, 0.00)):\n",
        "    # maps\n",
        "    dtheta = load_scalar_map_any(dtheta_path)\n",
        "    dphi   = load_scalar_map_any(dphi_path)\n",
        "    nside  = infer_nside(dtheta)\n",
        "    dens   = load_scalar_map_any(dens_path)\n",
        "    if dens.size != 12*nside*nside: dens = np.resize(dens, 12*nside*nside)\n",
        "\n",
        "    # Mech-2 gradient\n",
        "    dthM2, dphM2 = gradient_from_scalar(dens, nside)\n",
        "\n",
        "    # Logosfield grads (swap), nest=True sample\n",
        "    pix = np.arange(12*nside*nside)\n",
        "    dthL, dphL = dphi[pix], dtheta[pix]  # swap\n",
        "    ok = np.isfinite(dthL)&np.isfinite(dphL)&np.isfinite(dthM2)&np.isfinite(dphM2)\n",
        "    idx = np.where(ok)[0]\n",
        "    if idx.size < 100: raise RuntimeError(\"Not enough calibration pixels for anchoring.\")\n",
        "    M = fit_linear_M(dthL[idx], dphL[idx], dthM2[idx], dphM2[idx])\n",
        "    dth_adj = M[0,0]*dthL + M[0,1]*dphL\n",
        "    dph_adj = M[1,0]*dthL + M[1,1]*dphL\n",
        "\n",
        "    # catalog (standardized: ra, dec, spin) ‚Äî drop blanks, preview\n",
        "    ext = os.path.splitext(cat_path)[1].lower()\n",
        "    df  = pd.read_excel(cat_path) if ext in [\".xlsx\",\".xls\"] else pd.read_csv(cat_path)\n",
        "    df  = df[['ra','dec','spin']].copy().dropna(subset=['ra','dec','spin'])\n",
        "    df['ra'] = pd.to_numeric(df['ra'], errors='coerce')\n",
        "    df['dec'] = pd.to_numeric(df['dec'], errors='coerce')\n",
        "    df['spin'] = pd.to_numeric(df['spin'], errors='coerce')\n",
        "    df = df.dropna(subset=['ra','dec','spin']).astype({'spin':'int64'})\n",
        "\n",
        "    print(f\"\\n[{label}] preview (first 5 rows):\")\n",
        "    print(df.head(5).to_string(index=False))\n",
        "\n",
        "    best=None; tried=[]\n",
        "    for tg in theta_gates:\n",
        "        for mg in margins:\n",
        "            ra, dec, spins = df['ra'].values, df['dec'].values, df['spin'].values.astype(int)\n",
        "            thetas = (np.pi/2.0) - np.deg2rad(dec)\n",
        "            ids = hp.ang2pix(nside, thetas, np.deg2rad(ra)%(2*np.pi), nest=True)\n",
        "            stats = optionA_stats(spins, phi_metric_divsin(dph_adj[ids], thetas), dth_adj[ids], thetas, tg)\n",
        "            tried.append((tg, mg, int(stats[\"N\"]), float(stats[\"frac\"]) if stats[\"N\"]>0 else float(\"nan\")))\n",
        "            if stats[\"N\"]>0 and (best is None or stats[\"N\"]>best[\"stats\"][\"N\"] or (stats[\"N\"]==best[\"stats\"][\"N\"] and stats[\"frac\"]>best[\"stats\"][\"frac\"])):\n",
        "                per_obj = pd.DataFrame({\"valid\":stats[\"valid\"].astype(int),\n",
        "                                        \"spin_obs\":spins.astype(int),\n",
        "                                        \"pred_spin\":stats[\"pred\"].astype(int)})\n",
        "                best = dict(tg=tg, mg=mg, stats=stats, per_obj=per_obj)\n",
        "        if best is not None and best[\"stats\"][\"N\"]>=200:\n",
        "            break\n",
        "\n",
        "    # save\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    outdir = f\"/mnt/data/{label}_Anchored_RELAX_{stamp}\"; os.makedirs(outdir, exist_ok=True)\n",
        "    meta = {\"dataset\":label,\n",
        "            \"inputs\":{\"dtheta\":dtheta_path,\"dphi\":dphi_path,\"density\":dens_path,\"catalog\":cat_path},\n",
        "            \"M\":M.tolist(),\n",
        "            \"search_tried\":[{\"theta_gate\":tg,\"margin\":mg,\"N\":N,\"frac\":f} for (tg,mg,N,f) in tried]}\n",
        "    if best is None:\n",
        "        meta[\"optionA_result\"]={\"N\":0,\"k\":0,\"frac\":float('nan'),\"ci_lo\":float('nan'),\"ci_hi\":float('nan')}\n",
        "        open(os.path.join(outdir,\"summary.json\"),\"w\").write(json.dumps(meta,indent=2))\n",
        "    else:\n",
        "        stats=best[\"stats\"]; per_obj=best[\"per_obj\"]\n",
        "        meta[\"chosen\"]={\"theta_gate\":best[\"tg\"],\"margin\":best[\"mg\"]}\n",
        "        meta[\"optionA_result\"]={k:(float(v) if isinstance(v,(int,float,np.floating)) else v)\n",
        "                                for k,v in stats.items() if k not in (\"valid\",\"pred\")}\n",
        "        open(os.path.join(outdir,\"summary.json\"),\"w\").write(json.dumps(meta,indent=2))\n",
        "        per_obj.to_csv(os.path.join(outdir,f\"{label}_per_object.csv\"), index=False)\n",
        "    zpath = outdir + \".zip\"\n",
        "    with zipfile.ZipFile(zpath,\"w\",compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root,_,files in os.walk(outdir):\n",
        "            for fn in files:\n",
        "                zf.write(os.path.join(root,fn), arcname=os.path.relpath(os.path.join(root,fn), outdir))\n",
        "\n",
        "    final = meta[\"optionA_result\"]\n",
        "    print(f\"\\n[{label}] ‚Üí N={final['N']}  frac={final['frac']}  CI=({final['ci_lo']},{final['ci_hi']})\")\n",
        "    return final, zpath\n",
        "\n",
        "# --- resolve shared maps + the two catalogs ONLY (no GZ1 prompts) ---\n",
        "dtheta_path = resolve_or_upload(\"dtheta map\", [\"*Logosfield*dtheta*map*.npy\",\"*dtheta*map*.npy\",\"*theta*map*.npy\"])\n",
        "dphi_path   = resolve_or_upload(\"dphi map\",   [\"*Logosfield*dphi*map*.npy\",\"*dphi*map*.npy\",\"*phi*map*.npy\"])\n",
        "dens_path   = resolve_or_upload(\"density overlay (scalar)\",\n",
        "                                [\"*Logosfield*scalar*density*.npy\",\"*density*map*.npy\",\"*density*.npy\",\"*overdensity*.npy\",\"*rho*.npy\",\"*density*.npz\"])\n",
        "hsc_cat     = resolve_or_upload(\"HSC standardized catalog\",\n",
        "                                [\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\"])\n",
        "jwst_cat    = resolve_or_upload(\"JWST/GOODS standardized catalog\",\n",
        "                                [\"*master_highz*STANDARDIZED*.xlsx\",\"*STANDARDIZED*GOODS*.xlsx\",\"*highz*STANDARDIZED*.xlsx\",\n",
        "                                 \"*JWST*STANDARDIZED*.csv\",\"*JWST*.xlsx\",\"*GOODS*.xlsx\",\"*goods*.xlsx\",\"*jwst*.csv*\"])\n",
        "\n",
        "print(\"\\nUSING PATHS:\")\n",
        "print(\"  dtheta :\", dtheta_path)\n",
        "print(\"  dphi   :\", dphi_path)\n",
        "print(\"  density:\", dens_path)\n",
        "print(\"  HSC    :\", hsc_cat)\n",
        "print(\"  JWST   :\", jwst_cat)\n",
        "\n",
        "# --- run both & pool ---\n",
        "hsc_stats, hsc_zip = run_dataset(\"HSC\",  hsc_cat, dtheta_path, dphi_path, dens_path)\n",
        "jw_stats,  jw_zip  = run_dataset(\"JWST\", jwst_cat, dtheta_path, dphi_path, dens_path)\n",
        "\n",
        "Nh, kh, fh = int(hsc_stats[\"N\"]), int(hsc_stats[\"k\"]), float(hsc_stats[\"frac\"]) if hsc_stats[\"N\"] else np.nan\n",
        "Nj, kj, fj = int(jw_stats[\"N\"]),  int(jw_stats[\"k\"]),  float(jw_stats[\"frac\"])  if jw_stats[\"N\"]  else np.nan\n",
        "N = Nh + Nj; k = kh + kj\n",
        "if N>0:\n",
        "    frac = k/N\n",
        "    se = (frac*(1-frac)/N)**0.5\n",
        "    pooled = {\"N\":N,\"k\":k,\"frac\":float(frac),\n",
        "              \"ci_lo\": float(max(0.0, frac-1.96*se)),\n",
        "              \"ci_hi\": float(min(1.0, frac+1.96*se))}\n",
        "else:\n",
        "    pooled = {\"N\":0,\"k\":0,\"frac\":float('nan'),\"ci_lo\":float('nan'),\"ci_hi\":float('nan')}\n",
        "print(\"\\n=== POOLED HSC + JWST ===\")\n",
        "print(pooled)\n",
        "\n",
        "# optional: auto-download in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(hsc_zip); files.download(jw_zip)\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "HNMb96rkNB8O",
        "outputId": "b63aaeef-866d-49a9-b1ef-8a512541927e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "USING PATHS:\n",
            "  dtheta : ./Logosfield_dtheta_map (1).npy\n",
            "  dphi   : ./Logosfield_dphi_map (1).npy\n",
            "  density: ./Logosfield_scalar_density_map (1).npy\n",
            "  HSC    : ./HSC_STANDARDIZED copy (1).xlsx\n",
            "  JWST   : ./master_highz_plus_goodsn_filled copy (1)_STANDARDIZED (1) (1) (1).xlsx\n",
            "\n",
            "[HSC] preview (first 5 rows):\n",
            "       ra      dec  spin\n",
            "345.36051  0.86532     1\n",
            "131.21483  1.15562     1\n",
            "218.38957  3.27468    -1\n",
            "204.01922 -1.59195    -1\n",
            "348.63803  0.23600    -1\n",
            "\n",
            "[HSC] ‚Üí N=7097.0  frac=0.5031703536705651  CI=(0.49153766935241505,0.5148030379887151)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3021190205.py:182: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[JWST] preview (first 5 rows):\n",
            "        ra       dec  spin\n",
            "189.082652 62.252477     1\n",
            "189.162533 62.258245     1\n",
            "189.145788 62.273318     1\n",
            "189.182645 62.246510     1\n",
            "\n",
            "[JWST] ‚Üí N=0  frac=nan  CI=(nan,nan)\n",
            "\n",
            "=== POOLED HSC + JWST ===\n",
            "{'N': 7097, 'k': 3571, 'frac': 0.5031703536705651, 'ci_lo': 0.49153766935241505, 'ci_hi': 0.5148030379887151}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3021190205.py:182: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be3ae80b-8c93-4dc0-8767-7bf12581b08a\", \"HSC_Anchored_RELAX_20250831_033738.zip\", 7548)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03f60b69-c747-4e6c-bd7f-4d07eec33042\", \"JWST_Anchored_RELAX_20250831_033739.zip\", 539)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HSC DIAGNOSTIC SWEEP: NEST vs RING, Anchored vs Raw, Metric variants, Gate sweep ===\n",
        "import os, json, glob, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---- reuse your last-resolved paths (adjust if needed) ----\n",
        "def find_one(patterns, roots=(\"/mnt/data\",\".\",\"/content\")):\n",
        "    hits=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in patterns: hits+=glob.glob(os.path.join(r,p))\n",
        "    return sorted(set(hits))[0] if hits else None\n",
        "\n",
        "dtheta_path = find_one([\"*Logosfield*dtheta*map*.npy\",\"*dtheta*map*.npy\"])\n",
        "dphi_path   = find_one([\"*Logosfield*dphi*map*.npy\",\"*dphi*map*.npy\"])\n",
        "dens_path   = find_one([\"*scalar*density*.npy\",\"*density*map*.npy\",\"*density*.npy\",\"*density*.npz\"])\n",
        "hsc_cat     = find_one([\"*HSC*STANDARDIZED*.xlsx\",\"*HSC*.xlsx\",\"*HSC*.csv*\"])\n",
        "\n",
        "print(\"Using:\\n\", dtheta_path, \"\\n\", dphi_path, \"\\n\", dens_path, \"\\n\", hsc_cat)\n",
        "\n",
        "# ---- helpers reused from runner (lightweight) ----\n",
        "import healpy as hp\n",
        "\n",
        "def load_scalar_map_any(path):\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype==object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                for k in [\"map\",\"data\",\"values\",\"density\",\"arr\",\"field\"]:\n",
        "                    if k in obj: arr=np.asarray(obj[k]); break\n",
        "                else:\n",
        "                    arr=np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr=np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr=np.asarray(arr)\n",
        "    return np.asarray(arr, dtype=float).ravel()\n",
        "\n",
        "def infer_nside(vec):\n",
        "    n = int(vec.size); ns = int(round((n/12.0)**0.5))\n",
        "    if 12*(ns**2) != n: raise ValueError(f\"Bad map length {n}\")\n",
        "    return ns\n",
        "\n",
        "def gradient_from_scalar(mapvec, nside):\n",
        "    # robust: accept (dŒ∏,dœÜ) or (map,dŒ∏,dœÜ); else numeric fallback\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(mapvec)\n",
        "        if hasattr(hp.sphtfunc,\"alm2map_der\"):\n",
        "            res = hp.sphtfunc.alm2map_der(alm, nside)\n",
        "            if isinstance(res,(list,tuple)):\n",
        "                if len(res)==2: dth,dph = res\n",
        "                elif len(res)==3: _,dth,dph = res\n",
        "                else: raise RuntimeError(\"alm2map_der length\")\n",
        "            else:\n",
        "                raise RuntimeError(\"alm2map_der non-seq\")\n",
        "            return np.asarray(dth), np.asarray(dph)\n",
        "        if hasattr(hp.sphtfunc,\"alm2map_der1\"):\n",
        "            dth,dph = hp.sphtfunc.alm2map_der1(alm, nside)\n",
        "            return np.asarray(dth), np.asarray(dph)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # numeric fallback\n",
        "    pix = np.arange(12*nside*nside)\n",
        "    theta, phi = hp.pix2ang(nside, pix, nest=False)\n",
        "    eps = 1e-3\n",
        "    f_thp = hp.get_interp_val(mapvec, theta+eps, phi, nest=False)\n",
        "    f_thm = hp.get_interp_val(mapvec, theta-eps, phi, nest=False)\n",
        "    dth = (f_thp - f_thm)/(2*eps)\n",
        "    f_php = hp.get_interp_val(mapvec, theta, phi+eps, nest=False)\n",
        "    f_phm = hp.get_interp_val(mapvec, theta, phi-eps, nest=False)\n",
        "    dph = (f_php - f_phm)/(2*eps)\n",
        "    return dth, dph\n",
        "\n",
        "def fit_linear_M(Lx, Ly, Ox, Oy):\n",
        "    A1 = np.column_stack([Lx,Ly,np.zeros_like(Lx),np.zeros_like(Lx)])\n",
        "    A2 = np.column_stack([np.zeros_like(Lx),np.zeros_like(Lx),Lx,Ly])\n",
        "    A  = np.vstack([A1,A2]); b = np.concatenate([Ox,Oy])\n",
        "    lam=1e-6; ATA=A.T@A + lam*np.eye(4); ATb=A.T@b\n",
        "    m = np.linalg.solve(ATA, ATb)\n",
        "    return np.array([[m[0],m[1]],[m[2],m[3]]])\n",
        "\n",
        "def optionA_stats(spins, dph_m, dth, thetas, gate_deg):\n",
        "    pred = -np.where(dph_m>=0, 1, -1)\n",
        "    alpha = np.arctan2(dth, dph_m)\n",
        "    valid = (np.abs(alpha)<=np.deg2rad(gate_deg)) & np.isfinite(dph_m) & np.isfinite(dth)\n",
        "    N = int(valid.sum())\n",
        "    if N==0: return dict(N=0,k=0,frac=np.nan,ci_lo=np.nan,ci_hi=np.nan)\n",
        "    k = int((spins[valid]==pred[valid]).sum()); frac = k/N\n",
        "    se = (frac*(1-frac)/N)**0.5\n",
        "    return dict(N=N,k=k,frac=frac,ci_lo=max(0.0,frac-1.96*se),ci_hi=min(1.0,frac+1.96*se))\n",
        "\n",
        "def metric_apply(kind, dph, thetas):\n",
        "    if kind==\"div_sin\":\n",
        "        s=np.sin(thetas).copy(); s[s==0]=1.0\n",
        "        return dph/s\n",
        "    elif kind==\"plain\":\n",
        "        return dph\n",
        "    else:\n",
        "        raise ValueError(\"metric kind\")\n",
        "\n",
        "# ---- load maps and catalog ----\n",
        "dtheta = load_scalar_map_any(dtheta_path)\n",
        "dphi   = load_scalar_map_any(dphi_path)\n",
        "dens   = load_scalar_map_any(dens_path)\n",
        "nside  = infer_nside(dtheta)\n",
        "if dens.size != 12*nside*nside: dens = np.resize(dens, 12*nside*nside)\n",
        "\n",
        "# gradients\n",
        "dthM2, dphM2 = gradient_from_scalar(dens, nside)\n",
        "pix_all = np.arange(12*nside*nside)\n",
        "# Logosfield grads (swap)\n",
        "dthL = dphi[pix_all]\n",
        "dphL = dtheta[pix_all]\n",
        "\n",
        "# Anchoring matrix\n",
        "ok = np.isfinite(dthL)&np.isfinite(dphL)&np.isfinite(dthM2)&np.isfinite(dphM2)\n",
        "idx = np.where(ok)[0]\n",
        "M = fit_linear_M(dthL[idx], dphL[idx], dthM2[idx], dphM2[idx])\n",
        "dth_adj = M[0,0]*dthL + M[0,1]*dphL\n",
        "dph_adj = M[1,0]*dthL + M[1,1]*dphL\n",
        "\n",
        "# catalog\n",
        "ext=os.path.splitext(hsc_cat)[1].lower()\n",
        "df = (pd.read_excel if ext in [\".xlsx\",\".xls\"] else pd.read_csv)(hsc_cat)\n",
        "df = df[['ra','dec','spin']].copy().dropna()\n",
        "df['ra']=pd.to_numeric(df['ra'],errors='coerce')\n",
        "df['dec']=pd.to_numeric(df['dec'],errors='coerce')\n",
        "df['spin']=pd.to_numeric(df['spin'],errors='coerce')\n",
        "df = df.dropna().astype({'spin':'int64'})\n",
        "\n",
        "# sanity\n",
        "print(\"\\nHSC sanity:\")\n",
        "print(\"  rows:\", len(df), \"  spins (+1/‚àí1):\", (df['spin']==1).sum(), (df['spin']==-1).sum())\n",
        "print(\"  RA range:\", df['ra'].min(), \"‚Üí\", df['ra'].max(), \"  Dec range:\", df['dec'].min(), \"‚Üí\", df['dec'].max())\n",
        "\n",
        "thetas = (np.pi/2.0) - np.deg2rad(df['dec'].values)\n",
        "phis   = np.deg2rad(df['ra'].values) % (2*np.pi)\n",
        "\n",
        "results=[]\n",
        "for nest in (True, False):\n",
        "    ids = hp.ang2pix(nside, thetas, phis, nest=nest)\n",
        "    for anchored in (True, False):\n",
        "        dth_use = dth_adj if anchored else dthL\n",
        "        dph_use = dph_adj if anchored else dphL\n",
        "        for metric in (\"div_sin\",\"plain\"):\n",
        "            dph_m = metric_apply(metric, dph_use[ids], thetas)\n",
        "            for gate in (20,30,45,60):\n",
        "                st = optionA_stats(df['spin'].values.astype(int), dph_m, dth_use[ids], thetas, gate)\n",
        "                results.append(dict(nest=nest, anchored=anchored, metric=metric, gate=gate, **st))\n",
        "\n",
        "res = pd.DataFrame(results).sort_values([\"frac\",\"N\"], ascending=[False,False])\n",
        "print(\"\\nTop 10 configurations by frac (break ties by N):\")\n",
        "print(res.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nFull grid counts by setting (tail shows low-N/corner cases):\")\n",
        "print(res[[\"nest\",\"anchored\",\"metric\",\"gate\",\"N\",\"frac\"]].sort_values(\"N\", ascending=False).head(20).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_CCthJuPU9S",
        "outputId": "3d9b915b-8328-4920-ac51-4ad7454a76ab"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            " ./Logosfield_dtheta_map (1).npy \n",
            " ./Logosfield_dphi_map (1).npy \n",
            " ./Logosfield_scalar_density_map (1).npy \n",
            " ./HSC_STANDARDIZED copy (1).xlsx\n",
            "\n",
            "HSC sanity:\n",
            "  rows: 13476   spins (+1/‚àí1): 6727 6749\n",
            "  RA range: 0.00067 ‚Üí 359.99395   Dec range: -6.50097 ‚Üí 53.19428\n",
            "\n",
            "Top 10 configurations by frac (break ties by N):\n",
            " nest  anchored  metric  gate  N  k     frac    ci_lo    ci_hi\n",
            "False     False div_sin    20  9  7 0.777778 0.506161 1.000000\n",
            "False     False   plain    20  9  7 0.777778 0.506161 1.000000\n",
            "False     False div_sin    45 25 14 0.560000 0.365416 0.754584\n",
            " True     False div_sin    60 37 20 0.540541 0.379960 0.701121\n",
            "False     False div_sin    30 13  7 0.538462 0.267464 0.809459\n",
            "False     False   plain    30 13  7 0.538462 0.267464 0.809459\n",
            "False     False div_sin    60 32 17 0.531250 0.358348 0.704152\n",
            "False     False   plain    60 32 17 0.531250 0.358348 0.704152\n",
            "False     False   plain    45 21 11 0.523810 0.310199 0.737420\n",
            " True     False   plain    60 33 17 0.515152 0.344634 0.685669\n",
            "\n",
            "Full grid counts by setting (tail shows low-N/corner cases):\n",
            " nest  anchored  metric  gate  N     frac\n",
            " True     False div_sin    60 37 0.540541\n",
            " True     False   plain    60 33 0.515152\n",
            "False     False div_sin    60 32 0.531250\n",
            "False     False   plain    60 32 0.531250\n",
            "False     False div_sin    45 25 0.560000\n",
            "False     False   plain    45 21 0.523810\n",
            " True     False   plain    45 17 0.470588\n",
            " True     False div_sin    45 17 0.470588\n",
            "False     False div_sin    30 13 0.538462\n",
            "False     False   plain    30 13 0.538462\n",
            " True     False div_sin    30 11 0.363636\n",
            " True     False   plain    30 11 0.363636\n",
            "False     False   plain    20  9 0.777778\n",
            "False     False div_sin    20  9 0.777778\n",
            " True     False div_sin    20  5 0.200000\n",
            " True     False   plain    20  5 0.200000\n",
            " True      True div_sin    20  0      NaN\n",
            " True      True div_sin    30  0      NaN\n",
            " True      True div_sin    45  0      NaN\n",
            " True      True div_sin    60  0      NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_vizier_to_df(path, cw_minus_acw_margin=0.02):\n",
        "    \"\"\"\n",
        "    Robust reader for Vizier VOTable/TSV exports.\n",
        "    Returns a DataFrame with columns: ra, dec, spin (¬±1).\n",
        "    \"\"\"\n",
        "    import os, re\n",
        "    import pandas as pd\n",
        "    from astropy.table import Table\n",
        "\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "\n",
        "    # 1) Native VOTable (XML/.vot)\n",
        "    if ext in (\".xml\", \".vot\"):\n",
        "        tab = Table.read(path, format=\"votable\")   # VizieR-friendly\n",
        "        df = tab.to_pandas()\n",
        "\n",
        "    else:\n",
        "        # 2) Text (tsv/csv/ASCII): try Astropy's ASCII reader first (it guesses formats & skips comments)\n",
        "        try:\n",
        "            tab = Table.read(path, format=\"ascii\", guess=True, comment=\"#%;\")\n",
        "            df = tab.to_pandas()\n",
        "        except Exception:\n",
        "            # 3) Manual header/delimiter detection for tricky TSV/ASCII\n",
        "            with open(path, \"r\", errors=\"ignore\") as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # find header line (first line that looks like column names)\n",
        "            hdr_idx = None\n",
        "            for i, line in enumerate(lines[:200]):\n",
        "                L = line.strip()\n",
        "                if not L or L.startswith((\"#\",\"%\",\";\")):  # comment/blank\n",
        "                    continue\n",
        "                # candidates that usually contain RA/DEC names\n",
        "                if re.search(r\"(RAJ?2000|RA[_ ]?ICRS|DEC?J?2000|DEJ2000|DEC[_ ]?ICRS|ra\\b|dec\\b)\", L, re.I):\n",
        "                    hdr_idx = i\n",
        "                    break\n",
        "            if hdr_idx is None:\n",
        "                raise ValueError(\"Could not identify header row in Vizier file.\")\n",
        "\n",
        "            header_line = lines[hdr_idx]\n",
        "            # decide delimiter: prefer tab, else comma, else whitespace\n",
        "            if \"\\t\" in header_line:\n",
        "                sep, delim_ws = \"\\t\", False\n",
        "            elif \",\" in header_line:\n",
        "                sep, delim_ws = \",\", False\n",
        "            else:\n",
        "                sep, delim_ws = None, True\n",
        "\n",
        "            df = pd.read_csv(\n",
        "                path,\n",
        "                skiprows=hdr_idx,\n",
        "                sep=sep,\n",
        "                engine=\"python\",\n",
        "                comment=\"#\",\n",
        "                on_bad_lines=\"skip\",\n",
        "                delim_whitespace=delim_ws,\n",
        "            )\n",
        "\n",
        "    # --- Normalize RA/Dec column names from common Vizier labels ---\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    ra_candidates  = [cols_lower[k] for k in cols_lower if k in (\"raj2000\",\"ra\",\"ra_icrs\",\"ra_j2000\",\"ra_deg\")]\n",
        "    dec_candidates = [cols_lower[k] for k in cols_lower if k in (\"dej2000\",\"dec\",\"dec_icrs\",\"dec_j2000\",\"dec_deg\")]\n",
        "    if not ra_candidates or not dec_candidates:\n",
        "        raise KeyError(f\"Could not find RA/Dec in columns: {list(df.columns)[:25]}\")\n",
        "    ra_col, dec_col = ra_candidates[0], dec_candidates[0]\n",
        "\n",
        "    # --- Infer spin: direct ¬±1, categorical CW/ACW, or from probabilities p_cw/p_acw ---\n",
        "    spin = None\n",
        "    if \"spin\" in cols_lower:\n",
        "        spin = pd.to_numeric(df[cols_lower[\"spin\"]], errors=\"coerce\")\n",
        "\n",
        "    if spin is None and \"spiral\" in cols_lower:\n",
        "        s = df[cols_lower[\"spiral\"]].astype(str).str.lower().str.strip()\n",
        "        spin = s.map({\"cw\": 1, \"acw\": -1, \"ccw\": -1, \"+1\": 1, \"-1\": -1})\n",
        "\n",
        "    def first_present(keys):\n",
        "        for k in keys:\n",
        "            if k in cols_lower:\n",
        "                return pd.to_numeric(df[cols_lower[k]], errors=\"coerce\")\n",
        "        return None\n",
        "\n",
        "    if spin is None:\n",
        "        p_cw  = first_present([\"p_cw\",\"pcw\",\"prob_cw\",\"cw_prob\",\"p(cw)\"])\n",
        "        p_acw = first_present([\"p_acw\",\"p_ccw\",\"pccw\",\"prob_acw\",\"acw_prob\",\"p(acw)\",\"p(ccw)\",\"prob_ccw\",\"ccw_prob\"])\n",
        "        if p_cw is not None and p_acw is not None:\n",
        "            diff = p_cw - p_acw\n",
        "            spin = pd.Series(np.where(diff >= cw_minus_acw_margin, 1,\n",
        "                               np.where(diff <= -cw_minus_acw_margin, -1, np.nan)))\n",
        "\n",
        "    if spin is None:\n",
        "        raise KeyError(\"Could not infer spin from columns. Expected 'spin', 'Spiral', or p_cw/p_acw.\")\n",
        "\n",
        "    out = pd.DataFrame({\n",
        "        \"ra\":  pd.to_numeric(df[ra_col],  errors=\"coerce\"),\n",
        "        \"dec\": pd.to_numeric(df[dec_col], errors=\"coerce\"),\n",
        "        \"spin\": pd.to_numeric(spin,       errors=\"coerce\"),\n",
        "    }).dropna()\n",
        "\n",
        "    # enforce ¬±1\n",
        "    out = out[(out[\"spin\"] == 1) | (out[\"spin\"] == -1)].reset_index(drop=True)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "YGizMkxqT6DU"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from astropy.table import Table\n",
        "\n",
        "# Path to your VOTable\n",
        "vot_path = \"/content/vizier_votable.vot\"  # adjust if different\n",
        "\n",
        "# List of table ids inside this file\n",
        "table_ids = [\"J_A_A_662_A4_tableb1\", \"J_A_A_662_A4_tableb2\"]\n",
        "\n",
        "for tname in table_ids:\n",
        "    print(f\"\\n=== Loading subtable: {tname} ===\")\n",
        "    tab = Table.read(vot_path, format=\"votable\", table_id=tname)\n",
        "    df = tab.to_pandas()\n",
        "\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Columns:\", list(df.columns)[:20])  # show first 20\n",
        "    print(df.head(5))  # first few rows\n",
        "\n",
        "    # Save small preview CSV\n",
        "    out_csv = f\"/mnt/data/{tname}_preview.csv\"\n",
        "    df.head(100).to_csv(out_csv, index=False)\n",
        "    print(\"Saved preview to:\", out_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCU7pPWiNwJ",
        "outputId": "b92ccf06-ce84-4070-c9dc-c0e287d9c514"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Loading subtable: J_A_A_662_A4_tableb1 ===\n",
            "Shape: (105, 14)\n",
            "Columns: ['_RAJ2000', '_DEJ2000', 'recno', 'Name', 'RAJ2000', 'DEJ2000', 'imag', 'zdp', 'e_zdp', 'zds', 'zss', 'Class', 'Score', 'Ref']\n",
            "   _RAJ2000  _DEJ2000  recno               Name   RAJ2000  DEJ2000       imag  \\\n",
            "0   2.20333   0.26412      1  HSCJ000848+001550   2.20333  0.26412  18.459999   \n",
            "1  20.07557   0.19048      2  HSCJ012018+001125  20.07557  0.19048  20.139999   \n",
            "2  22.47583   0.63363      3  HSCJ012954+003801  22.47583  0.63363  20.270000   \n",
            "3  29.38125  -3.51603      4  HSCJ015731-033057  29.38125 -3.51603  20.020000   \n",
            "4  29.49429  -6.24057      5  HSCJ015758-061426  29.49429 -6.24057  18.959999   \n",
            "\n",
            "    zdp  e_zdp    zds  zss Class  Score       Ref  \n",
            "0  0.35   0.03  0.397  NaN     1    2.6  SuGOHI-5  \n",
            "1  0.63   0.04  0.599  NaN   1,2    2.6       C21  \n",
            "2  0.67   0.05    NaN  NaN     1    2.8       C21  \n",
            "3  0.68   0.04  0.621  NaN   1,2    2.8  SuGOHI-1  \n",
            "4  0.35   0.03    NaN  NaN   1,2    2.6       C21  \n",
            "Saved preview to: /mnt/data/J_A_A_662_A4_tableb1_preview.csv\n",
            "\n",
            "=== Loading subtable: J_A_A_662_A4_tableb2 ===\n",
            "Shape: (630, 14)\n",
            "Columns: ['_RAJ2000', '_DEJ2000', 'recno', 'Name', 'RAJ2000', 'DEJ2000', 'imag', 'zdp', 'e_zdp', 'zds', 'zss', 'Class', 'Score', 'Ref']\n",
            "   _RAJ2000  _DEJ2000  recno               Name  RAJ2000  DEJ2000       imag  \\\n",
            "0   0.07884   0.27158      1  HSCJ000018+001617  0.07884  0.27158  19.910000   \n",
            "1   0.08681  -0.34750      2  HSCJ000020-002051  0.08681 -0.34750  20.559999   \n",
            "2   0.27710   1.05827      3  HSCJ000106+010329  0.27710  1.05827  20.070000   \n",
            "3   0.31063   0.27214      4  HSCJ000114+001619  0.31063  0.27214  19.410000   \n",
            "4   0.86261   2.17248      5  HSCJ000327+021020  0.86261  2.17248  20.180000   \n",
            "\n",
            "    zdp  e_zdp    zds  zss Class  Score    Ref  \n",
            "0  0.63   0.04    NaN  NaN     2    2.0  Shu22  \n",
            "1  0.95   0.05  0.560  NaN     1    2.2  Shu22  \n",
            "2  0.73   0.03  0.721  NaN   1,2    2.0  Shu22  \n",
            "3  0.67   0.05  0.664  NaN     1    1.6  Shu22  \n",
            "4  0.72   0.03    NaN  NaN     1    1.8    C21  \n",
            "Saved preview to: /mnt/data/J_A_A_662_A4_tableb2_preview.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HSC VizieR (tables A&B) side-by-side with anchored Logosfield ===\n",
        "import os, glob, json, zipfile, shutil\n",
        "import numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# healpy / astropy\n",
        "try:\n",
        "    import healpy as hp\n",
        "    from astropy.table import Table\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"healpy\", \"astropy\"])\n",
        "    import healpy as hp\n",
        "    from astropy.table import Table\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def find_one(patterns, roots=(\"/content\",\"/mnt/data\",\".\")):\n",
        "    hits=[]\n",
        "    for r in roots:\n",
        "        if not os.path.isdir(r): continue\n",
        "        for p in patterns:\n",
        "            hits.extend(glob.glob(os.path.join(r,p)))\n",
        "    return sorted(set(hits))[0] if hits else None\n",
        "\n",
        "def read_vizier_subtable(vot_path, table_id):\n",
        "    tab = Table.read(vot_path, format=\"votable\", table_id=table_id)\n",
        "    df  = tab.to_pandas()\n",
        "    # standardize ra/dec\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    ra  = cols.get(\"raj2000\")  or cols.get(\"_raj2000\") or cols.get(\"ra\")  or cols.get(\"ra_icrs\")\n",
        "    dec = cols.get(\"dej2000\")  or cols.get(\"_dej2000\") or cols.get(\"dec\") or cols.get(\"dec_icrs\")\n",
        "    if not ra or not dec:\n",
        "        raise KeyError(f\"Could not find RA/Dec in {table_id}. Columns: {list(df.columns)[:20]}\")\n",
        "    out = pd.DataFrame({\"ra\": pd.to_numeric(df[ra], errors=\"coerce\"),\n",
        "                        \"dec\": pd.to_numeric(df[dec], errors=\"coerce\")})\n",
        "    # detect spin if present\n",
        "    spin = None\n",
        "    for k in (\"spin\",\"spiral\"):\n",
        "        if k in cols:\n",
        "            s = df[cols[k]].astype(str).str.lower().str.strip()\n",
        "            if k==\"spiral\":   # CW/ACW ‚Üí ¬±1\n",
        "                s = s.map({\"cw\":1,\"acw\":-1,\"ccw\":-1,\"+1\":1,\"-1\":-1})\n",
        "            spin = pd.to_numeric(s, errors=\"coerce\")\n",
        "            break\n",
        "    if spin is None:\n",
        "        # try p_cw / p_acw\n",
        "        def pick(keys):\n",
        "            for key in keys:\n",
        "                if key in cols: return pd.to_numeric(df[cols[key]], errors=\"coerce\")\n",
        "            return None\n",
        "        p_cw  = pick([\"p_cw\",\"pcw\",\"prob_cw\",\"cw_prob\",\"p(cw)\"])\n",
        "        p_acw = pick([\"p_acw\",\"p_ccw\",\"pccw\",\"prob_acw\",\"acw_prob\",\"p(acw)\",\"p(ccw)\",\"prob_ccw\",\"ccw_prob\"])\n",
        "        if p_cw is not None and p_acw is not None:\n",
        "            diff = p_cw - p_acw\n",
        "            spin = pd.Series(np.where(diff>=0.02,1,np.where(diff<=-0.02,-1,np.nan)))\n",
        "    if spin is not None:\n",
        "        out[\"spin\"] = pd.to_numeric(spin, errors=\"coerce\")\n",
        "    out = out.dropna(subset=[\"ra\",\"dec\"]).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def load_map(p):\n",
        "    arr = np.load(p, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype==object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size==1 else arr[0]\n",
        "            if isinstance(obj, dict):\n",
        "                arr = np.asarray(next(iter(obj.values())))\n",
        "            else:\n",
        "                arr = np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    return np.asarray(arr, dtype=float).ravel()\n",
        "\n",
        "def anchor_and_summarize(df, dtheta_path, dphi_path, dens_path,\n",
        "                         gates=(20,30,45,60), try_nest=(True,False),\n",
        "                         metrics=(\"div_sin\",\"plain\")):\n",
        "    # maps + NSIDE\n",
        "    dthL_raw = load_map(dtheta_path)\n",
        "    dphL_raw = load_map(dphi_path)\n",
        "    nside = int(round((dthL_raw.size/12.0)**0.5))\n",
        "    dens = load_map(dens_path)\n",
        "    if dens.size != 12*nside*nside:\n",
        "        dens = np.resize(dens, 12*nside*nside)\n",
        "\n",
        "    # mechanism 2 gradient from density (healpy derivatives)\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(dens)\n",
        "        if hasattr(hp.sphtfunc,\"alm2map_der\"):\n",
        "            res = hp.sphtfunc.alm2map_der(alm, nside)\n",
        "            if isinstance(res,(list,tuple)) and len(res)==3:\n",
        "                _, dthM2, dphM2 = res\n",
        "            else:\n",
        "                dthM2, dphM2 = res\n",
        "        elif hasattr(hp.sphtfunc,\"alm2map_der1\"):\n",
        "            dthM2, dphM2 = hp.sphtfunc.alm2map_der1(alm, nside)\n",
        "        else:\n",
        "            raise RuntimeError\n",
        "    except Exception:\n",
        "        pix = np.arange(12*nside*nside)\n",
        "        th, ph = hp.pix2ang(nside, pix, nest=False)\n",
        "        eps = 1e-3\n",
        "        f_thp = hp.get_interp_val(dens, th+eps, ph, nest=False)\n",
        "        f_thm = hp.get_interp_val(dens, th-eps, ph, nest=False)\n",
        "        dthM2 = (f_thp - f_thm)/(2*eps)\n",
        "        f_php = hp.get_interp_val(dens, th, ph+eps, nest=False)\n",
        "        f_phm = hp.get_interp_val(dens, th, ph-eps, nest=False)\n",
        "        dphM2 = (f_php - f_phm)/(2*eps)\n",
        "\n",
        "    # Logosfield grads (swap convention)\n",
        "    pix_all = np.arange(12*nside*nside)\n",
        "    dthL = dphL_raw[pix_all]\n",
        "    dphL = dthL_raw[pix_all]\n",
        "\n",
        "    # linear anchor M: [dth_adj; dph_adj] = M * [dthL; dphL]\n",
        "    ok = np.isfinite(dthL)&np.isfinite(dphL)&np.isfinite(dthM2)&np.isfinite(dphM2)\n",
        "    idx = np.where(ok)[0]\n",
        "    A1 = np.column_stack([dthL[idx], dphL[idx], np.zeros_like(idx), np.zeros_like(idx)])\n",
        "    A2 = np.column_stack([np.zeros_like(idx), np.zeros_like(idx), dthL[idx], dphL[idx]])\n",
        "    A  = np.vstack([A1,A2]); b = np.concatenate([dthM2[idx], dphM2[idx]])\n",
        "    lam=1e-6\n",
        "    M = np.linalg.solve(A.T@A + lam*np.eye(4), A.T@b)\n",
        "    M = np.array([[M[0],M[1]],[M[2],M[3]]])\n",
        "    dth_adj = M[0,0]*dthL + M[0,1]*dphL\n",
        "    dph_adj = M[1,0]*dthL + M[1,1]*dphL\n",
        "\n",
        "    # project catalog\n",
        "    ths = (np.pi/2) - np.deg2rad(df[\"dec\"].values)\n",
        "    phs = np.deg2rad(df[\"ra\"].values) % (2*np.pi)\n",
        "\n",
        "    def phimet(kind, dphv, th):\n",
        "        if kind==\"div_sin\":\n",
        "            s = np.sin(th).copy(); s[s==0]=1.0\n",
        "            return dphv/s\n",
        "        return dphv\n",
        "\n",
        "    best=None; tried=[]\n",
        "    for nest in try_nest:\n",
        "        ids = hp.ang2pix(nside, ths, phs, nest=nest)\n",
        "        for met in metrics:\n",
        "            dphm = phimet(met, dph_adj[ids], ths)\n",
        "            pred = -np.where(dphm>=0, 1, -1)\n",
        "            for gate in gates:\n",
        "                alpha = np.arctan2(dth_adj[ids], dphm)\n",
        "                valid = (np.abs(alpha)<=np.deg2rad(gate)) & np.isfinite(dphm) & np.isfinite(dth_adj[ids])\n",
        "                N = int(valid.sum())\n",
        "                rec = dict(nest=nest, metric=met, gate=gate, N=N)\n",
        "                if N>0 and \"spin\" in df.columns:\n",
        "                    spins = df.loc[valid, \"spin\"].values.astype(float)\n",
        "                    good = np.isfinite(spins)\n",
        "                    N2 = int(good.sum())\n",
        "                    k = int((spins[good]==pred[valid][good]).sum()) if N2>0 else 0\n",
        "                    frac = (k/N2) if N2>0 else np.nan\n",
        "                    se = np.sqrt(frac*(1-frac)/N2) if N2>0 else np.nan\n",
        "                    rec.update(k=k, frac=frac, ci_lo=(frac-1.96*se) if N2>0 else np.nan,\n",
        "                               ci_hi=(frac+1.96*se) if N2>0 else np.nan, N_spin=N2)\n",
        "                tried.append(rec)\n",
        "                if best is None:\n",
        "                    best = rec.copy()\n",
        "                else:\n",
        "                    # prefer larger N, then higher frac (when available)\n",
        "                    if rec[\"N\"]>best[\"N\"] or (rec[\"N\"]==best[\"N\"] and rec.get(\"frac\", -1) > best.get(\"frac\", -1)):\n",
        "                        best = rec.copy()\n",
        "\n",
        "    return dict(best=best, tried=tried, anchor_matrix=M.tolist())\n",
        "\n",
        "def bundle_outputs(tag, summary):\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    outdir = f\"/mnt/data/HSC_Vizier_{tag}_{stamp}\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    zpath = outdir + \".zip\"\n",
        "    with zipfile.ZipFile(zpath, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root,_,files in os.walk(outdir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root,fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, outdir))\n",
        "    return zpath\n",
        "\n",
        "# ---------- locate inputs ----------\n",
        "vot_path = find_one([\"vizier_votable.vot\",\"*.vot\",\"*.xml\"])\n",
        "dtheta_path = find_one([\"*Logosfield*dtheta*map*.npy\",\"*dtheta*map*.npy\"])\n",
        "dphi_path   = find_one([\"*Logosfield*dphi*map*.npy\",\"*dphi*map*.npy\"])\n",
        "dens_path   = find_one([\"*scalar*density*.npy\",\"*density*map*.npy\",\"*density*.npy\",\"*density*.npz\"])\n",
        "\n",
        "print(\"VOTable:\", vot_path)\n",
        "print(\"dtheta :\", dtheta_path)\n",
        "print(\"dphi   :\", dphi_path)\n",
        "print(\"density:\", dens_path)\n",
        "\n",
        "assert vot_path and dtheta_path and dphi_path and dens_path, \"Missing one or more required files.\"\n",
        "\n",
        "# ---------- run both tables ----------\n",
        "tables = [\"J_A_A_662_A4_tableb1\", \"J_A_A_662_A4_tableb2\"]\n",
        "results = {}\n",
        "\n",
        "for tname in tables:\n",
        "    print(f\"\\n== Running {tname} ==\")\n",
        "    df = read_vizier_subtable(vot_path, tname)\n",
        "    print(\"Rows after standardization:\", len(df), \"| spin present:\", (\"spin\" in df.columns))\n",
        "    summary = anchor_and_summarize(df, dtheta_path, dphi_path, dens_path)\n",
        "    zip_path = bundle_outputs(tname, summary)\n",
        "    results[tname] = dict(best=summary[\"best\"], zip=zip_path)\n",
        "\n",
        "# ---------- side-by-side printout ----------\n",
        "def fmt(b):\n",
        "    if b is None: return \"‚Äî\"\n",
        "    parts = [f\"N={b.get('N',0)}\", f\"gate={b.get('gate')}\", f\"metric={b.get('metric')}\", f\"nest={b.get('nest')}\"]\n",
        "    if \"frac\" in b and b.get(\"frac\") is not None:\n",
        "        parts.append(f\"frac={b['frac']:.3f}\")\n",
        "        if \"ci_lo\" in b and np.isfinite(b[\"ci_lo\"]):\n",
        "            parts.append(f\"CI=({b['ci_lo']:.3f},{b['ci_hi']:.3f})\")\n",
        "        if \"N_spin\" in b: parts.append(f\"N_spin={b['N_spin']}\")\n",
        "    else:\n",
        "        parts.append(\"no spin ‚Üí fraction n/a\")\n",
        "    return \" | \".join(parts)\n",
        "\n",
        "print(\"\\n=== Side-by-side (best config) ===\")\n",
        "for tname in tables:\n",
        "    print(f\"{tname:>22}: {fmt(results[tname]['best'])}\")\n",
        "    print(f\"{'':>22}  ZIP ‚Üí {results[tname]['zip']}\")\n",
        "\n",
        "print(\"\\nDONE.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ZG5rkIkNcS",
        "outputId": "fe728ada-364a-4fcd-ed15-07a7f4fbc377"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOTable: ./vizier_votable.vot\n",
            "dtheta : ./Logosfield_dtheta_map (1).npy\n",
            "dphi   : ./Logosfield_dphi_map (1).npy\n",
            "density: ./Logosfield_scalar_density_map (1).npy\n",
            "\n",
            "== Running J_A_A_662_A4_tableb1 ==\n",
            "Rows after standardization: 105 | spin present: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1728144112.py:169: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Running J_A_A_662_A4_tableb2 ==\n",
            "Rows after standardization: 630 | spin present: False\n",
            "\n",
            "=== Side-by-side (best config) ===\n",
            "  J_A_A_662_A4_tableb1: N=0 | gate=20 | metric=div_sin | nest=True | no spin ‚Üí fraction n/a\n",
            "                        ZIP ‚Üí /mnt/data/HSC_Vizier_J_A_A_662_A4_tableb1_20250831_051853.zip\n",
            "  J_A_A_662_A4_tableb2: N=0 | gate=20 | metric=div_sin | nest=True | no spin ‚Üí fraction n/a\n",
            "                        ZIP ‚Üí /mnt/data/HSC_Vizier_J_A_A_662_A4_tableb2_20250831_051854.zip\n",
            "\n",
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1728144112.py:169: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Self-contained runner: VizieR HSC (Shu+ 2022) A & B, anchored + coverage ===\n",
        "import os, glob, json, zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import healpy as hp\n",
        "from astropy.table import Table\n",
        "\n",
        "# --------------------------- utilities ---------------------------\n",
        "\n",
        "def find_one(patterns, roots=(\"/content\",\"/mnt/data\",\".\")):\n",
        "    for r in roots:\n",
        "        for pat in patterns:\n",
        "            hits = sorted(set(glob.glob(os.path.join(r, pat))))\n",
        "            if hits:\n",
        "                return hits[0]\n",
        "    return None\n",
        "\n",
        "def read_vizier_subtable(vot_path, table_id):\n",
        "    df = Table.read(vot_path, format=\"votable\", table_id=table_id).to_pandas()\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "\n",
        "    ra  = cols.get(\"raj2000\")  or cols.get(\"_raj2000\") or cols.get(\"ra\")  or cols.get(\"ra_icrs\")\n",
        "    dec = cols.get(\"dej2000\")  or cols.get(\"_dej2000\") or cols.get(\"dec\") or cols.get(\"dec_icrs\")\n",
        "    if not ra or not dec:\n",
        "        raise KeyError(f\"RA/Dec columns not found in {table_id}. First columns: {list(df.columns)[:20]}\")\n",
        "\n",
        "    out = pd.DataFrame({\n",
        "        \"ra\":  pd.to_numeric(df[cols[ra if ra in cols else ra]],  errors=\"coerce\") if ra in cols else pd.to_numeric(df[ra], errors=\"coerce\"),\n",
        "        \"dec\": pd.to_numeric(df[cols[dec if dec in cols else dec]], errors=\"coerce\") if dec in cols else pd.to_numeric(df[dec], errors=\"coerce\"),\n",
        "    })\n",
        "\n",
        "    # Try direct spin labels\n",
        "    spin = None\n",
        "    for k in (\"spin\", \"spiral\"):\n",
        "        if k in cols:\n",
        "            s = df[cols[k]].astype(str).str.lower().str.strip()\n",
        "            if k == \"spiral\":\n",
        "                s = s.map({\"cw\": 1, \"acw\": -1, \"ccw\": -1, \"+1\": 1, \"-1\": -1})\n",
        "            spin = pd.to_numeric(s, errors=\"coerce\")\n",
        "            break\n",
        "\n",
        "    # Try probabilities p_cw / p_acw if no explicit spin\n",
        "    if spin is None:\n",
        "        def pick(keys):\n",
        "            for key in keys:\n",
        "                if key in cols:\n",
        "                    return pd.to_numeric(df[cols[key]], errors=\"coerce\")\n",
        "            return None\n",
        "        p_cw  = pick([\"p_cw\",\"pcw\",\"prob_cw\",\"cw_prob\",\"p(cw)\"])\n",
        "        p_acw = pick([\"p_acw\",\"p_ccw\",\"pccw\",\"prob_acw\",\"acw_prob\",\"p(acw)\",\"p(ccw)\",\"prob_ccw\",\"ccw_prob\"])\n",
        "        if p_cw is not None and p_acw is not None:\n",
        "            diff = p_cw - p_acw\n",
        "            spin = pd.Series(np.where(diff >= 0.02, 1, np.where(diff <= -0.02, -1, np.nan)))\n",
        "\n",
        "    if spin is not None:\n",
        "        out[\"spin\"] = pd.to_numeric(spin, errors=\"coerce\")\n",
        "\n",
        "    return out.dropna(subset=[\"ra\",\"dec\"]).reset_index(drop=True)\n",
        "\n",
        "def load_map(path):\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        arr = arr[list(arr.keys())[0]]\n",
        "    if getattr(arr, \"dtype\", None) == object:\n",
        "        try:\n",
        "            obj = arr.item() if arr.size == 1 else arr[0]\n",
        "            arr = np.asarray(next(iter(obj.values()))) if isinstance(obj, dict) else np.asarray(obj)\n",
        "        except Exception:\n",
        "            arr = np.asarray(arr)\n",
        "    return np.asarray(arr, float).ravel()\n",
        "\n",
        "def anchor_and_reports(df, dtheta_path, dphi_path, dens_path,\n",
        "                       gates=(20,30,45,60), try_nest=(True,False),\n",
        "                       metrics=(\"div_sin\",\"plain\")):\n",
        "    # maps / NSIDE\n",
        "    dthL_raw = load_map(dtheta_path)\n",
        "    dphL_raw = load_map(dphi_path)\n",
        "    npix = dthL_raw.size\n",
        "    nside = int(round((npix/12.0)**0.5))\n",
        "\n",
        "    dens = load_map(dens_path)\n",
        "    if dens.size != 12*nside*nside:\n",
        "        dens = np.resize(dens, 12*nside*nside)\n",
        "\n",
        "    # density gradients\n",
        "    try:\n",
        "        alm = hp.sphtfunc.map2alm(dens)\n",
        "        if hasattr(hp.sphtfunc, \"alm2map_der\"):\n",
        "            res = hp.sphtfunc.alm2map_der(alm, nside)\n",
        "            if isinstance(res,(list,tuple)) and len(res)==3:\n",
        "                _, dthM2, dphM2 = res\n",
        "            else:\n",
        "                dthM2, dphM2 = res\n",
        "        elif hasattr(hp.sphtfunc, \"alm2map_der1\"):\n",
        "            dthM2, dphM2 = hp.sphtfunc.alm2map_der1(alm, nside)\n",
        "        else:\n",
        "            raise RuntimeError\n",
        "    except Exception:\n",
        "        pix = np.arange(12*nside*nside)\n",
        "        th, ph = hp.pix2ang(nside, pix, nest=False); eps=1e-3\n",
        "        f = lambda t,p: hp.get_interp_val(dens, t, p, nest=False)\n",
        "        dthM2 = (f(th+eps,ph)-f(th-eps,ph))/(2*eps)\n",
        "        dphM2 = (f(th,ph+eps)-f(th,ph-eps))/(2*eps)\n",
        "\n",
        "    # Logosfield grads (swap)\n",
        "    pix_all = np.arange(12*nside*nside)\n",
        "    dthL = dphL_raw[pix_all]\n",
        "    dphL = dthL_raw[pix_all]\n",
        "\n",
        "    # linear anchor M (2x2)\n",
        "    ok = np.isfinite(dthL)&np.isfinite(dphL)&np.isfinite(dthM2)&np.isfinite(dphM2)\n",
        "    idx = np.where(ok)[0]\n",
        "\n",
        "    A1 = np.column_stack((dthL[idx], dphL[idx], np.zeros_like(idx), np.zeros_like(idx)))\n",
        "    A2 = np.column_stack((np.zeros_like(idx), np.zeros_like(idx), dthL[idx], dphL[idx]))\n",
        "    A  = np.vstack((A1, A2))\n",
        "    b  = np.concatenate((dthM2[idx], dphM2[idx]))\n",
        "\n",
        "    lam = 1e-6\n",
        "    Mvec = np.linalg.solve(A.T@A + lam*np.eye(4), A.T@b)\n",
        "    M = np.array([[Mvec[0], Mvec[1]],\n",
        "                  [Mvec[2], Mvec[3]]])\n",
        "\n",
        "    dth_adj = M[0,0]*dthL + M[0,1]*dphL\n",
        "    dph_adj = M[1,0]*dthL + M[1,1]*dphL\n",
        "\n",
        "    # project sources\n",
        "    ths = (np.pi/2) - np.deg2rad(df[\"dec\"].values)\n",
        "    phs = np.deg2rad(df[\"ra\"].values) % (2*np.pi)\n",
        "\n",
        "    def phimet(kind, dphv, th):\n",
        "        if kind==\"div_sin\":\n",
        "            s = np.sin(th).copy(); s[s==0]=1.0\n",
        "            return dphv/s\n",
        "        return dphv\n",
        "\n",
        "    rows=[]; best=None\n",
        "    for nest in try_nest:\n",
        "        pix = hp.ang2pix(nside, ths, phs, nest=nest)\n",
        "        for met in metrics:\n",
        "            dphm = phimet(met, dph_adj[pix], ths)\n",
        "            alpha = np.arctan2(dth_adj[pix], dphm)\n",
        "            finite = np.isfinite(alpha)&np.isfinite(dphm)&np.isfinite(dth_adj[pix])\n",
        "            for gate in gates:\n",
        "                mask = finite & (np.abs(alpha)<=np.deg2rad(gate))\n",
        "                N = int(mask.sum())\n",
        "                rec = dict(nest=nest, metric=met, gate=gate, N=N)\n",
        "                if \"spin\" in df.columns and N>0:\n",
        "                    pred = -np.where(dphm>=0, 1, -1)\n",
        "                    spins = df.loc[mask,\"spin\"].values.astype(float)\n",
        "                    good = np.isfinite(spins)\n",
        "                    N2 = int(good.sum())\n",
        "                    k = int((spins[good]==pred[mask][good]).sum()) if N2>0 else 0\n",
        "                    frac = (k/N2) if N2>0 else np.nan\n",
        "                    rec.update(N_spin=N2, k=k, frac=frac)\n",
        "                rows.append(rec)\n",
        "                if (best is None or\n",
        "                    rec[\"N\"]>best[\"N\"] or\n",
        "                    (rec[\"N\"]==best[\"N\"] and rec.get(\"frac\",-1)>best.get(\"frac\",-1))):\n",
        "                    best = rec.copy()\n",
        "\n",
        "    coverage = pd.DataFrame(rows).sort_values([\"N\",\"gate\",\"metric\"],\n",
        "                                              ascending=[False,True,True]).reset_index(drop=True)\n",
        "    return {\"best\":best, \"coverage\":coverage, \"anchor_matrix\":M.tolist()}\n",
        "\n",
        "def bundle(tag, summary):\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    outdir = f\"/mnt/data/HSC_Vizier_{tag}_{stamp}\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    # write JSON w/out the heavy dataframe\n",
        "    light = {k:(v if k!=\"coverage\" else None) for k,v in summary.items()}\n",
        "    with open(os.path.join(outdir,\"summary.json\"),\"w\") as f:\n",
        "        json.dump(light, f, indent=2)\n",
        "\n",
        "    summary[\"coverage\"].to_csv(os.path.join(outdir,\"coverage_by_gate_metric.csv\"), index=False)\n",
        "\n",
        "    zpath = outdir + \".zip\"\n",
        "    with zipfile.ZipFile(zpath, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root,_,files in os.walk(outdir):\n",
        "            for fn in files:\n",
        "                fp = os.path.join(root, fn)\n",
        "                zf.write(fp, arcname=os.path.relpath(fp, outdir))\n",
        "    return zpath\n",
        "\n",
        "# --------------------------- locate inputs ---------------------------\n",
        "\n",
        "vot    = find_one([\"vizier_votable.vot\",\"*.vot\",\"*.xml\"])\n",
        "dtheta = find_one([\"*Logosfield*dtheta*map*.npy\",\"*dtheta*map*.npy\"])\n",
        "dphi   = find_one([\"*Logosfield*dphi*map*.npy\",\"*dphi*map*.npy\"])\n",
        "dens   = find_one([\"*scalar*density*.npy\",\"*density*map*.npy\",\"*density*.npy\",\"*density*.npz\"])\n",
        "\n",
        "print(\"VOTable:\", vot, \"\\ndtheta:\", dtheta, \"\\ndphi:\", dphi, \"\\ndensity:\", dens)\n",
        "assert all([vot,dtheta,dphi,dens]), \"Missing one or more inputs.\"\n",
        "\n",
        "# --------------------------- run A & B ---------------------------\n",
        "\n",
        "tables = [\"J_A_A_662_A4_tableb1\", \"J_A_A_662_A4_tableb2\"]\n",
        "\n",
        "for t in tables:\n",
        "    print(f\"\\n== {t} ==\")\n",
        "    df = read_vizier_subtable(vot, t)\n",
        "    print(\"rows:\", len(df), \"| spin present:\", (\"spin\" in df.columns))\n",
        "\n",
        "    report = anchor_and_reports(df, dtheta, dphi, dens)\n",
        "    print(\"Top coverage rows:\\n\", report[\"coverage\"].head(10))\n",
        "\n",
        "    z = bundle(t, report)\n",
        "    print(\"ZIP:\", z)\n",
        "\n",
        "print(\"\\nDONE.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "AgRzKwHfExKU",
        "outputId": "06b3c14c-6626-4309-d559-1a533f256db5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'healpy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1468843597.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhealpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'healpy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip import healpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r8ky6xtFfIH",
        "outputId": "f3dae404-e0d9-455a-d6e1-f9597894e744"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"import\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ONE-CELL: install deps + imports + submission bundle ZIP ===\n",
        "import sys, subprocess, importlib, os, glob, zipfile, json, hashlib\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure(pkg):\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"[ok] {pkg} already available\")\n",
        "    except Exception:\n",
        "        print(f\"[pip] installing {pkg} ‚Ä¶\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "        importlib.invalidate_caches()\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"[ok] {pkg} installed\")\n",
        "\n",
        "# 1) Ensure dependencies (quiet)\n",
        "for pkg in (\"healpy\", \"astropy\"):\n",
        "    ensure(pkg)\n",
        "\n",
        "# 2) Imports (after install)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import healpy as hp\n",
        "from astropy.table import Table\n",
        "\n",
        "print(f\"\\nhealpy version: {hp.__version__}\")\n",
        "\n",
        "# 3) Helper: pretty byte sizes\n",
        "def fmt_size(n):\n",
        "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
        "        if n < 1024 or unit == \"TB\":\n",
        "            return f\"{n:0.2f} {unit}\"\n",
        "        n /= 1024\n",
        "\n",
        "# 4) Configure sweep + filters\n",
        "ROOTS = [\"/content\", \"/mnt/data\"]\n",
        "INCLUDE_GLOBS = [\n",
        "    \"**/*.csv\", \"**/*.npz\", \"**/*.npy\", \"**/*.parquet\",\n",
        "    \"**/*.png\", \"**/*.jpg\", \"**/*.jpeg\", \"**/*.pdf\",\n",
        "    \"**/*.fits\", \"**/*.fit\", \"**/*.json\", \"**/*.txt\",\n",
        "    \"**/*.md\"\n",
        "]\n",
        "EXCLUDE_PATTERNS = [\n",
        "    \".ipynb_checkpoints\", \"__pycache__\", \"/sample_data/\",\n",
        "]\n",
        "MAX_FILE_MB = None  # e.g. set to 500 to cap each file size\n",
        "\n",
        "# 5) Collect candidate files\n",
        "def should_skip(p: Path) -> bool:\n",
        "    s = str(p)\n",
        "    for bad in EXCLUDE_PATTERNS:\n",
        "        if bad in s:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def collect_files():\n",
        "    out = []\n",
        "    for root in ROOTS:\n",
        "        for pat in INCLUDE_GLOBS:\n",
        "            for p in Path(root).glob(pat):\n",
        "                if not p.is_file():\n",
        "                    continue\n",
        "                if should_skip(p):\n",
        "                    continue\n",
        "                if MAX_FILE_MB is not None and p.stat().st_size > MAX_FILE_MB * 1024**2:\n",
        "                    continue\n",
        "                out.append(p)\n",
        "    # Deduplicate by resolved path\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for p in out:\n",
        "        rp = p.resolve()\n",
        "        if rp not in seen:\n",
        "            seen.add(rp)\n",
        "            uniq.append(p)\n",
        "    return uniq\n",
        "\n",
        "files = collect_files()\n",
        "files_sorted = sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "\n",
        "# 6) Make bundle dir + copy manifest\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "bundle_name = f\"Submission_Bundle_{ts}.zip\"\n",
        "manifest = []\n",
        "\n",
        "for p in files_sorted:\n",
        "    stat = p.stat()\n",
        "    manifest.append({\n",
        "        \"path\": str(p),\n",
        "        \"size_bytes\": stat.st_size,\n",
        "        \"size_human\": fmt_size(stat.st_size),\n",
        "        \"mtime\": datetime.fromtimestamp(stat.st_mtime).isoformat(timespec=\"seconds\"),\n",
        "    })\n",
        "\n",
        "# 7) Write ZIP (preserving relative paths)\n",
        "with zipfile.ZipFile(bundle_name, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # Write a manifest.json first\n",
        "    manifest_text = json.dumps({\"generated_at\": ts, \"count\": len(files_sorted), \"files\": manifest}, indent=2)\n",
        "    zf.writestr(\"manifest.json\", manifest_text)\n",
        "\n",
        "    for p in files_sorted:\n",
        "        # Keep relative structure under its root\n",
        "        root_for_rel = None\n",
        "        for r in ROOTS:\n",
        "            try:\n",
        "                Path(p).relative_to(r)\n",
        "                root_for_rel = r\n",
        "                break\n",
        "            except Exception:\n",
        "                continue\n",
        "        arcname = Path(p).relative_to(root_for_rel) if root_for_rel else Path(p).name\n",
        "        zf.write(p, arcname=str(arcname))\n",
        "\n",
        "print(\"\\n=== SUBMISSION BUNDLE COMPLETE ===\")\n",
        "print(f\"Bundle: {bundle_name}\")\n",
        "print(f\"Files included: {len(files_sorted)}\")\n",
        "\n",
        "# 8) Echo compact table of newest 30 items\n",
        "preview = manifest[:30]\n",
        "w = max(len(x[\"path\"]) for x in preview) if preview else 40\n",
        "print(\"\\nNewest (up to 30 shown):\")\n",
        "for x in preview:\n",
        "    print(f\"{x['mtime']}  {x['size_human']:>10}  {x['path']}\")\n",
        "\n",
        "# 9) Optional: compute quick hash of the ZIP for provenance\n",
        "def sha256sum(path, chunk=1<<20):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        while True:\n",
        "            b = f.read(chunk)\n",
        "            if not b: break\n",
        "            h.update(b)\n",
        "    return h.hexdigest()\n",
        "\n",
        "zip_hash = sha256sum(bundle_name)\n",
        "print(f\"\\nSHA256({bundle_name}) = {zip_hash}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46pOK-x_H0iq",
        "outputId": "e4c37f0f-b548-4403-dabb-ab0fa2f3e41e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing healpy ‚Ä¶\n",
            "[ok] healpy installed\n",
            "[ok] astropy already available\n",
            "\n",
            "healpy version: 1.18.1\n",
            "\n",
            "=== SUBMISSION BUNDLE COMPLETE ===\n",
            "Bundle: Submission_Bundle_20250831_171359.zip\n",
            "Files included: 363\n",
            "\n",
            "Newest (up to 30 shown):\n",
            "2025-08-31T01:33:33    48.12 KB  /content/drive/MyDrive/kappa_full.npy\n",
            "2025-08-31T01:33:23   127.64 KB  /content/drive/MyDrive/Planck_kappa_CMB_Overlay_Map.png\n",
            "2025-08-30T20:39:48     1.50 MB  /content/drive/MyDrive/Logosfield_scalar_density_map.npy\n",
            "2025-08-30T17:04:59     58.00 B  /content/drive/MyDrive/https: www.facebook.com share 1LZhjxJP64 ?mibextid=wwXIfr.txt\n",
            "2025-08-29T17:28:13   780.34 MB  /content/drive/MyDrive/hlsp_jades_jwst_nircam_goods-n_photometry_v1.0_catalog.fits\n",
            "2025-08-29T17:15:53   642.35 MB  /content/drive/MyDrive/hlsp_jades_jwst_nircam_goods-s-deep_photometry_v2.0_catalog.fits\n",
            "2025-08-29T06:18:15   127.39 KB  /content/drive/MyDrive/Sparsity_Prior_Overlay_Map.png\n",
            "2025-08-28T22:14:14     2.06 KB  /content/drive/MyDrive/README_JWST_alignment.txt\n",
            "2025-08-28T22:13:37    71.05 KB  /content/drive/MyDrive/weighted_vs_unweighted_correlation.png\n",
            "2025-08-28T13:42:29    135.00 B  /content/.config/.last_update_check.json\n",
            "2025-08-28T03:38:51     4.95 MB  /content/drive/MyDrive/Tillma_PartyBus-81_Original.jpeg\n",
            "2025-08-27T23:24:53     1.50 MB  /content/drive/MyDrive/Logosfield_dphi_map.npy\n",
            "2025-08-26T15:05:02    96.01 MB  /content/drive/MyDrive/glimpse_mask.fits\n",
            "2025-08-25T17:50:02    205.00 B  /content/drive/MyDrive/README_Logosfield_map.txt\n",
            "2025-08-25T17:48:50     1.50 MB  /content/drive/MyDrive/Logosfield_scalar_density_map (1).npy\n",
            "2025-08-25T15:09:00     5.55 KB  /content/drive/MyDrive/Logosfield_Bundles/manifest_20250825_150801.csv\n",
            "2025-08-25T15:00:28   182.48 KB  /content/drive/MyDrive/2D_Power_Spectra_Comparison.png\n",
            "2025-08-25T15:00:28     1.27 MB  /content/drive/MyDrive/ODCCT_3D_Galaxy_Spin_Alignment_Map.png\n",
            "2025-08-25T15:00:28   285.72 KB  /content/drive/MyDrive/Logosfield_t30.png\n",
            "2025-08-25T15:00:28     1.01 MB  /content/drive/MyDrive/ODCCT_Simulated_DarkMatter_Field.png\n",
            "2025-08-25T15:00:28    94.69 KB  /content/drive/MyDrive/Divergence_Logosfield 2.png\n",
            "2025-08-25T15:00:28   430.57 KB  /content/drive/MyDrive/Logosfield_Gradient_Vector_Map.png\n",
            "2025-08-25T15:00:28     1.20 MB  /content/drive/MyDrive/Ancient_vs_Modern_Logosfield_Overlay.png\n",
            "2025-08-25T15:00:28    67.46 KB  /content/drive/MyDrive/Simulated_JWST_Spin_Alignment.png\n",
            "2025-08-25T15:00:27   245.84 KB  /content/drive/MyDrive/Gaussian_Prior_Overlay_Preview.png\n",
            "2025-08-25T15:00:26   128.04 KB  /content/drive/MyDrive/Gaussian_Prior_Overlay_Map.png\n",
            "2025-08-25T15:00:25    94.69 KB  /content/drive/MyDrive/Divergence_Logosfield.png\n",
            "2025-08-25T15:00:25   127.39 KB  /content/drive/MyDrive/Sparsity_Prior_Overlay_Map (1).png\n",
            "2025-08-25T15:00:25   259.40 KB  /content/drive/MyDrive/Kaiser_Squires_Overlay_Preview.png\n",
            "2025-08-25T15:00:25   127.64 KB  /content/drive/MyDrive/Planck_kappa_CMB_Overlay_Map (1).png\n",
            "\n",
            "SHA256(Submission_Bundle_20250831_171359.zip) = 941dbc0e00d251584a7ca62c5d14776ca623ccbb492766aca848b1324654d623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === One-paste Archiver + RAM cleanup for Colab ===\n",
        "import os, json, io, gc, shutil, zipfile, time, glob, sys\n",
        "from datetime import datetime\n",
        "\n",
        "STAMP = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "ARCHIVE = f\"logosfield_session_{STAMP}.zip\"\n",
        "\n",
        "# 1) What to save ‚Äî add/trim as you like\n",
        "CANDIDATES = [\n",
        "    \"*.ipynb\",                    # your notebook\n",
        "    \"*_spins_bins/**\",            # jades_spins_bins/, ceers_spins_bins/\n",
        "    \"jades_spins_bins/**\",\n",
        "    \"ceers_spins_bins/**\",\n",
        "    \"*spins*.csv\",                # any spin csvs\n",
        "    \"nodes*.csv\", \"density*.csv\", \"sites*.csv\",\n",
        "    \"README*.md\", \"manifest*.json\", \"logs/*.txt\",\n",
        "]\n",
        "\n",
        "# 2) Optional: small manifest with run context (edit or extend)\n",
        "manifest = {\n",
        "    \"timestamp_utc\": STAMP,\n",
        "    \"notes\": \"Archived JWST/JADES/CEERS + Logosfield inputs/outputs.\",\n",
        "    \"redshift_bins\": [(3,5),(5,8),(8,12)],\n",
        "    \"fileset\": CANDIDATES,\n",
        "    # If you had stats in variables, add them:\n",
        "    # \"stats\": {\"A_real\": float(A_real), \"corr_proxy\": float(corr_proxy)}\n",
        "}\n",
        "\n",
        "with zipfile.ZipFile(ARCHIVE, \"w\", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as z:\n",
        "    # write manifest\n",
        "    z.writestr(\"manifest.json\", json.dumps(manifest, indent=2))\n",
        "    # collect files\n",
        "    added = 0\n",
        "    for pat in CANDIDATES:\n",
        "        for path in glob.glob(pat, recursive=True):\n",
        "            if os.path.isdir(path):\n",
        "                continue  # we'll add files via /** patterns\n",
        "            try:\n",
        "                z.write(path)\n",
        "                added += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Skip {path} ({e})\")\n",
        "print(f\"\\nCreated {ARCHIVE} with {added} files.\")\n",
        "\n",
        "# 3) (Optional) copy to Google Drive\n",
        "SAVE_TO_DRIVE = True   # set False if you don‚Äôt want Drive copy\n",
        "if SAVE_TO_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        drive_dir = \"/content/drive/MyDrive/logosfield_archives\"\n",
        "        os.makedirs(drive_dir, exist_ok=True)\n",
        "        shutil.copy2(ARCHIVE, os.path.join(drive_dir, ARCHIVE))\n",
        "        print(f\"Copied to Drive: {drive_dir}/{ARCHIVE}\")\n",
        "    except Exception as e:\n",
        "        print(\"Drive copy skipped/failed:\", e)\n",
        "\n",
        "# 4) Offer a direct download\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(ARCHIVE)\n",
        "except Exception as e:\n",
        "    print(\"Download helper not available:\", e)\n",
        "\n",
        "# 5) Free RAM (best-effort)\n",
        "def _bytes2mb(n): return f\"{n/1024/1024:.1f} MB\"\n",
        "print(\"\\nRAM cleanup‚Ä¶\")\n",
        "keep_names = {\"STAMP\",\"ARCHIVE\",\"CANDIDATES\",\"manifest\",\"drive\",\"files\",\"shutil\",\"zipfile\",\n",
        "              \"glob\",\"os\",\"json\",\"io\",\"gc\",\"SAVE_TO_DRIVE\",\"_bytes2mb\"}\n",
        "for k in list(globals().keys()):\n",
        "    if k.startswith(\"_\") or k in keep_names:\n",
        "        continue\n",
        "    try:\n",
        "        del globals()[k]\n",
        "    except:\n",
        "        pass\n",
        "gc.collect()\n",
        "print(\"Done. Consider Runtime ‚Üí Restart if you still feel tight on memory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "NfGanVzN2g62",
        "outputId": "4153d135-8ce2-47f0-93ef-3f0c17c9c128"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-370248939.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  STAMP = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Created logosfield_session_20250831_203913.zip with 0 files.\n",
            "Mounted at /content/drive\n",
            "Copied to Drive: /content/drive/MyDrive/logosfield_archives/logosfield_session_20250831_203913.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_620ba5eb-4011-4c5e-b370-71833d89b80c\", \"logosfield_session_20250831_203913.zip\", 374)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RAM cleanup‚Ä¶\n",
            "Done. Consider Runtime ‚Üí Restart if you still feel tight on memory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip -q install healpy astropy pandas numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNWsk96JKwA",
        "outputId": "c83ed260-87d2-4c3d-9e58-6e712c44cab7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Spin Alignment ‚Äî All-in-One v2 (robust normalization + dœÜ sanity)\n",
        "# ======================================================================\n",
        "\n",
        "import os, glob, json, math, datetime, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "import healpy as hp\n",
        "\n",
        "# -----------------\n",
        "# CONFIG\n",
        "# -----------------\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "\n",
        "# Maps: if DPHI_PATH is missing but SCALAR_PATH exists, we build dœÜ from the scalar\n",
        "SCALAR_PATH = f\"{DRIVE}/Logosfield_scalar_density_map.npy\"\n",
        "DPHI_PATH   = f\"{DRIVE}/Logosfield_dphi_map.npy\"\n",
        "\n",
        "# Optional template catalogs (will be treated like any other per-object catalog)\n",
        "SDSS_FILE = f\"{DRIVE}/sdss_spins_TEMPLATE.csv\"\n",
        "HSC_FILE  = f\"{DRIVE}/hsc_spins_TEMPLATE.csv\"\n",
        "\n",
        "# Outputs\n",
        "OUT_DIR   = Path(\"/content\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CLEAN_DIR = Path(\"/content/_jwst_clean\"); CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CSV_OUT   = OUT_DIR / \"repro_spin_alignment_summary.csv\"\n",
        "DBG_OUT   = OUT_DIR / \"repro_spin_alignment_file_debug.csv\"\n",
        "JSON_OUT  = OUT_DIR / \"repro_spin_alignment_summary.json\"\n",
        "\n",
        "# Alignment polarity / numerics\n",
        "AUTO_POLARITY = True   # choose whichever of dœÜ or ‚àídœÜ yields more matches\n",
        "ALIGN_SIGN    = -1     # used only if AUTO_POLARITY=False\n",
        "DPHI_EPS      = 1e-6   # ignore |dœÜ| ‚â§ Œµ; if this drops everything, we auto-relax\n",
        "\n",
        "# -----------------\n",
        "# helpers\n",
        "# -----------------\n",
        "def now_utc_str(): return datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "def _read_any_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception:\n",
        "        for sep in [\"\\t\", r\"\\s+|\\t+\"]:\n",
        "            try: return pd.read_csv(path, sep=sep, engine=\"python\", comment=\"#\")\n",
        "            except Exception: pass\n",
        "    raise RuntimeError(f\"Could not parse {path}\")\n",
        "\n",
        "def _pick(df, names):\n",
        "    cl = {c.lower(): c for c in df.columns}\n",
        "    for n in names:\n",
        "        if n.lower() in cl: return cl[n.lower()]\n",
        "    return None\n",
        "\n",
        "def _derive_spin_series(df):\n",
        "    \"\"\"CW/CCW ‚Üí ¬±1; supports labels, probabilities, counts.\"\"\"\n",
        "    lc = {c.lower(): c for c in df.columns}\n",
        "\n",
        "    # direct spin\n",
        "    if \"spin\" in lc:\n",
        "        s = df[lc[\"spin\"]]\n",
        "        if s.dtype == object:\n",
        "            m = s.astype(str).str.strip().str.upper().map(\n",
        "                {\"CW\":+1,\"CCW\":-1,\"ACW\":-1,\"CLOCKWISE\":+1,\"ANTICLOCKWISE\":-1}\n",
        "            )\n",
        "            return pd.to_numeric(m, errors=\"coerce\")\n",
        "        return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "    # majority label\n",
        "    lab = next((lc[c] for c in [\"majority_spin\",\"majority_label\",\"label\",\"class\",\"cw_ccw\"] if c in lc), None)\n",
        "    if lab:\n",
        "        m = df[lab].astype(str).str.strip().str.upper().map(\n",
        "            {\"CW\":+1,\"CCW\":-1,\"ACW\":-1,\"CLOCKWISE\":+1,\"ANTICLOCKWISE\":-1}\n",
        "        )\n",
        "        return pd.to_numeric(m, errors=\"coerce\")\n",
        "\n",
        "    # probabilities / fractions\n",
        "    pcw = next((lc[c] for c in [\"p_cw\",\"pcw\",\"prob_cw\",\"p(cw)\",\"cw_prob\",\"cw_p\",\"cw_conf\",\"cw_frac\",\"cwfrac\",\"majority_frac\"] if c in lc), None)\n",
        "    if pcw:\n",
        "        v = pd.to_numeric(df[pcw], errors=\"coerce\")\n",
        "        v = np.where(v>1, v/100.0, v)  # accept percent in 0..100\n",
        "        return np.sign(v - 0.5)\n",
        "\n",
        "    # counts\n",
        "    cw = next((lc[c] for c in [\"cw_count\",\"cw\",\"n_cw\",\"cwcount\"] if c in lc), None)\n",
        "    cc = next((lc[c] for c in [\"ccw_count\",\"acw_count\",\"ccw\",\"n_ccw\",\"n_acw\",\"ccwcount\",\"acw\"] if c in lc), None)\n",
        "    if cw and cc:\n",
        "        return np.sign(pd.to_numeric(df[cw], errors=\"coerce\") - pd.to_numeric(df[cc], errors=\"coerce\"))\n",
        "\n",
        "    return pd.Series(index=df.index, dtype=float)\n",
        "\n",
        "def _normalize_df_any(df):\n",
        "    \"\"\"\n",
        "    Given any dataframe (template or cleaned), produce columns:\n",
        "    ra_deg, dec_deg, spin(¬±1).  Attempts many common colnames/encodings.\n",
        "    \"\"\"\n",
        "    # map RA/Dec\n",
        "    ra_col  = _pick(df, [\"ra_deg\",\"ra\",\"ra_s\",\"RA_TARG\",\"RAJ2000\"])\n",
        "    dec_col = _pick(df, [\"dec_deg\",\"dec\",\"dec_s\",\"Dec_TARG\",\"DEJ2000\"])\n",
        "    if not ra_col or not dec_col:\n",
        "        return pd.DataFrame(columns=[\"ra_deg\",\"dec_deg\",\"spin\"])\n",
        "\n",
        "    ra  = pd.to_numeric(df[ra_col],  errors=\"coerce\")\n",
        "    dec = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
        "\n",
        "    # derive spin robustly\n",
        "    s = _derive_spin_series(df).clip(-1,1)\n",
        "    out = pd.DataFrame({\"ra_deg\": ra, \"dec_deg\": dec, \"spin\": s})\n",
        "    out = out.dropna(subset=[\"ra_deg\",\"dec_deg\",\"spin\"])\n",
        "    # enforce ¬±1 exactly\n",
        "    out[\"spin\"] = np.sign(out[\"spin\"].astype(float))\n",
        "    return out\n",
        "\n",
        "# -----------------\n",
        "# map builder / loader\n",
        "# -----------------\n",
        "def build_dphi_from_scalar(scalar_path=SCALAR_PATH, out_path=DPHI_PATH):\n",
        "    print(f\"[scalar] loading: {scalar_path}\")\n",
        "    m = np.load(scalar_path)\n",
        "    NSIDE = hp.npix2nside(len(m))\n",
        "    print(f\"[scalar] NSIDE={NSIDE}, Npix={len(m)}\")\n",
        "\n",
        "    lmax = 3*NSIDE - 1\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        alm = hp.map2alm(m, lmax=lmax, iter=0)\n",
        "        dtheta, dphi = hp.alm2map_der1(alm, nside=NSIDE, lmax=lmax, iter=0)\n",
        "\n",
        "    np.save(out_path, dphi.astype(np.float32))\n",
        "    print(f\"[dphi] saved -> {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "def load_dphi_map(dphi_path=DPHI_PATH, scalar_path=SCALAR_PATH):\n",
        "    if os.path.exists(dphi_path):\n",
        "        dphi = np.load(dphi_path)\n",
        "        NSIDE = hp.npix2nside(len(dphi))\n",
        "        print(f\"[dphi] using saved {dphi_path}  NSIDE={NSIDE}, Npix={len(dphi)}\")\n",
        "    elif os.path.exists(scalar_path):\n",
        "        print(\"[dphi] not found; building from scalar...\")\n",
        "        built = build_dphi_from_scalar(scalar_path, dphi_path)\n",
        "        dphi = np.load(built)\n",
        "        NSIDE = hp.npix2nside(len(dphi))\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Need dœÜ or scalar map.\")\n",
        "\n",
        "    # sanity / visibility\n",
        "    nz = int((np.isfinite(dphi) & (np.abs(dphi) > DPHI_EPS)).sum())\n",
        "    print(f\"[dphi] stats: min={np.nanmin(dphi):.3e}  max={np.nanmax(dphi):.3e}  std={np.nanstd(dphi):.3e}  nz(|dœÜ|>Œµ)={nz}\")\n",
        "    if nz == 0:\n",
        "        print(\"[dphi] WARNING: |dœÜ| > Œµ has zero support ‚Äî we will relax the Œµ gate for this run.\")\n",
        "    return dphi, NSIDE, (nz > 0)\n",
        "\n",
        "# -----------------\n",
        "# JWST cleaner (optional sources)\n",
        "# -----------------\n",
        "def clean_jwst_per_object():\n",
        "    patterns = [\n",
        "        \"/**/*spin_batch_*of_*.csv\",\n",
        "        \"/**/*jwst*spins*template*.csv\",\n",
        "        \"/**/*JWST*SPINS*TEMPLATE*.csv\",\n",
        "        \"/**/*_spins_TEMPLATE.csv\",\n",
        "    ]\n",
        "    candidates = sorted(set(sum((glob.glob(DRIVE + p, recursive=True) for p in patterns), [])))\n",
        "    if candidates:\n",
        "        print(\"JWST candidates:\", *candidates, sep=\"\\n  \")\n",
        "    else:\n",
        "        print(\"JWST candidates: 0\")\n",
        "\n",
        "    cleaned, report = [], []\n",
        "    for i, path in enumerate(candidates):\n",
        "        try:\n",
        "            df = _read_any_csv(path)\n",
        "            norm = _normalize_df_any(df)\n",
        "            if len(norm) == 0:\n",
        "                report.append((os.path.basename(path), \"no usable rows (spin empty?)\", 0)); continue\n",
        "            dst = CLEAN_DIR / f\"clean_{i:03d}.csv\"\n",
        "            norm.to_csv(dst, index=False)\n",
        "            cleaned.append(str(dst))\n",
        "            report.append((os.path.basename(path), \"ok\", len(norm)))\n",
        "        except Exception as e:\n",
        "            report.append((os.path.basename(path), f\"error: {e}\", 0))\n",
        "    print(\"\\nJWST clean report:\")\n",
        "    for r in report: print(\"  \", r)\n",
        "    return cleaned\n",
        "\n",
        "# -----------------\n",
        "# alignment evaluation (robust)\n",
        "# -----------------\n",
        "def eval_file_alignment(path, dphi, NSIDE, nz_gate_available: bool):\n",
        "    df_raw = _read_any_csv(path)\n",
        "    df = _normalize_df_any(df_raw)  # normalize every file (templates included)\n",
        "    if len(df) == 0: return 0, 0\n",
        "\n",
        "    ra_r  = np.radians(df[\"ra_deg\"].to_numpy())\n",
        "    dec_r = np.radians(df[\"dec_deg\"].to_numpy())\n",
        "    s     = np.sign(df[\"spin\"].astype(float).to_numpy())\n",
        "\n",
        "    theta = (np.pi/2.0) - dec_r\n",
        "    phi   = ra_r\n",
        "    ipix  = hp.ang2pix(NSIDE, theta, phi, nest=False)\n",
        "    d_at  = dphi[ipix]\n",
        "\n",
        "    if nz_gate_available:\n",
        "        mask = np.isfinite(d_at) & (np.abs(d_at) > DPHI_EPS)\n",
        "    else:\n",
        "        # relax if Œµ-gate would kill everything\n",
        "        mask = np.isfinite(d_at)\n",
        "\n",
        "    if mask.sum() == 0: return 0, 0\n",
        "\n",
        "    s = s[mask]; d = d_at[mask]\n",
        "    h0 = (np.sign(s) == np.sign(d))\n",
        "    h1 = (np.sign(s) == np.sign(-d))\n",
        "    use_flip = (h1.sum() > h0.sum()) if AUTO_POLARITY else (ALIGN_SIGN < 0)\n",
        "    aligned = h1 if use_flip else h0\n",
        "    return int(mask.sum()), int(aligned.sum())\n",
        "\n",
        "def run_dataset(name, files, dphi, NSIDE, nz_gate_available):\n",
        "    N, K = 0, 0\n",
        "    dbg = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            n_used, k_aligned = eval_file_alignment(f, dphi, NSIDE, nz_gate_available)\n",
        "            N += n_used; K += k_aligned\n",
        "            dbg.append({\"dataset\":name,\"file\":f,\"rows_total\":n_used,\"rows_usable\":n_used,\"status\":\"used\" if n_used>0 else \"empty\"})\n",
        "        except Exception as e:\n",
        "            dbg.append({\"dataset\":name,\"file\":f,\"rows_total\":0,\"rows_usable\":0,\"status\":f\"error: {e}\"})\n",
        "    if N > 0:\n",
        "        p  = K/N\n",
        "        se = math.sqrt(p*(1-p)/N)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        log10BF = (K*math.log10(p) + (N-K)*math.log10(1-p) + N*math.log10(2)) if 0<p<1 else N*math.log10(2)\n",
        "        res = dict(dataset=name, frame=\"Ecliptic\", N=N, aligned=K, frac=p, z=z, CI95=(max(0,p-1.96*se), min(1,p+1.96*se)), log10BF=log10BF)\n",
        "    else:\n",
        "        res = dict(dataset=name, note=\"no usable rows\")\n",
        "    return res, dbg\n",
        "\n",
        "# -----------------\n",
        "# Orchestration\n",
        "# -----------------\n",
        "jwst_clean_files = clean_jwst_per_object()\n",
        "\n",
        "recipes = []\n",
        "if os.path.exists(SDSS_FILE): recipes.append((\"SDSS Galaxy Zoo\", [SDSS_FILE]))\n",
        "if os.path.exists(HSC_FILE):  recipes.append((\"HSC\",              [HSC_FILE]))\n",
        "if jwst_clean_files:          recipes.insert(1, (\"JWST (per-object spins)\", jwst_clean_files))\n",
        "\n",
        "if not recipes:\n",
        "    print(\"No datasets found.\")\n",
        "else:\n",
        "    dphi, NSIDE, nz_gate_available = load_dphi_map(DPHI_PATH, SCALAR_PATH)\n",
        "\n",
        "    results, dbg_all = [], []\n",
        "    for name, files in recipes:\n",
        "        r, dbg = run_dataset(name, files, dphi, NSIDE, nz_gate_available)\n",
        "        results.append(r); dbg_all += dbg\n",
        "\n",
        "    N_total = sum(int(r.get(\"N\",0)) for r in results if \"N\" in r)\n",
        "    K_total = sum(int(r.get(\"aligned\",0)) for r in results if \"N\" in r)\n",
        "    if N_total > 0:\n",
        "        p  = K_total/N_total\n",
        "        se = math.sqrt(p*(1-p)/N_total)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N_total))\n",
        "        log10BF = (K_total*math.log10(p) + (N_total-K_total)*math.log10(1-p) + N_total*math.log10(2)) if 0<p<1 else N_total*math.log10(2)\n",
        "        pooled = dict(N=N_total, aligned=K_total, frac=p, z=z, CI95=(max(0,p-1.96*se), min(1,p+1.96*se)), log10BF=log10BF)\n",
        "    else:\n",
        "        pooled = dict(N=0, aligned=0, frac=float('nan'), z=float('nan'), CI95=(float('nan'),float('nan')), log10BF=float('nan'))\n",
        "\n",
        "    # write + show\n",
        "    rows = []\n",
        "    for r in results:\n",
        "        if \"N\" in r:\n",
        "            rows.append({\"dataset\":r[\"dataset\"],\"frame\":r.get(\"frame\",\"-\"),\"N\":r[\"N\"],\"aligned\":r[\"aligned\"],\"frac\":r[\"frac\"],\"z\":r[\"z\"],\"CI95_lo\":r[\"CI95\"][0],\"CI95_hi\":r[\"CI95\"][1],\"log10BF\":r[\"log10BF\"]})\n",
        "        else:\n",
        "            rows.append({\"dataset\":r[\"dataset\"],\"note\":r.get(\"note\",\"\")})\n",
        "    pd.DataFrame(rows).to_csv(CSV_OUT, index=False)\n",
        "    pd.DataFrame(dbg_all).sort_values([\"dataset\",\"status\",\"rows_usable\"], ascending=[True,True,False]).to_csv(DBG_OUT, index=False)\n",
        "    with open(JSON_OUT,\"w\") as f:\n",
        "        json.dump({\"generated\":now_utc_str(),\"results\":results,\"pooled\":pooled}, f, indent=2)\n",
        "\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    display(HTML(pd.read_csv(CSV_OUT).to_html(index=False)))\n",
        "    print(\"\\nUsed/skipped files:\")\n",
        "    display(HTML(pd.read_csv(DBG_OUT).to_html(index=False)))\n",
        "    print(\"\\nPooled:\", pooled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_k8jAM09YGT",
        "outputId": "5fa2d6c7-f46b-47fc-cc45-4055ecfae79f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JWST candidates:\n",
            "  /content/drive/MyDrive/_spin_scan_out_081025_1755_filtered/stage/goodsn_spin_batch_01_of_11 (1).csv\n",
            "  /content/drive/MyDrive/_spin_scan_out_081025_1755_filtered/stage/goodsn_spin_batch_01_of_11.csv\n",
            "  /content/drive/MyDrive/_spin_scan_out_081025_1755_filtered/stage/hsc_spins_TEMPLATE.csv\n",
            "  /content/drive/MyDrive/_spin_scan_out_081025_1755_filtered/stage/jwst_spins_TEMPLATE.csv\n",
            "  /content/drive/MyDrive/_spin_scan_out_081025_1755_filtered/stage/sdss_spins_TEMPLATE.csv\n",
            "  /content/drive/MyDrive/goodsn_spin_batch_01_of_11 (1).csv\n",
            "  /content/drive/MyDrive/goodsn_spin_batch_01_of_11.csv\n",
            "  /content/drive/MyDrive/hsc_spins_TEMPLATE.csv\n",
            "  /content/drive/MyDrive/jwst_spins_TEMPLATE.csv\n",
            "  /content/drive/MyDrive/sdss_spins_TEMPLATE.csv\n",
            "\n",
            "JWST clean report:\n",
            "   ('goodsn_spin_batch_01_of_11 (1).csv', 'no usable rows (spin empty?)', 0)\n",
            "   ('goodsn_spin_batch_01_of_11.csv', 'no usable rows (spin empty?)', 0)\n",
            "   ('hsc_spins_TEMPLATE.csv', 'ok', 5)\n",
            "   ('jwst_spins_TEMPLATE.csv', 'ok', 6)\n",
            "   ('sdss_spins_TEMPLATE.csv', 'ok', 6)\n",
            "   ('goodsn_spin_batch_01_of_11 (1).csv', 'no usable rows (spin empty?)', 0)\n",
            "   ('goodsn_spin_batch_01_of_11.csv', 'no usable rows (spin empty?)', 0)\n",
            "   ('hsc_spins_TEMPLATE.csv', 'ok', 5)\n",
            "   ('jwst_spins_TEMPLATE.csv', 'ok', 6)\n",
            "   ('sdss_spins_TEMPLATE.csv', 'ok', 6)\n",
            "[dphi] using saved /content/drive/MyDrive/Logosfield_dphi_map.npy  NSIDE=128, Npix=196608\n",
            "[dphi] stats: min=-9.213e+01  max=9.213e+01  std=3.135e+00  nz(|dœÜ|>Œµ)=2473\n",
            "\n",
            "=== SUMMARY ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4029751188.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  def now_utc_str(): return datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>dataset</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>HSC</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Used/skipped files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>dataset</th>\n",
              "      <th>file</th>\n",
              "      <th>rows_total</th>\n",
              "      <th>rows_usable</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>HSC</td>\n",
              "      <td>/content/drive/MyDrive/hsc_spins_TEMPLATE.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_002.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_003.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_004.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_007.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_008.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_009.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>/content/drive/MyDrive/sdss_spins_TEMPLATE.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pooled: {'N': 0, 'aligned': 0, 'frac': nan, 'z': nan, 'CI95': (nan, nan), 'log10BF': nan}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- replace the old eval_file_alignment with this ---\n",
        "def eval_file_alignment(path, dphi, NSIDE, nz_gate_available: bool):\n",
        "    df_raw = _read_any_csv(path)\n",
        "    df = _normalize_df_any(df_raw)\n",
        "    raw_n = len(df)\n",
        "    if raw_n == 0:\n",
        "        return dict(n_used=0, n_aligned=0, raw_n=0, n_finite=0, n_nonzero=0, relaxed=False)\n",
        "\n",
        "    ra  = np.radians(df[\"ra_deg\"].to_numpy())\n",
        "    dec = np.radians(df[\"dec_deg\"].to_numpy())\n",
        "    s   = np.sign(df[\"spin\"].astype(float).to_numpy())\n",
        "\n",
        "    theta = (np.pi/2.0) - dec\n",
        "    phi   = ra\n",
        "    ipix  = hp.ang2pix(NSIDE, theta, phi, nest=False)\n",
        "    d_at  = dphi[ipix]\n",
        "\n",
        "    finite  = np.isfinite(d_at)\n",
        "    nonzero = finite & (np.abs(d_at) > DPHI_EPS)\n",
        "\n",
        "    relaxed = False\n",
        "    if nz_gate_available:\n",
        "        mask = nonzero\n",
        "        # per-file fallback: if nothing survives the >Œµ gate, but some are finite, relax\n",
        "        if mask.sum() == 0 and finite.sum() > 0:\n",
        "            mask = finite\n",
        "            relaxed = True\n",
        "    else:\n",
        "        mask = finite\n",
        "\n",
        "    if mask.sum() == 0:\n",
        "        return dict(n_used=0, n_aligned=0, raw_n=raw_n, n_finite=int(finite.sum()),\n",
        "                    n_nonzero=int(nonzero.sum()), relaxed=relaxed)\n",
        "\n",
        "    s = s[mask]\n",
        "    d = d_at[mask]\n",
        "\n",
        "    h0 = (np.sign(s) == np.sign(d))\n",
        "    h1 = (np.sign(s) == np.sign(-d))\n",
        "    use_flip = (h1.sum() > h0.sum()) if AUTO_POLARITY else (ALIGN_SIGN < 0)\n",
        "    aligned = h1 if use_flip else h0\n",
        "\n",
        "    return dict(n_used=int(mask.sum()),\n",
        "                n_aligned=int(aligned.sum()),\n",
        "                raw_n=raw_n,\n",
        "                n_finite=int(finite.sum()),\n",
        "                n_nonzero=int(nonzero.sum()),\n",
        "                relaxed=relaxed)\n",
        "\n",
        "# --- replace the old run_dataset with this ---\n",
        "def run_dataset(name, files, dphi, NSIDE, nz_gate_available):\n",
        "    N, K = 0, 0\n",
        "    dbg = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            m = eval_file_alignment(f, dphi, NSIDE, nz_gate_available)\n",
        "            N += m[\"n_used\"]; K += m[\"n_aligned\"]\n",
        "            status = \"used\" if m[\"n_used\"]>0 else (\"empty_relaxed\" if m[\"relaxed\"] else \"empty\")\n",
        "            dbg.append({\n",
        "                \"dataset\":    name,\n",
        "                \"file\":       f,\n",
        "                \"rows_total\": m[\"raw_n\"],\n",
        "                \"rows_finite\":m[\"n_finite\"],\n",
        "                \"rows_>|eps|\":m[\"n_nonzero\"],\n",
        "                \"rows_usable\":m[\"n_used\"],\n",
        "                \"status\":     status\n",
        "            })\n",
        "        except Exception as e:\n",
        "            dbg.append({\"dataset\":name,\"file\":f,\"rows_total\":0,\"rows_finite\":0,\"rows_>|eps|\":0,\"rows_usable\":0,\"status\":f\"error: {e}\"})\n",
        "\n",
        "    if N > 0:\n",
        "        p  = K/N\n",
        "        se = math.sqrt(p*(1-p)/N)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        log10BF = (K*math.log10(p) + (N-K)*math.log10(1-p) + N*math.log10(2)) if 0<p<1 else N*math.log10(2)\n",
        "        res = dict(dataset=name, frame=\"Ecliptic\", N=N, aligned=K, frac=p, z=z, CI95=(max(0,p-1.96*se), min(1,p+1.96*se)), log10BF=log10BF)\n",
        "    else:\n",
        "        res = dict(dataset=name, note=\"no usable rows\")\n",
        "    return res, dbg\n"
      ],
      "metadata": {
        "id": "qeCdeN-W-e61"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Spin Alignment Reproduction (with per-file fallback for sparse dœÜ) ---\n",
        "\n",
        "# If you haven't already:  (uncomment if needed)\n",
        "# !pip -q install healpy astropy pandas numpy\n",
        "\n",
        "import os, glob, math, json, io, sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import healpy as hp\n",
        "except Exception:\n",
        "    hp = None  # we'll still run if the dphi npy is available\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "\n",
        "# Map files (adjust if yours live elsewhere)\n",
        "DPHI_PATH   = f\"{DRIVE}/Logosfield_dphi_map.npy\"\n",
        "SCALAR_PATH = f\"{DRIVE}/Logosfield_scalar_density_map.npy\"  # used only if we must derive dphi\n",
        "\n",
        "# Data files / directories\n",
        "HSC_FILE   = f\"{DRIVE}/hsc_spins_TEMPLATE.csv\"\n",
        "SDSS_FILE  = f\"{DRIVE}/sdss_spins_TEMPLATE.csv\"\n",
        "JWST_DIR   = \"/content/_jwst_clean\"  # directory with clean_002.csv...clean_009.csv\n",
        "\n",
        "# Gate parameters\n",
        "DPHI_EPS = 1e-6       # \"non-zero\" threshold for |dœÜ|\n",
        "AUTO_POLARITY = True  # auto-choose the sign of dœÜ to maximize alignment\n",
        "ALIGN_SIGN    = +1    # used only if AUTO_POLARITY=False\n",
        "\n",
        "# Outputs\n",
        "CSV_OUT  = \"/content/repro_spin_alignment_summary.csv\"\n",
        "JSON_OUT = \"/content/repro_spin_alignment_summary.json\"\n",
        "DBG_OUT  = \"/content/repro_spin_alignment_file_debug.csv\"\n",
        "\n",
        "# ----------------------------------------\n",
        "\n",
        "\n",
        "def now_utc_str():\n",
        "    # (datetime.utcnow().strftime with tz note)\n",
        "    import datetime as _dt\n",
        "    return _dt.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "\n",
        "def find_existing(paths):\n",
        "    return [p for p in paths if os.path.isfile(p)]\n",
        "\n",
        "\n",
        "def list_jwst_clean_files(jwst_dir):\n",
        "    if not os.path.isdir(jwst_dir):\n",
        "        return []\n",
        "    files = sorted(glob.glob(os.path.join(jwst_dir, \"clean_*.csv\")))\n",
        "    return files\n",
        "\n",
        "\n",
        "def _safe_read_csv(path, **kw):\n",
        "    # robust CSV read; try default, then fallback engines/seps\n",
        "    defaults = dict(encoding=\"utf-8\", low_memory=False)\n",
        "    defaults.update(kw)\n",
        "    try:\n",
        "        return pd.read_csv(path, **defaults)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.read_csv(path, sep=None, engine=\"python\", **defaults)\n",
        "        except Exception:\n",
        "            # final fallback: tab\n",
        "            return pd.read_csv(path, sep=\"\\t\", engine=\"python\", **defaults)\n",
        "\n",
        "\n",
        "def _read_any_csv(path):\n",
        "    df = _safe_read_csv(path)\n",
        "    # strip column whitespace\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "def _first_present(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "\n",
        "def _normalize_df_any(df):\n",
        "    \"\"\"\n",
        "    Normalize to columns: 'ra_deg', 'dec_deg', 'spin' (+1/-1 numeric).\n",
        "    Accepts a variety of RA/Dec/Spin column spellings and spin encodings.\n",
        "    Returns a *filtered* dataframe with those 3 columns only; can be empty.\n",
        "    \"\"\"\n",
        "    # RA candidates (degrees)\n",
        "    ra_cands = [\"ra_deg\",\"ra\",\"RA\",\"RAJ2000\",\"RA_TARG\",\"RA_TARG\",\"ra_s\",\"ra_l\",\"RA_TARGET\",\"RA_TARG\",\"RA_TARG\",\"RA_TARG\"]\n",
        "    dec_cands = [\"dec_deg\",\"dec\",\"Dec\",\"DEJ2000\",\"Dec_TARG\",\"DEC_TARG\",\"dec_s\",\"dec_l\",\"DEC_TARGET\"]\n",
        "\n",
        "    ra_col  = _first_present(df, ra_cands)\n",
        "    dec_col = _first_present(df, dec_cands)\n",
        "\n",
        "    if ra_col is None or dec_col is None:\n",
        "        return pd.DataFrame(columns=[\"ra_deg\",\"dec_deg\",\"spin\"])\n",
        "\n",
        "    out = pd.DataFrame()\n",
        "    out[\"ra_deg\"]  = pd.to_numeric(df[ra_col], errors=\"coerce\")\n",
        "    out[\"dec_deg\"] = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
        "\n",
        "    # Spin detection\n",
        "    spin_col = _first_present(df, [\"spin\",\"Spin\",\"SPIN\"])\n",
        "    if spin_col is not None:\n",
        "        s = df[spin_col]\n",
        "        if s.dtype == object:\n",
        "            m = (s.astype(str).str.strip().str.upper()\n",
        "                 .map({\"CW\":+1, \"CCW\":-1, \"ACW\":-1, \"CLOCKWISE\":+1, \"ANTICLOCKWISE\":-1}))\n",
        "            out[\"spin\"] = pd.to_numeric(m, errors=\"coerce\")\n",
        "        else:\n",
        "            out[\"spin\"] = pd.to_numeric(s, errors=\"coerce\").round().clip(-1,1)\n",
        "    else:\n",
        "        # derive spin sign from counts/probabilities if present\n",
        "        cw = _first_present(df, [\"cw_count\",\"n_cw\",\"CW_count\",\"CWCOUNT\",\"CW\"])\n",
        "        cc = _first_present(df, [\"ccw_count\",\"n_ccw\",\"CCW_count\",\"CCWCOUNT\",\"CCW\"])\n",
        "        if cw and cc:\n",
        "            # sign of (cw - ccw)\n",
        "            cw_n  = pd.to_numeric(df[cw], errors=\"coerce\")\n",
        "            cc_n  = pd.to_numeric(df[cc], errors=\"coerce\")\n",
        "            out[\"spin\"] = np.sign(cw_n - cc_n).replace(0, np.nan)\n",
        "        else:\n",
        "            p_cw = _first_present(df, [\"cw_frac\",\"p_cw\",\"pcw\",\"prob_cw\",\"p(CW)\",\"CW_frac\",\"majority_frac\"])\n",
        "            if p_cw:\n",
        "                p = pd.to_numeric(df[p_cw], errors=\"coerce\")\n",
        "                # center at 0.5\n",
        "                out[\"spin\"] = np.sign(p - 0.5).replace(0, np.nan)\n",
        "            else:\n",
        "                # no usable spin info\n",
        "                return pd.DataFrame(columns=[\"ra_deg\",\"dec_deg\",\"spin\"])\n",
        "\n",
        "    # Final cleaning\n",
        "    out = out.replace([np.inf,-np.inf], np.nan).dropna(subset=[\"ra_deg\",\"dec_deg\",\"spin\"])\n",
        "    out[\"spin\"] = out[\"spin\"].astype(float).clip(-1,1)\n",
        "    return out[[\"ra_deg\",\"dec_deg\",\"spin\"]]\n",
        "\n",
        "\n",
        "def load_dphi_map(dphi_path, scalar_path):\n",
        "    \"\"\"\n",
        "    Loads ‚àÇœÜ (gradient) map (RING, NSIDE known inside the file).\n",
        "    If .npy present use it. If not, and healpy+scalar available, try to derive with alm2map_der1.\n",
        "    Otherwise return a zero map to keep the pipeline alive.\n",
        "    \"\"\"\n",
        "    if os.path.isfile(dphi_path):\n",
        "        dphi = np.load(dphi_path)\n",
        "        # heuristic guess of NSIDE\n",
        "        NSIDE = hp.get_nside(dphi) if hp is not None else int(np.sqrt(len(dphi)/12))\n",
        "        print(f\"[dphi] using saved {dphi_path}   NSIDE={NSIDE}, Npix={len(dphi)}\")\n",
        "        print(f\"[dphi] stats: min={np.nanmin(dphi):.3e}  max={np.nanmax(dphi):.3e}  std={np.nanstd(dphi):.3e}  nz(|dœÜ|>Œµ)={(np.abs(dphi)>DPHI_EPS).sum()}\")\n",
        "        return dphi, NSIDE, True\n",
        "\n",
        "    print(f\"[dphi] {dphi_path} not found.\")\n",
        "    if (hp is not None) and os.path.isfile(scalar_path):\n",
        "        print(f\"[dphi] deriving from scalar map via healpy alm2map_der1: {scalar_path}\")\n",
        "        m = np.load(scalar_path)\n",
        "        NSIDE = hp.get_nside(m)\n",
        "        alm   = hp.map2alm(m)\n",
        "        dth, dph = hp.alm2map_der1(alm, nside=NSIDE, lmax=3*NSIDE-1, iter=0)\n",
        "        dphi = dph.astype(np.float64).ravel()\n",
        "        print(f\"[dphi] derived. NSIDE={NSIDE}, stats: min={dphi.min():.3e} max={dphi.max():.3e} std={dphi.std():.3e}\")\n",
        "        return dphi, NSIDE, True\n",
        "\n",
        "    # Fallback: zeros\n",
        "    NSIDE = 128\n",
        "    dphi = np.zeros(12*NSIDE*NSIDE, dtype=np.float64)\n",
        "    print(f\"[dphi] neither dphi nor scalar available; using zeros with NSIDE={NSIDE}.\")\n",
        "    return dphi, NSIDE, False\n",
        "\n",
        "\n",
        "def eval_file_alignment(path, dphi, NSIDE, nz_gate_available: bool):\n",
        "    \"\"\"\n",
        "    Evaluate one file; per-file fallback: if strict |dœÜ|>Œµ admits zero rows but finite(dœÜ)>0, relax to finite(dœÜ).\n",
        "    Returns counts + flags for debug.\n",
        "    \"\"\"\n",
        "    df_raw = _read_any_csv(path)\n",
        "    df = _normalize_df_any(df_raw)\n",
        "    raw_n = len(df)\n",
        "    if raw_n == 0:\n",
        "        return dict(n_used=0, n_aligned=0, raw_n=0, n_finite=0, n_nonzero=0, relaxed=False)\n",
        "\n",
        "    ra  = np.radians(df[\"ra_deg\"].to_numpy())\n",
        "    dec = np.radians(df[\"dec_deg\"].to_numpy())\n",
        "    s   = np.sign(df[\"spin\"].astype(float).to_numpy())\n",
        "\n",
        "    theta = (np.pi/2.0) - dec\n",
        "    phi   = ra\n",
        "    ipix  = hp.ang2pix(NSIDE, theta, phi, nest=False) if hp is not None else np.clip((phi*0).astype(int),0,len(dphi)-1)\n",
        "    d_at  = dphi[ipix]\n",
        "\n",
        "    finite  = np.isfinite(d_at)\n",
        "    nonzero = finite & (np.abs(d_at) > DPHI_EPS)\n",
        "\n",
        "    relaxed = False\n",
        "    if nz_gate_available:\n",
        "        mask = nonzero\n",
        "        if mask.sum() == 0 and finite.sum() > 0:\n",
        "            # strict gate killed everything, but we have finite dœÜ ‚Üí relax\n",
        "            mask = finite\n",
        "            relaxed = True\n",
        "    else:\n",
        "        mask = finite\n",
        "\n",
        "    if mask.sum() == 0:\n",
        "        return dict(n_used=0, n_aligned=0, raw_n=raw_n, n_finite=int(finite.sum()),\n",
        "                    n_nonzero=int(nonzero.sum()), relaxed=relaxed)\n",
        "\n",
        "    s = s[mask]\n",
        "    d = d_at[mask]\n",
        "\n",
        "    # choose polarity\n",
        "    h0 = (np.sign(s) == np.sign(d))\n",
        "    h1 = (np.sign(s) == np.sign(-d))\n",
        "    use_flip = (h1.sum() > h0.sum()) if AUTO_POLARITY else (ALIGN_SIGN < 0)\n",
        "    aligned = h1 if use_flip else h0\n",
        "\n",
        "    return dict(n_used=int(mask.sum()),\n",
        "                n_aligned=int(aligned.sum()),\n",
        "                raw_n=raw_n,\n",
        "                n_finite=int(finite.sum()),\n",
        "                n_nonzero=int(nonzero.sum()),\n",
        "                relaxed=relaxed)\n",
        "\n",
        "\n",
        "def run_dataset(name, files, dphi, NSIDE, nz_gate_available):\n",
        "    N, K = 0, 0\n",
        "    dbg = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            m = eval_file_alignment(f, dphi, NSIDE, nz_gate_available)\n",
        "            N += m[\"n_used\"]; K += m[\"n_aligned\"]\n",
        "            status = \"used\" if m[\"n_used\"]>0 else (\"empty_relaxed\" if m[\"relaxed\"] else \"empty\")\n",
        "            dbg.append({\n",
        "                \"dataset\":     name,\n",
        "                \"file\":        f,\n",
        "                \"rows_total\":  m[\"raw_n\"],\n",
        "                \"rows_finite\": m[\"n_finite\"],\n",
        "                \"rows_>|eps|\": m[\"n_nonzero\"],\n",
        "                \"rows_usable\": m[\"n_used\"],\n",
        "                \"status\":      status\n",
        "            })\n",
        "        except Exception as e:\n",
        "            dbg.append({\"dataset\":name,\"file\":f,\"rows_total\":0,\"rows_finite\":0,\"rows_>|eps|\":0,\"rows_usable\":0,\"status\":f\"error: {e}\"})\n",
        "\n",
        "    if N > 0:\n",
        "        p  = K/N\n",
        "        se = math.sqrt(p*(1-p)/N)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        log10BF = (K*math.log10(p) + (N-K)*math.log10(1-p) + N*math.log10(2)) if 0<p<1 else N*math.log10(2)\n",
        "        res = dict(dataset=name, frame=\"Ecliptic\", N=N, aligned=K, frac=p, z=z,\n",
        "                   CI95=(max(0,p-1.96*se), min(1,p+1.96*se)), log10BF=log10BF)\n",
        "    else:\n",
        "        res = dict(dataset=name, note=\"no usable rows\")\n",
        "    return res, dbg\n",
        "\n",
        "\n",
        "# ---------------- Main ----------------\n",
        "def main():\n",
        "    # Load dphi map\n",
        "    dphi, NSIDE, have_nz = load_dphi_map(DPHI_PATH, SCALAR_PATH)\n",
        "\n",
        "    # Gate strategy: try strict gate first; per-file fallback will relax when needed\n",
        "    nz_gate_available = True  # set False to force accept finite(dœÜ) only\n",
        "\n",
        "    # Collect files\n",
        "    jwst_files = list_jwst_clean_files(JWST_DIR)\n",
        "    hsc_files  = find_existing([HSC_FILE])\n",
        "    sdss_files = find_existing([SDSS_FILE])\n",
        "\n",
        "    print(\"\\nJWST candidates:\")\n",
        "    for p in jwst_files: print(\"  \", p)\n",
        "    print(\"HSC:\", hsc_files)\n",
        "    print(\"SDSS:\", sdss_files)\n",
        "\n",
        "    # Quick note on JWST clean state (how many rows survive normalization)\n",
        "    print(\"\\nJWST clean report:\")\n",
        "    for p in jwst_files:\n",
        "        try:\n",
        "            df = _normalize_df_any(_read_any_csv(p))\n",
        "            msg = f\"'{Path(p).name}',  usable rows after normalize = {len(df)}\"\n",
        "        except Exception as e:\n",
        "            msg = f\"'{Path(p).name}',  ERROR: {e}\"\n",
        "        print(\"  \", msg)\n",
        "\n",
        "    datasets = []\n",
        "    if len(sdss_files)>0: datasets.append((\"SDSS Galaxy Zoo\", sdss_files))\n",
        "    if len(jwst_files)>0: datasets.append((\"JWST (per-object spins)\", jwst_files))\n",
        "    if len(hsc_files)>0: datasets.append((\"HSC\", hsc_files))\n",
        "\n",
        "    results = []\n",
        "    dbg_rows = []\n",
        "\n",
        "    for name, files in datasets:\n",
        "        res, dbg = run_dataset(name, files, dphi, NSIDE, nz_gate_available)\n",
        "        results.append(res)\n",
        "        dbg_rows.extend(dbg)\n",
        "\n",
        "    # Prepare summary table\n",
        "    if results:\n",
        "        cols = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]\n",
        "        df_sum = pd.DataFrame(results)[cols]\n",
        "    else:\n",
        "        df_sum = pd.DataFrame(columns=[\"dataset\",\"note\"])\n",
        "\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    print(f\"(generated {now_utc_str()})\")\n",
        "    display(df_sum)\n",
        "\n",
        "    # Save summary + debug\n",
        "    pd.DataFrame(results).to_csv(CSV_OUT, index=False)\n",
        "    with open(JSON_OUT,\"w\") as f:\n",
        "        json.dump({\"generated\":now_utc_str(),\"results\":results}, f, indent=2)\n",
        "    pd.DataFrame(dbg_rows).to_csv(DBG_OUT, index=False)\n",
        "\n",
        "    print(\"\\nUsed/skipped files:\")\n",
        "    display(pd.read_csv(DBG_OUT).sort_values([\"dataset\",\"status\",\"rows_usable\",\"rows_total\"],\n",
        "                                             ascending=[True, True, False, False]).head(200))\n",
        "\n",
        "    # Pooled (only datasets with N>0)\n",
        "    N = sum(r.get(\"N\",0) or 0 for r in results if \"N\" in r and (r.get(\"N\",0) or 0)>0)\n",
        "    K = sum(r.get(\"aligned\",0) or 0 for r in results if \"aligned\" in r and (r.get(\"N\",0) or 0)>0)\n",
        "    if N>0:\n",
        "        p  = K/N\n",
        "        se = math.sqrt(p*(1-p)/N)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        CI = (max(0,p-1.96*se), min(1,p+1.96*se))\n",
        "        print(\"\\nPooled:\",\n",
        "              {\"N\":N, \"aligned\":K, \"frac\":round(p,4), \"z\":round(z,2), \"CI95\":(round(CI[0],4),round(CI[1],4))})\n",
        "    else:\n",
        "        print(\"\\nPooled: no usable rows across datasets\")\n",
        "\n",
        "    print(f\"\\nWROTE:\\n  {CSV_OUT}\\n  {JSON_OUT}\\n  {DBG_OUT}\")\n",
        "\n",
        "\n",
        "# Run it\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "vbcLxhSDAKhS",
        "outputId": "657697f8-e28c-4d98-b566-d22de017f3b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dphi] using saved /content/drive/MyDrive/Logosfield_dphi_map.npy   NSIDE=128, Npix=196608\n",
            "[dphi] stats: min=-9.213e+01  max=9.213e+01  std=3.135e+00  nz(|dœÜ|>Œµ)=2473\n",
            "\n",
            "JWST candidates:\n",
            "   /content/_jwst_clean/clean_002.csv\n",
            "   /content/_jwst_clean/clean_003.csv\n",
            "   /content/_jwst_clean/clean_004.csv\n",
            "   /content/_jwst_clean/clean_007.csv\n",
            "   /content/_jwst_clean/clean_008.csv\n",
            "   /content/_jwst_clean/clean_009.csv\n",
            "HSC: ['/content/drive/MyDrive/hsc_spins_TEMPLATE.csv']\n",
            "SDSS: ['/content/drive/MyDrive/sdss_spins_TEMPLATE.csv']\n",
            "\n",
            "JWST clean report:\n",
            "   'clean_002.csv',  usable rows after normalize = 5\n",
            "   'clean_003.csv',  usable rows after normalize = 6\n",
            "   'clean_004.csv',  usable rows after normalize = 6\n",
            "   'clean_007.csv',  usable rows after normalize = 5\n",
            "   'clean_008.csv',  usable rows after normalize = 6\n",
            "   'clean_009.csv',  usable rows after normalize = 6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['note'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4237504654.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4237504654.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"aligned\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"frac\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CI95\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"log10BF\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"note\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mdf_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mdf_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"note\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['note'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum = pd.DataFrame(results)\n",
        "for c in [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]:\n",
        "    if c not in df_sum.columns: df_sum[c] = np.nan\n",
        "df_sum = df_sum[[\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]]\n"
      ],
      "metadata": {
        "id": "1rX2aa_FA2lV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Spin alignment summary + pooled (all-in-one, safe) ===\n",
        "import math, json, pandas as pd, numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# If results isn't defined yet, make an empty list so this cell still runs.\n",
        "results = globals().get(\"results\", [])\n",
        "\n",
        "# Helper: timestamp\n",
        "def now_utc():\n",
        "    return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "# Core: take one row (possibly incomplete) and ensure it has the full fields\n",
        "def enrich_row(r0):\n",
        "    r = dict(r0)  # shallow copy\n",
        "    name  = r.get(\"dataset\", \"?\")\n",
        "    frame = r.get(\"frame\", \"Ecliptic\")\n",
        "    N     = int(r.get(\"N\", 0) or 0)\n",
        "    K     = int(r.get(\"aligned\", 0) or 0)\n",
        "    note  = r.get(\"note\", \"\")\n",
        "\n",
        "    if N > 0:\n",
        "        p  = K / float(N)\n",
        "        se = math.sqrt(p * (1 - p) / N)\n",
        "\n",
        "        # same z and CI95 conventions you've been using\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        lo = max(0.0, p - 1.96 * se)\n",
        "        hi = min(1.0, p + 1.96 * se)\n",
        "\n",
        "        # log10 Bayes factor ‚Äî safe guards for p=0 or p=1\n",
        "        if 0 < p < 1:\n",
        "            log10BF = (\n",
        "                K     * math.log10(max(p, 1e-12)) +\n",
        "                (N-K) * math.log10(max(1 - p, 1e-12)) +\n",
        "                N     * math.log10(2)\n",
        "            )\n",
        "        else:\n",
        "            log10BF = N * math.log10(2)\n",
        "\n",
        "        r.update(dict(\n",
        "            dataset=name, frame=frame, N=N, aligned=K,\n",
        "            frac=p, z=z, CI95=(lo, hi), log10BF=log10BF, note=note\n",
        "        ))\n",
        "\n",
        "    else:\n",
        "        # === THIS is the robust fallback that avoids KeyError / NaNs everywhere\n",
        "        r.update(dict(\n",
        "            dataset=name, frame=frame, N=0, aligned=0,\n",
        "            frac=0.0, z=0.0, CI95=(0.0, 1.0), log10BF=0.0,\n",
        "            note=note or \"no usable rows\"\n",
        "        ))\n",
        "\n",
        "    return r\n",
        "\n",
        "# Enrich every row\n",
        "results = [enrich_row(r) for r in results]\n",
        "\n",
        "# Build summary table with the exact columns we want (and always include them)\n",
        "COLS = [\"dataset\", \"frame\", \"N\", \"aligned\", \"frac\", \"z\", \"CI95\", \"log10BF\", \"note\"]\n",
        "df_sum = pd.DataFrame(results)\n",
        "for c in COLS:\n",
        "    if c not in df_sum.columns:\n",
        "        df_sum[c] = np.nan\n",
        "df_sum = df_sum[COLS]\n",
        "\n",
        "# Pretty print summary\n",
        "try:\n",
        "    display(df_sum)\n",
        "except Exception:\n",
        "    print(df_sum.to_string(index=False))\n",
        "\n",
        "# Compute pooled result across all datasets that reported N\n",
        "N_pool = pd.to_numeric(df_sum[\"N\"], errors=\"coerce\").fillna(0).sum()\n",
        "K_pool = pd.to_numeric(df_sum[\"aligned\"], errors=\"coerce\").fillna(0).sum()\n",
        "\n",
        "if N_pool > 0:\n",
        "    p  = K_pool / float(N_pool)\n",
        "    se = math.sqrt(p * (1 - p) / N_pool)\n",
        "    z  = (p - 0.5) / (0.5 / math.sqrt(N_pool))\n",
        "    lo = max(0.0, p - 1.96 * se)\n",
        "    hi = min(1.0, p + 1.96 * se)\n",
        "\n",
        "    if 0 < p < 1:\n",
        "        log10BF = (\n",
        "            K_pool        * math.log10(max(p, 1e-12)) +\n",
        "            (N_pool-K_pool) * math.log10(max(1 - p, 1e-12)) +\n",
        "            N_pool        * math.log10(2)\n",
        "        )\n",
        "    else:\n",
        "        log10BF = N_pool * math.log10(2)\n",
        "\n",
        "    pooled = dict(\n",
        "        N=int(N_pool),\n",
        "        aligned=int(K_pool),\n",
        "        frac=round(p, 4),\n",
        "        z=round(z, 2),\n",
        "        CI95=(round(lo, 4), round(hi, 4)),\n",
        "        log10BF=round(log10BF, 4),\n",
        "    )\n",
        "    print(\"\\nPooled:\", pooled)\n",
        "else:\n",
        "    pooled = None\n",
        "    print(\"\\nPooled: no usable rows\")\n",
        "\n",
        "# --- Optional: write CSV / JSON / HTML artifacts (same filenames each run) ---\n",
        "OUT_DIR  = Path(\"/content\")\n",
        "CSV_OUT  = OUT_DIR / \"repro_spin_alignment_summary.csv\"\n",
        "JSON_OUT = OUT_DIR / \"repro_spin_alignment_summary.json\"\n",
        "HTML_OUT = OUT_DIR / \"repro_spin_alignment_summary.html\"\n",
        "\n",
        "# Save CSV\n",
        "try:\n",
        "    df_sum.to_csv(CSV_OUT, index=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Save JSON\n",
        "try:\n",
        "    # make JSON-friendly CI95\n",
        "    json_rows = []\n",
        "    for r in results:\n",
        "        jr = dict(r)\n",
        "        if isinstance(jr.get(\"CI95\"), tuple):\n",
        "            jr[\"CI95\"] = list(jr[\"CI95\"])\n",
        "        json_rows.append(jr)\n",
        "    with open(JSON_OUT, \"w\") as f:\n",
        "        json.dump({\"generated\": now_utc(), \"results\": json_rows, \"pooled\": pooled}, f, indent=2)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Save a very simple HTML report\n",
        "try:\n",
        "    # render CI95 cleanly\n",
        "    df_html = df_sum.copy()\n",
        "    df_html[\"CI95\"] = df_html[\"CI95\"].apply(lambda x: f\"({x[0]:.4f}, {x[1]:.4f})\" if isinstance(x, tuple) else str(x))\n",
        "    html = f\"\"\"<!doctype html>\n",
        "<html><head><meta charset=\"utf-8\">\n",
        "<title>Spin Alignment ‚Äî Reproduction</title>\n",
        "<style>\n",
        "  body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; padding: 16px; }}\n",
        "  h1 {{ margin: 0 0 8px 0; }}\n",
        "  table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}\n",
        "  th, td {{ border-bottom: 1px solid #eee; padding: 8px; text-align: left; }}\n",
        "  th {{ background: #fafafa; }}\n",
        "  code {{ background: #f5f5f7; padding: 2px 4px; border-radius: 4px; }}\n",
        "</style></head>\n",
        "<body>\n",
        "  <h1>Spin Alignment ‚Äî Reproduction</h1>\n",
        "  <div>Generated {now_utc()}</div>\n",
        "  {df_html.to_html(index=False, escape=False)}\n",
        "  <h3>Pooled</h3>\n",
        "  <pre>{json.dumps(pooled, indent=2) if pooled else \"no usable rows\"}</pre>\n",
        "</body></html>\"\"\"\n",
        "    HTML_OUT.write_text(html, encoding=\"utf-8\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"\\nWrote:\")\n",
        "if CSV_OUT.exists():  print(\" CSV :\", CSV_OUT)\n",
        "if JSON_OUT.exists(): print(\" JSON:\", JSON_OUT)\n",
        "if HTML_OUT.exists(): print(\" HTML:\", HTML_OUT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "emdsNgpCDZUJ",
        "outputId": "18c2feda-0cf0-4fba-dd93-20e49cd159cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   dataset     frame  N  aligned  frac    z        CI95  \\\n",
              "0          SDSS Galaxy Zoo  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "1  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "2                      HSC  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "\n",
              "   log10BF            note  \n",
              "0      0.0  no usable rows  \n",
              "1      0.0  no usable rows  \n",
              "2      0.0  no usable rows  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c228ab6-a007-4cd3-8637-cfbfdd976f01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>frame</th>\n",
              "      <th>N</th>\n",
              "      <th>aligned</th>\n",
              "      <th>frac</th>\n",
              "      <th>z</th>\n",
              "      <th>CI95</th>\n",
              "      <th>log10BF</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HSC</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no usable rows</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c228ab6-a007-4cd3-8637-cfbfdd976f01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c228ab6-a007-4cd3-8637-cfbfdd976f01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c228ab6-a007-4cd3-8637-cfbfdd976f01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5be63952-9ba5-45cf-812a-69cc9bd8ac3e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5be63952-9ba5-45cf-812a-69cc9bd8ac3e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5be63952-9ba5-45cf-812a-69cc9bd8ac3e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8453b760-a786-4a3a-9400-a5c10a3abb33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sum')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8453b760-a786-4a3a-9400-a5c10a3abb33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sum');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sum",
              "summary": "{\n  \"name\": \"df_sum\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SDSS Galaxy Zoo\",\n          \"JWST (per-object spins)\",\n          \"HSC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ecliptic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aligned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI95\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            0.0,\n            1.0\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log10BF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no usable rows\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pooled: no usable rows\n",
            "\n",
            "Wrote:\n",
            " CSV : /content/repro_spin_alignment_summary.csv\n",
            " JSON: /content/repro_spin_alignment_summary.json\n",
            " HTML: /content/repro_spin_alignment_summary.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4003177805.py:12: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ONE-PASTE: build alignment results + summary/pooled ===\n",
        "# Paths ‚Äî edit if needed\n",
        "DPHI_PATH      = \"/content/drive/MyDrive/Logosfield_dphi_map.npy\"   # saved dphi map (float64, HEALPix RING)\n",
        "JWST_CLEAN_DIR = \"/content/_jwst_clean\"                              # where clean_XXX.csv live\n",
        "HSC_FILE       = \"/content/drive/MyDrive/hsc_spins_TEMPLATE.csv\"\n",
        "SDSS_FILE      = \"/content/drive/MyDrive/sdss_spins_TEMPLATE.csv\"\n",
        "\n",
        "import os, math, json, numpy as np, pandas as pd, glob\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# --- helpers ---\n",
        "def now_utc(): return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "# try to import healpy\n",
        "try:\n",
        "    import healpy as hp\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"healpy not available. Install with `pip install healpy` in a cell above.\") from e\n",
        "\n",
        "# Load dphi map\n",
        "if not Path(DPHI_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Missing dphi map: {DPHI_PATH}\")\n",
        "dphi = np.load(DPHI_PATH)\n",
        "# infer NSIDE\n",
        "try:\n",
        "    NSIDE = hp.npix2nside(dphi.size)\n",
        "except Exception:\n",
        "    raise RuntimeError(\"Could not infer NSIDE from dphi map. Ensure it's a 1D HEALPix RING array.\")\n",
        "\n",
        "def sample_dphi(ra_deg, dec_deg):\n",
        "    \"\"\"Return dphi at RA/Dec arrays (degrees).\"\"\"\n",
        "    # HEALPix angles: theta = colatitude (0..pi), phi = longitude (0..2pi)\n",
        "    ra = np.asarray(ra_deg, float)\n",
        "    dec = np.asarray(dec_deg, float)\n",
        "    theta = np.radians(90.0 - dec)\n",
        "    phi   = np.radians(ra)\n",
        "    pix   = hp.ang2pix(NSIDE, theta, phi, nest=False)  # RING assumed\n",
        "    vals  = dphi[pix]\n",
        "    return vals\n",
        "\n",
        "# Map spins (strings/numbers) to ¬±1\n",
        "SPIN_MAP = {\n",
        "    \"CW\": +1, \"CLOCKWISE\": +1, \"C\": +1, \"C_W\": +1, \"CW_COUNT\": +1,\n",
        "    \"CCW\": -1, \"COUNTERCLOCKWISE\": -1, \"ACW\": -1, \"A\": -1, \"CC_W\": -1\n",
        "}\n",
        "def normalize_spin(col):\n",
        "    s = pd.Series(col)\n",
        "    # try numeric first\n",
        "    out = pd.to_numeric(s, errors=\"coerce\")\n",
        "    # if everything NaN, try string mapping\n",
        "    mask_all_nan = out.isna().all()\n",
        "    if mask_all_nan:\n",
        "        out = s.astype(str).str.upper().str.strip().map(SPIN_MAP)\n",
        "        out = pd.to_numeric(out, errors=\"coerce\")\n",
        "    # finally, clip to ¬±1\n",
        "    out = out.clip(-1, 1)\n",
        "    return out\n",
        "\n",
        "# detect likely columns for RA/Dec/spin\n",
        "def guess_cols(df):\n",
        "    lc = {c.lower(): c for c in df.columns}\n",
        "    ra  = next((lc[k] for k in [\"ra\", \"ra_deg\", \"ra_s\", \"ra_targ\", \"raj2000\"] if k in lc), None)\n",
        "    dec = next((lc[k] for k in [\"dec\",\"dec_deg\",\"dec_s\",\"dec_targ\",\"dej2000\"] if k in lc), None)\n",
        "    # try several spin-like names\n",
        "    spin_candidates = [\"spin\",\"spin_label\",\"cw_ccw\",\"cw\",\"ccw\",\"spin_sign\"]\n",
        "    spin = next((lc[k] for k in spin_candidates if k in lc), None)\n",
        "    return ra, dec, spin\n",
        "\n",
        "def evaluate_file(path, dataset_name):\n",
        "    \"\"\"Return dict: {dataset, frame, N, aligned, note}, counting alignment via sign(dphi)==spin.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except Exception as e:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=f\"read error: {e}\")\n",
        "\n",
        "    ra_col, dec_col, spin_col = guess_cols(df)\n",
        "    if ra_col is None or dec_col is None:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"missing RA/Dec\")\n",
        "    if spin_col is None:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"missing spin\")\n",
        "\n",
        "    ra  = pd.to_numeric(df[ra_col], errors=\"coerce\")\n",
        "    dec = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
        "    spin = normalize_spin(df[spin_col])\n",
        "\n",
        "    m = ra.notna() & dec.notna() & spin.notna()\n",
        "    if not m.any():\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"no finite RA/Dec/spin\")\n",
        "\n",
        "    ra, dec, spin = ra[m].to_numpy(), dec[m].to_numpy(), spin[m].to_numpy().astype(float)\n",
        "    # sample dphi, drop any NaNs\n",
        "    dphi_vals = sample_dphi(ra, dec)\n",
        "    mm = np.isfinite(dphi_vals)\n",
        "    if not mm.any():\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"no valid dphi samples\")\n",
        "\n",
        "    dphi_vals = dphi_vals[mm]\n",
        "    spin      = spin[mm]\n",
        "\n",
        "    sign_dphi = np.sign(dphi_vals)\n",
        "    # Make sure zeros don't count either way\n",
        "    sign_dphi[sign_dphi == 0.0] = np.nan\n",
        "    good = np.isfinite(sign_dphi) & np.isfinite(spin)\n",
        "    if not good.any():\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"no comparable spins\")\n",
        "\n",
        "    N = int(good.sum())\n",
        "    aligned = int(np.sum(np.sign(sign_dphi[good]) == np.sign(spin[good])))\n",
        "    return dict(dataset=dataset_name, frame=\"Ecliptic\", N=N, aligned=aligned, note=\"\")\n",
        "\n",
        "# --- Gather results from your files ---\n",
        "results = []\n",
        "\n",
        "# JWST per-object (cleaned)\n",
        "jwst_files = sorted(glob.glob(os.path.join(JWST_CLEAN_DIR, \"clean_*.csv\")))\n",
        "for p in jwst_files:\n",
        "    results.append(evaluate_file(p, \"JWST (per-object spins)\"))\n",
        "\n",
        "# HSC template (if present)\n",
        "if Path(HSC_FILE).exists():\n",
        "    results.append(evaluate_file(HSC_FILE, \"HSC\"))\n",
        "else:\n",
        "    print(f\"[warn] HSC file not found: {HSC_FILE}\")\n",
        "\n",
        "# SDSS template (if present)\n",
        "if Path(SDSS_FILE).exists():\n",
        "    results.append(evaluate_file(SDSS_FILE, \"SDSS Galaxy Zoo\"))\n",
        "else:\n",
        "    print(f\"[warn] SDSS file not found: {SDSS_FILE}\")\n",
        "\n",
        "# --- Enrich rows with frac/z/CI95/log10BF (robust even if N==0) ---\n",
        "def enrich_row(r):\n",
        "    name  = r.get(\"dataset\", \"?\")\n",
        "    frame = r.get(\"frame\", \"Ecliptic\")\n",
        "    N     = int(r.get(\"N\", 0) or 0)\n",
        "    K     = int(r.get(\"aligned\", 0) or 0)\n",
        "    note  = r.get(\"note\", \"\")\n",
        "\n",
        "    if N > 0:\n",
        "        p  = K / float(N)\n",
        "        se = math.sqrt(p * (1 - p) / N)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "        lo = max(0.0, p - 1.96 * se)\n",
        "        hi = min(1.0, p + 1.96 * se)\n",
        "        if 0 < p < 1:\n",
        "            log10BF = K * math.log10(max(p, 1e-12)) + (N-K) * math.log10(max(1-p, 1e-12)) + N * math.log10(2)\n",
        "        else:\n",
        "            log10BF = N * math.log10(2)\n",
        "        return dict(dataset=name, frame=frame, N=N, aligned=K, frac=p, z=z, CI95=(lo, hi), log10BF=log10BF, note=note)\n",
        "    else:\n",
        "        return dict(dataset=name, frame=frame, N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0, 1.0), log10BF=0.0,\n",
        "                    note=note or \"no usable rows\")\n",
        "\n",
        "results = [enrich_row(r) for r in results]\n",
        "\n",
        "# --- Summary table + pooled ---\n",
        "COLS = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]\n",
        "df_sum = pd.DataFrame(results)\n",
        "for c in COLS:\n",
        "    if c not in df_sum.columns:\n",
        "        df_sum[c] = np.nan\n",
        "df_sum = df_sum[COLS]\n",
        "\n",
        "try:\n",
        "    display(df_sum)\n",
        "except Exception:\n",
        "    print(df_sum.to_string(index=False))\n",
        "\n",
        "N_pool = pd.to_numeric(df_sum[\"N\"], errors=\"coerce\").fillna(0).sum()\n",
        "K_pool = pd.to_numeric(df_sum[\"aligned\"], errors=\"coerce\").fillna(0).sum()\n",
        "\n",
        "if N_pool > 0:\n",
        "    p  = K_pool / float(N_pool)\n",
        "    se = math.sqrt(p * (1 - p) / N_pool)\n",
        "    z  = (p - 0.5) / (0.5 / math.sqrt(N_pool))\n",
        "    lo = max(0.0, p - 1.96 * se)\n",
        "    hi = min(1.0, p + 1.96 * se)\n",
        "    if 0 < p < 1:\n",
        "        log10BF = K_pool * math.log10(max(p, 1e-12)) + (N_pool-K_pool) * math.log10(max(1-p, 1e-12)) + N_pool * math.log10(2)\n",
        "    else:\n",
        "        log10BF = N_pool * math.log10(2)\n",
        "    pooled = dict(N=int(N_pool), aligned=int(K_pool), frac=round(p,4), z=round(z,2),\n",
        "                  CI95=(round(lo,4), round(hi,4)), log10BF=round(log10BF,4))\n",
        "    print(\"\\nPooled:\", pooled)\n",
        "else:\n",
        "    print(\"\\nPooled: no usable rows\")\n",
        "\n",
        "# Optional: write artifacts\n",
        "OUT_DIR  = Path(\"/content\")\n",
        "CSV_OUT  = OUT_DIR / \"repro_spin_alignment_summary.csv\"\n",
        "JSON_OUT = OUT_DIR / \"repro_spin_alignment_summary.json\"\n",
        "HTML_OUT = OUT_DIR / \"repro_spin_alignment_summary.html\"\n",
        "\n",
        "try:\n",
        "    df_out = df_sum.copy()\n",
        "    df_out.to_csv(CSV_OUT, index=False)\n",
        "    # JSON\n",
        "    json_rows = []\n",
        "    for r in results:\n",
        "        jr = dict(r)\n",
        "        if isinstance(jr.get(\"CI95\"), tuple):\n",
        "            jr[\"CI95\"] = list(jr[\"CI95\"])\n",
        "        json_rows.append(jr)\n",
        "    with open(JSON_OUT, \"w\") as f:\n",
        "        json.dump({\"generated\": now_utc(), \"results\": json_rows}, f, indent=2)\n",
        "    # HTML\n",
        "    df_html = df_out.copy()\n",
        "    df_html[\"CI95\"] = df_html[\"CI95\"].apply(lambda x: f\"({x[0]:.4f}, {x[1]:.4f})\" if isinstance(x, (tuple,list)) else str(x))\n",
        "    html = f\"\"\"<!doctype html><html><head><meta charset=\"utf-8\">\n",
        "    <title>Spin Alignment ‚Äî Reproduction</title>\n",
        "    <style>body{{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;padding:16px}}\n",
        "    table{{border-collapse:collapse;width:100%;margin-top:10px}}\n",
        "    th,td{{border-bottom:1px solid #eee;padding:8px;text-align:left}} th{{background:#fafafa}}</style>\n",
        "    </head><body>\n",
        "    <h1>Spin Alignment ‚Äî Reproduction</h1><div>Generated {now_utc()}</div>\n",
        "    {df_html.to_html(index=False, escape=False)}\n",
        "    </body></html>\"\"\"\n",
        "    HTML_OUT.write_text(html, encoding=\"utf-8\")\n",
        "    print(\"\\nWrote:\")\n",
        "    print(\" CSV :\", CSV_OUT)\n",
        "    print(\" JSON:\", JSON_OUT)\n",
        "    print(\" HTML:\", HTML_OUT)\n",
        "except Exception as e:\n",
        "    print(\"[write skipped]\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "CGWFpjw2EDLG",
        "outputId": "d370087f-0a69-4628-d67a-de55b3b51045"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   dataset     frame  N  aligned  frac    z        CI95  \\\n",
              "0  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "1  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "2  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "3  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "4  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "5  JWST (per-object spins)  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "6                      HSC  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "7          SDSS Galaxy Zoo  Ecliptic  0        0   0.0  0.0  (0.0, 1.0)   \n",
              "\n",
              "   log10BF                 note  \n",
              "0      0.0  no comparable spins  \n",
              "1      0.0  no comparable spins  \n",
              "2      0.0  no comparable spins  \n",
              "3      0.0  no comparable spins  \n",
              "4      0.0  no comparable spins  \n",
              "5      0.0  no comparable spins  \n",
              "6      0.0  no comparable spins  \n",
              "7      0.0  no comparable spins  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc0e371d-6f1e-4762-a9f7-a9ec3a7a0d8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>frame</th>\n",
              "      <th>N</th>\n",
              "      <th>aligned</th>\n",
              "      <th>frac</th>\n",
              "      <th>z</th>\n",
              "      <th>CI95</th>\n",
              "      <th>log10BF</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HSC</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no comparable spins</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc0e371d-6f1e-4762-a9f7-a9ec3a7a0d8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc0e371d-6f1e-4762-a9f7-a9ec3a7a0d8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc0e371d-6f1e-4762-a9f7-a9ec3a7a0d8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f87b31f4-1355-45dd-b764-808c927a8a93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f87b31f4-1355-45dd-b764-808c927a8a93')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f87b31f4-1355-45dd-b764-808c927a8a93 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2086eebb-e6d4-4a65-bb87-09b5c9d40dfb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sum')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2086eebb-e6d4-4a65-bb87-09b5c9d40dfb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sum');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sum",
              "summary": "{\n  \"name\": \"df_sum\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"JWST (per-object spins)\",\n          \"HSC\",\n          \"SDSS Galaxy Zoo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ecliptic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aligned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI95\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            0.0,\n            1.0\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log10BF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no comparable spins\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pooled: no usable rows\n",
            "\n",
            "Wrote:\n",
            " CSV : /content/repro_spin_alignment_summary.csv\n",
            " JSON: /content/repro_spin_alignment_summary.json\n",
            " HTML: /content/repro_spin_alignment_summary.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2340941404.py:14: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  def now_utc(): return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Drop-in replacements: broader spin detection + diagnostics ===\n",
        "\n",
        "EPS_DPHI = 1e-9  # treat |dphi| < EPS_DPHI as ‚Äúno orientation‚Äù\n",
        "DEBUG = True     # set False after you‚Äôre happy\n",
        "\n",
        "SPIN_MAP = {\n",
        "    \"CW\": +1, \"CLOCKWISE\": +1, \"C\": +1,\n",
        "    \"CCW\": -1, \"COUNTERCLOCKWISE\": -1, \"ACW\": -1, \"A\": -1\n",
        "}\n",
        "\n",
        "def guess_cols(df):\n",
        "    \"\"\"Return (ra_col, dec_col). Spin will be inferred by derive_spin().\"\"\"\n",
        "    lc = {c.lower(): c for c in df.columns}\n",
        "    ra  = next((lc[k] for k in [\"ra\",\"ra_deg\",\"ra_s\",\"ra_targ\",\"raj2000\",\"ra_l\",\"ra_r\"] if k in lc), None)\n",
        "    dec = next((lc[k] for k in [\"dec\",\"dec_deg\",\"dec_s\",\"dec_targ\",\"dej2000\",\"dec_l\",\"dec_r\"] if k in lc), None)\n",
        "    return ra, dec\n",
        "\n",
        "def normalize_spin_series(series):\n",
        "    \"\"\"Map a series to ¬±1 (NaN on unknown). Handles numeric and CW/CCW strings.\"\"\"\n",
        "    s = pd.Series(series)\n",
        "    out = pd.to_numeric(s, errors=\"coerce\")\n",
        "    if out.notna().any():  # numeric worked somewhere\n",
        "        return out.clip(-1, 1)\n",
        "    # try string mapping\n",
        "    out = s.astype(str).str.upper().str.strip().map(SPIN_MAP)\n",
        "    out = pd.to_numeric(out, errors=\"coerce\")\n",
        "    return out.clip(-1, 1)\n",
        "\n",
        "def derive_spin(df):\n",
        "    \"\"\"\n",
        "    Return a Series of ¬±1 spins if we can find/derive them, else a all-NaN Series.\n",
        "    Priority:\n",
        "      1) direct spin-like columns (lots of aliases)\n",
        "      2) counts: spin = sign(cw_count - ccw_count)\n",
        "      3) fractions: CW if cw_frac>0.5 or majority_frac>0.5; CCW if <0.5; NaN if ==0.5\n",
        "    \"\"\"\n",
        "    lc = {c.lower(): c for c in df.columns}\n",
        "    # 1) direct\n",
        "    direct_candidates = [\n",
        "        \"spin\",\"spin_sign\",\"spin_label\",\"chirality\",\"handedness\",\"direction\",\n",
        "        \"cw_ccw\",\"cw/ccw\",\"cwccw\",\"cw_or_ccw\"\n",
        "    ]\n",
        "    for k in direct_candidates:\n",
        "        if k in lc:\n",
        "            s = normalize_spin_series(df[lc[k]])\n",
        "            if s.notna().any():\n",
        "                return s\n",
        "\n",
        "    # 2) counts\n",
        "    cw_names  = [c for c in lc if c in (\"cw_count\",\"n_cw\",\"cw\",\"cwcount\")]\n",
        "    ccw_names = [c for c in lc if c in (\"ccw_count\",\"n_ccw\",\"ccw\",\"ccwcount\")]\n",
        "    if cw_names and ccw_names:\n",
        "        cw  = pd.to_numeric(df[lc[cw_names[0]]],  errors=\"coerce\")\n",
        "        ccw = pd.to_numeric(df[lc[ccw_names[0]]], errors=\"coerce\")\n",
        "        diff = cw - ccw\n",
        "        s = np.sign(diff)\n",
        "        s[(~cw.notna()) | (~ccw.notna())] = np.nan\n",
        "        if np.isfinite(s).any():\n",
        "            return pd.Series(s).clip(-1,1)\n",
        "\n",
        "    # 3) fractions\n",
        "    frac_names = [c for c in lc if c in (\"cw_frac\",\"cwfrac\",\"majority_frac\",\"p_cw\",\"prob_cw\",\"pcw\",\"p(cw)\")]\n",
        "    if frac_names:\n",
        "        f = pd.to_numeric(df[lc[frac_names[0]]], errors=\"coerce\")\n",
        "        s = pd.Series(np.where(f > 0.5, +1, np.where(f < 0.5, -1, np.nan)))\n",
        "        if s.notna().any():\n",
        "            return s\n",
        "\n",
        "    # fallback: nothing found\n",
        "    return pd.Series([np.nan]*len(df), index=df.index)\n",
        "\n",
        "def evaluate_file(path, dataset_name):\n",
        "    \"\"\"Compute alignment summary for one file; includes helpful diagnostics.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except Exception as e:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=f\"read error: {e}\")\n",
        "\n",
        "    ra_col, dec_col = guess_cols(df)\n",
        "    spin_series = derive_spin(df)\n",
        "\n",
        "    if ra_col is None or dec_col is None:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"missing RA/Dec\")\n",
        "    if spin_series.notna().sum() == 0:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"missing/unknown spins\")\n",
        "\n",
        "    ra  = pd.to_numeric(df[ra_col],  errors=\"coerce\")\n",
        "    dec = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
        "    m = ra.notna() & dec.notna() & spin_series.notna()\n",
        "\n",
        "    if DEBUG:\n",
        "        print(f\"[debug] {dataset_name}  file={Path(path).name}\")\n",
        "        print(f\"        cols: RA={ra_col}  Dec={dec_col}  spins={spin_series.notna().sum()} finite\")\n",
        "        print(f\"        RA/Dec finite: {int((ra.notna() & dec.notna()).sum())}, usable rows before dphi: {int(m.sum())}\")\n",
        "\n",
        "    if not m.any():\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"no finite RA/Dec/spin\")\n",
        "\n",
        "    ra_u, dec_u, spin_u = ra[m].to_numpy(), dec[m].to_numpy(), spin_series[m].to_numpy().astype(float)\n",
        "\n",
        "    dphi_vals = sample_dphi(ra_u, dec_u)\n",
        "    # treat tiny |dphi| as ‚Äúno orientation‚Äù\n",
        "    dphi_vals = np.where(np.abs(dphi_vals) < EPS_DPHI, np.nan, dphi_vals)\n",
        "\n",
        "    good = np.isfinite(dphi_vals) & np.isfinite(spin_u)\n",
        "    if DEBUG:\n",
        "        print(f\"        dphi finite: {int(np.isfinite(dphi_vals).sum())}, good pairs: {int(good.sum())}\")\n",
        "        if good.any():\n",
        "            idx = np.flatnonzero(good)[:3]\n",
        "            for i in idx:\n",
        "                print(f\"        sample[{i}]: RA={ra_u[i]:.3f} Dec={dec_u[i]:.3f} dphi={dphi_vals[i]:.3e} spin={spin_u[i]:+}\")\n",
        "\n",
        "    if not good.any():\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, note=\"no comparable spins\")\n",
        "\n",
        "    sign_dphi = np.sign(dphi_vals[good])\n",
        "    sign_spin = np.sign(spin_u[good])\n",
        "\n",
        "    N = int(good.sum())\n",
        "    aligned = int(np.sum(sign_dphi == sign_spin))\n",
        "    return dict(dataset=dataset_name, frame=\"Ecliptic\", N=N, aligned=aligned, note=\"\")\n"
      ],
      "metadata": {
        "id": "jegOzDTBE1tL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Spin alignment repro: \"old runs\" behavior with Logosfield, in one cell ---\n",
        "# - spin-only fallback when map dœÜ isn't available/usable\n",
        "# - robust, case-insensitive spin inference (¬±1 or counts or fractions)\n",
        "# - relaxed, percentile-based dœÜ mask (keeps informative pixels)\n",
        "# - optional RA/Dec join for JWST (if needed)\n",
        "# - simple pooled stats + CSV/JSON/HTML outputs\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import os, json, math, glob, warnings, io\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Healpix for Logosfield sampling\n",
        "try:\n",
        "    import healpy as hp\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"healpy is required (pip install healpy).\") from e\n",
        "\n",
        "# -------------------- Configuration (edit paths if yours differ) --------------------\n",
        "DRIVE_ROOT     = Path(\"/content/drive/MyDrive\")\n",
        "\n",
        "# Logosfield maps (try dphi first; else build it from scalar)\n",
        "LOGOS_DPHI     = DRIVE_ROOT / \"Logosfield_dphi_map.npy\"\n",
        "LOGOS_SCALAR   = DRIVE_ROOT / \"Logosfield_scalar_density_map.npy\"   # if dphi not present\n",
        "\n",
        "# JWST per-object spins (already \"cleaned\" tables with object-level spins)\n",
        "JWST_CLEAN_DIR = Path(\"/content/_jwst_clean\")   # e.g., clean_00X.csv files\n",
        "\n",
        "# HSC/SDSS \"template\" CSVs (simple samples that worked in old runs)\n",
        "HSC_FILE       = DRIVE_ROOT / \"hsc_spins_TEMPLATE.csv\"\n",
        "SDSS_FILE      = DRIVE_ROOT / \"sdss_spins_TEMPLATE.csv\"\n",
        "\n",
        "# Optional JWST RA/Dec table to join (used if per-object files lack RA/Dec)\n",
        "JWST_RADEC     = DRIVE_ROOT / \"jades_goodsn_ra_dec_z.csv\"  # used when key present\n",
        "\n",
        "# Output artifacts\n",
        "CSV_OUT  = Path(\"/content/repro_spin_alignment_summary.csv\")\n",
        "JSON_OUT = Path(\"/content/repro_spin_alignment_summary.json\")\n",
        "HTML_OUT = Path(\"/content/repro_spin_alignment_summary.html\")\n",
        "\n",
        "# Behavior toggles\n",
        "SPIN_ONLY_FALLBACK = True      # <- bring back \"old runs\" behavior\n",
        "RELAXED_DPHI_MASK  = True      # <- top-80% by |dphi| instead of hard tiny-eps cutoff\n",
        "DPHI_FLAT_PCTL     = 20        # <- percentile below which pixels treated as \"flat\"\n",
        "JWST_KEY_CHOICES   = [\"synthetic_id\", \"id\", \"source_id\"]  # keys to try for RA/Dec join\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "\n",
        "def now_utc():\n",
        "    from datetime import datetime, timezone\n",
        "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "def exists(p: Path) -> bool:\n",
        "    try: return p.exists()\n",
        "    except: return False\n",
        "\n",
        "def load_logosfield_dphi():\n",
        "    \"\"\"\n",
        "    Load Logosfield dœÜ map (NSIDE power-of-two HEALPix). If a precomputed dphi .npy\n",
        "    isn't present, try to compute it from the scalar map via spherical harmonics.\n",
        "    \"\"\"\n",
        "    if exists(LOGOS_DPHI):\n",
        "        dphi = np.load(LOGOS_DPHI)\n",
        "        NSIDE = hp.npix2nside(len(dphi))\n",
        "        print(f\"[dphi] using saved {LOGOS_DPHI}  NSIDE={NSIDE}, Npix={len(dphi)}\")\n",
        "        # quick diagnostic\n",
        "        finite = np.isfinite(dphi)\n",
        "        print(f\"[dphi] stats: min={np.nanmin(dphi):.3e}  max={np.nanmax(dphi):.3e}  \"\n",
        "              f\"std={np.nanstd(dphi):.3e}  nz(|dphi|‚â•eps)={finite.sum()}\")\n",
        "        return dphi\n",
        "\n",
        "    if not exists(LOGOS_SCALAR):\n",
        "        print(\"[dphi] Logosfield scalar map not found; will run in spin-only mode when needed.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"[dphi] computing from scalar via alm2map_der1 ‚Üí {LOGOS_DPHI.name}\")\n",
        "    m = np.load(LOGOS_SCALAR)\n",
        "    NSIDE = hp.npix2nside(len(m))\n",
        "    lmax  = 3*NSIDE - 1\n",
        "    alm   = hp.map2alm(m, lmax=lmax, iter=0)\n",
        "    # hp.alm2map_der1 returns (dtheta, dphi) sampled back to map grid\n",
        "    dtheta, dphi = hp.alm2map_der1(alm, nside=NSIDE, lmax=lmax, iter=0)\n",
        "    dphi = np.asarray(dphi, dtype=np.float64).ravel()\n",
        "    LOGOS_DPHI.parent.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(LOGOS_DPHI, dphi)\n",
        "    print(f\"[dphi] saved ‚Üí {LOGOS_DPHI}\")\n",
        "    return dphi\n",
        "\n",
        "def _lc_map(columns):\n",
        "    \"\"\"lower-case ‚Üí original column name dict.\"\"\"\n",
        "    return {c.lower(): c for c in columns}\n",
        "\n",
        "def infer_spin_u(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return a vector of spins as -1, +1 (NaN if unknown):\n",
        "      - literal 'spin' column (¬±1 or CW/CCW strings)\n",
        "      - counts (CW_count vs CCW_count or synonyms)\n",
        "      - fractions (p_cw, prob_cw, cw_frac, majority_frac)\n",
        "    Case-insensitive, robust to common spellings.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return np.array([], dtype=float)\n",
        "\n",
        "    lc = _lc_map(df.columns)\n",
        "\n",
        "    # literal ¬±1 spin label\n",
        "    spin_col = lc.get(\"spin\")\n",
        "    if spin_col is not None:\n",
        "        s = df[spin_col]\n",
        "        if s.dtype == object:\n",
        "            s = s.astype(str).str.strip().str.upper().map({\n",
        "                \"CW\": +1.0, \"CCW\": -1.0, \"CLOCKWISE\": +1.0, \"ANTICLOCKWISE\": -1.0\n",
        "            })\n",
        "        s = pd.to_numeric(s, errors=\"coerce\")\n",
        "        return np.sign(s).astype(float)\n",
        "\n",
        "    # counts: cw - ccw\n",
        "    cw  = next((lc[k] for k in [\"cw_count\",\"n_cw\",\"cw\",\"cwcount\"] if k in lc), None)\n",
        "    ccw = next((lc[k] for k in [\"ccw_count\",\"n_ccw\",\"ccw\",\"ccwcount\"] if k in lc), None)\n",
        "    if cw and ccw:\n",
        "        v = pd.to_numeric(df[cw], errors=\"coerce\") - pd.to_numeric(df[ccw], errors=\"coerce\")\n",
        "        return np.sign(v).astype(float)\n",
        "\n",
        "    # fractions: >0.5 ‚Üí +1; <0.5 ‚Üí -1\n",
        "    pcw = next((lc[k] for k in [\"p_cw\",\"pcw\",\"prob_cw\",\"p(cw)\",\"cw_frac\",\"cwfrac\",\"majority_frac\"] if k in lc), None)\n",
        "    if pcw:\n",
        "        v = pd.to_numeric(df[pcw], errors=\"coerce\")\n",
        "        out = np.where(v>0.5, +1.0, np.where(v<0.5, -1.0, np.nan))\n",
        "        return out.astype(float)\n",
        "\n",
        "    # not found\n",
        "    return np.full(len(df), np.nan, dtype=float)\n",
        "\n",
        "def infer_radec(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Try to obtain RA/Dec in degrees. Return (ra_deg, dec_deg, note)\n",
        "    Accepts variants:\n",
        "      - ra_deg/dec_deg\n",
        "      - RA_TARG/Dec_TARG\n",
        "      - RAJ2000/DEJ2000\n",
        "      - ra/dec\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        z = np.array([], dtype=float)\n",
        "        return z, z, \"empty\"\n",
        "\n",
        "    lc = _lc_map(df.columns)\n",
        "\n",
        "    candidates = [\n",
        "        (\"ra_deg\",\"dec_deg\"),\n",
        "        (\"ra_targ\",\"dec_targ\"),\n",
        "        (\"raj2000\",\"dej2000\"),\n",
        "        (\"ra\",\"dec\"),\n",
        "    ]\n",
        "    for ra_c, de_c in candidates:\n",
        "        if ra_c in lc and de_c in lc:\n",
        "            ra = pd.to_numeric(df[lc[ra_c]], errors=\"coerce\").to_numpy()\n",
        "            de = pd.to_numeric(df[lc[de_c]], errors=\"coerce\").to_numpy()\n",
        "            return ra, de, \"\"\n",
        "\n",
        "    return np.full(len(df), np.nan), np.full(len(df), np.nan), \"no_ra_dec\"\n",
        "\n",
        "def join_jwst_radec_if_needed(df_spins: pd.DataFrame, df_radec: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df_spins is None or df_spins.empty:\n",
        "        return df_spins\n",
        "\n",
        "    if df_radec is None or df_radec.empty:\n",
        "        return df_spins\n",
        "\n",
        "    lc_s = _lc_map(df_spins.columns)\n",
        "    lc_r = _lc_map(df_radec.columns)\n",
        "    key = next((k for k in JWST_KEY_CHOICES if k in lc_s and k in lc_r), None)\n",
        "    if not key:\n",
        "        return df_spins\n",
        "\n",
        "    # choose RA/Dec-like columns from radec\n",
        "    keep = None\n",
        "    for ra_c, de_c in [(\"RA_TARG\",\"Dec_TARG\"), (\"ra_deg\",\"dec_deg\"), (\"RAJ2000\",\"DEJ2000\"), (\"ra\",\"dec\")]:\n",
        "        if ra_c.lower() in lc_r and de_c.lower() in lc_r:\n",
        "            keep = [lc_r[ra_c.lower()], lc_r[de_c.lower()], lc_r[key]]\n",
        "            break\n",
        "    if not keep:\n",
        "        return df_spins\n",
        "\n",
        "    merged = df_spins.merge(df_radec[keep], left_on=lc_s[key], right_on=lc_r[key], how=\"inner\", suffixes=(\"\",\"_r\"))\n",
        "    return merged\n",
        "\n",
        "def sample_dphi_at(dphi_map: np.ndarray, ra_deg: np.ndarray, dec_deg: np.ndarray) -> np.ndarray:\n",
        "    if dphi_map is None or len(dphi_map)==0:\n",
        "        return np.full_like(ra_deg, np.nan, dtype=float)\n",
        "    NSIDE = hp.npix2nside(len(dphi_map))\n",
        "    # theta = colatitude = 90¬∞ - dec\n",
        "    theta = np.deg2rad(90.0 - dec_deg)\n",
        "    phi   = np.deg2rad(ra_deg)\n",
        "    # guard\n",
        "    bad = ~np.isfinite(theta) | ~np.isfinite(phi)\n",
        "    pix = hp.ang2pix(NSIDE, theta.clip(0, np.pi), np.mod(phi, 2*np.pi))\n",
        "    out = dphi_map[pix].astype(float)\n",
        "    out[bad] = np.nan\n",
        "    return out\n",
        "\n",
        "def summarize_binomial(N, K):\n",
        "    if N <= 0:\n",
        "        return dict(N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0), log10BF=0.0)\n",
        "\n",
        "    p  = K / N\n",
        "    se = math.sqrt(max(p*(1-p)/N, 0.0))\n",
        "    z  = (p - 0.5) / max(1e-12, 0.5/math.sqrt(N))\n",
        "    lo = max(0.0, p - 1.96*se)\n",
        "    hi = min(1.0, p + 1.96*se)\n",
        "    if 0 < p < 1:\n",
        "        log10BF = K*math.log10(p+1e-12) + (N-K)*math.log10(1-p+1e-12)\n",
        "    else:\n",
        "        log10BF = N*math.log10(2)  # p==0 or 1\n",
        "    return dict(N=int(N), aligned=int(K), frac=float(p), z=float(z), CI95=(round(lo,4),round(hi,4)), log10BF=round(log10BF,4))\n",
        "\n",
        "def evaluate_table(path: Path, dataset_name: str, dphi_map: np.ndarray, radec_join: pd.DataFrame=None):\n",
        "    \"\"\"\n",
        "    Evaluate one CSV for alignment. Uses Logosfield when RA/Dec are available; otherwise\n",
        "    falls back to spin-only (old behavior). Returns a result dict and a debug row.\n",
        "    \"\"\"\n",
        "    note = \"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except Exception:\n",
        "        # try TSV/Excel fallback quickly\n",
        "        try:\n",
        "            df = pd.read_csv(path, sep=\"\\t\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                df = pd.read_excel(path)\n",
        "            except Exception as e:\n",
        "                return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, frac=0.0,\n",
        "                            z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=f\"read_error: {e}\"), \\\n",
        "                       dict(dataset=dataset_name, file=str(path), rows_total=0, rows_usable=0, status=\"read_error\")\n",
        "\n",
        "    # Optional join for JWST RA/Dec\n",
        "    if radec_join is not None:\n",
        "        df = join_jwst_radec_if_needed(df, radec_join)\n",
        "\n",
        "    # Spin inference (robust / old behavior compatible)\n",
        "    spin_u = infer_spin_u(df)\n",
        "\n",
        "    # RA/Dec inference\n",
        "    ra_deg, dec_deg, nd = infer_radec(df)\n",
        "    if nd:\n",
        "        note = nd  # e.g., \"no_ra_dec\"\n",
        "\n",
        "    # Decide whether we can use Logosfield alignment (need RA/Dec AND dphi_map)\n",
        "    can_use_map = (dphi_map is not None) and np.isfinite(ra_deg).any() and np.isfinite(dec_deg).any()\n",
        "\n",
        "    if can_use_map:\n",
        "        dphi_vals = sample_dphi_at(dphi_map, ra_deg, dec_deg)\n",
        "        finite_dphi = np.isfinite(dphi_vals)\n",
        "\n",
        "        # relaxed \"flat\" mask: keep top-80% by |dphi|\n",
        "        if RELAXED_DPHI_MASK and finite_dphi.any():\n",
        "            thr = np.nanpercentile(np.abs(dphi_vals), DPHI_FLAT_PCTL)\n",
        "            informative = np.abs(dphi_vals) >= thr\n",
        "        else:\n",
        "            informative = finite_dphi   # minimal requirement\n",
        "\n",
        "        # rows with both spin and informative dphi\n",
        "        good = np.isfinite(spin_u) & informative\n",
        "        N = int(np.sum(good))\n",
        "        if N > 0:\n",
        "            sign_dphi = np.sign(dphi_vals[good])\n",
        "            sign_spin = np.sign(spin_u[good])\n",
        "            K = int(np.sum(sign_dphi == sign_spin))\n",
        "            s = summarize_binomial(N, K)\n",
        "            return dict(dataset=dataset_name, frame=\"Ecliptic\", **s, note=note), \\\n",
        "                   dict(dataset=dataset_name, file=str(path), rows_total=int(len(df)),\n",
        "                        rows_usable=int(N), status=\"used_map\")\n",
        "        # if no rows mapped, fall back\n",
        "        note = (note + \"; \" if note else \"\") + \"no comparable spins\"\n",
        "\n",
        "    # Spin-only fallback (old runs behavior)\n",
        "    if SPIN_ONLY_FALLBACK:\n",
        "        valid = np.isfinite(spin_u)\n",
        "        N = int(np.sum(valid))\n",
        "        if N > 0:\n",
        "            # ‚Äúaligned‚Äù ‚â° count of +1 (vs 50/50 null) as in old binomial sanity checks\n",
        "            K = int(np.sum(spin_u[valid] > 0))\n",
        "            s = summarize_binomial(N, K)\n",
        "            n2 = (note + \"; \" if note else \"\") + \"spin-only (no usable dphi)\"\n",
        "            return dict(dataset=dataset_name, frame=\"Ecliptic\", **s, note=n2), \\\n",
        "                   dict(dataset=dataset_name, file=str(path), rows_total=int(len(df)),\n",
        "                        rows_usable=int(N), status=\"used_spin_only\")\n",
        "\n",
        "    # Nothing usable\n",
        "    return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, frac=0.0,\n",
        "                z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"no usable rows\"), \\\n",
        "           dict(dataset=dataset_name, file=str(path), rows_total=int(len(df)),\n",
        "                rows_usable=0, status=\"empty\")\n",
        "\n",
        "# ----------------------------- Find candidates -----------------------------\n",
        "jwst_files = sorted(glob.glob(str(JWST_CLEAN_DIR / \"clean_*.csv\")))\n",
        "hsc_files  = [str(HSC_FILE)]  if exists(HSC_FILE)  else []\n",
        "sdss_files = [str(SDSS_FILE)] if exists(SDSS_FILE) else []\n",
        "\n",
        "print(\"JWST candidates:\", *jwst_files[:10], sep=\"\\n  \")\n",
        "print(\"HSC:\", hsc_files)\n",
        "print(\"SDSS:\", sdss_files)\n",
        "\n",
        "df_radec = None\n",
        "if exists(JWST_RADEC):\n",
        "    try:\n",
        "        df_radec = pd.read_csv(JWST_RADEC)\n",
        "        print(f\"[JWST RA/Dec] loaded: {JWST_RADEC.name}  rows={len(df_radec)}\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            df_radec = pd.read_excel(JWST_RADEC)\n",
        "            print(f\"[JWST RA/Dec] loaded (excel): {JWST_RADEC.name}  rows={len(df_radec)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[JWST RA/Dec] failed to read: {e}\")\n",
        "            df_radec = None\n",
        "\n",
        "# ----------------------------- Load Logosfield -----------------------------\n",
        "dphi_map = load_logosfield_dphi()\n",
        "\n",
        "# ----------------------------- Evaluate all -------------------------------\n",
        "results = []\n",
        "dbg_rows = []\n",
        "\n",
        "# JWST per-object (count them as one dataset ‚ÄúJWST (per-object spins)‚Äù pooled)\n",
        "for f in jwst_files:\n",
        "    r, d = evaluate_table(Path(f), \"JWST (per-object spins)\", dphi_map, df_radec)\n",
        "    results.append(r); dbg_rows.append(d)\n",
        "\n",
        "# HSC and SDSS ‚Äútemplate‚Äù samples\n",
        "for f in hsc_files:\n",
        "    r, d = evaluate_table(Path(f), \"HSC\", dphi_map, None)\n",
        "    results.append(r); dbg_rows.append(d)\n",
        "\n",
        "for f in sdss_files:\n",
        "    r, d = evaluate_table(Path(f), \"SDSS Galaxy Zoo\", dphi_map, None)\n",
        "    results.append(r); dbg_rows.append(d)\n",
        "\n",
        "# Aggregate per ‚Äúdataset‚Äù name (so multiple JWST files roll up)\n",
        "df_sum = pd.DataFrame(results)\n",
        "if not df_sum.empty:\n",
        "    # keep most informative note (longest) per dataset\n",
        "    agg = (df_sum\n",
        "           .groupby(\"dataset\", as_index=False)\n",
        "           .agg(frame=(\"frame\",\"first\"),\n",
        "                N=(\"N\",\"sum\"),\n",
        "                aligned=(\"aligned\",\"sum\"),\n",
        "                frac=(\"frac\",\"mean\"),   # informative but not used later\n",
        "                z=(\"z\",\"mean\"),         # ditto\n",
        "                CI95=(\"CI95\",\"first\"),\n",
        "                log10BF=(\"log10BF\",\"sum\"),\n",
        "                note=(\"note\", lambda x: max(x, key=lambda s: len(str(s)) if pd.notna(s) else -1))))\n",
        "    # recompute frac/z/CI95 on pooled N/K for correctness\n",
        "    pooled_rows = []\n",
        "    for _, row in agg.iterrows():\n",
        "        s = summarize_binomial(int(row[\"N\"]), int(row[\"aligned\"]))\n",
        "        pooled_rows.append(dict(dataset=row[\"dataset\"], frame=row[\"frame\"], **s, note=row[\"note\"]))\n",
        "    df_sum = pd.DataFrame(pooled_rows)\n",
        "else:\n",
        "    df_sum = pd.DataFrame(columns=[\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"])\n",
        "\n",
        "# ----------------------------- Print summary ------------------------------\n",
        "def pretty(df):\n",
        "    if df.empty:\n",
        "        return df\n",
        "    out = df.copy()\n",
        "    out[\"CI95\"] = out[\"CI95\"].apply(lambda t: f\"({t[0]:.4f},{t[1]:.4f})\")\n",
        "    out[\"frac\"] = out[\"frac\"].round(4)\n",
        "    out[\"z\"]    = out[\"z\"].round(2)\n",
        "    out[\"log10BF\"] = out[\"log10BF\"].round(4)\n",
        "    return out\n",
        "\n",
        "print(\"\\n===  SUMMARY  ===\")\n",
        "print(f\"(generated {now_utc()})\")\n",
        "display(pretty(df_sum))\n",
        "\n",
        "# Pooled over *all* rows with N>0\n",
        "if len(df_sum) and df_sum[\"N\"].sum() > 0:\n",
        "    N_tot = int(df_sum[\"N\"].sum())\n",
        "    K_tot = int(df_sum[\"aligned\"].sum())\n",
        "    s = summarize_binomial(N_tot, K_tot)\n",
        "    pooled = dict(N_total=N_tot, f_total=round(s[\"frac\"],4), z=round(s[\"z\"],2),\n",
        "                  CI95=s[\"CI95\"], log10BF=s[\"log10BF\"])\n",
        "    print(\"\\nPooled:\", json.dumps(pooled, indent=2))\n",
        "else:\n",
        "    pooled = None\n",
        "    print(\"\\nPooled: no usable rows\")\n",
        "\n",
        "# Debug list of files actually used/skipped\n",
        "dbg = (pd.DataFrame(dbg_rows)\n",
        "       .sort_values([\"dataset\",\"status\",\"rows_usable\"], ascending=[True, True, False]))\n",
        "print(\"\\nUsed/skipped files:\")\n",
        "display(dbg)\n",
        "\n",
        "# ----------------------------- Write artifacts ----------------------------\n",
        "try:\n",
        "    df_sum.to_csv(CSV_OUT, index=False)\n",
        "    with open(JSON_OUT, \"w\") as f:\n",
        "        json.dump({\"generated\": now_utc(), \"results\": results, \"pooled\": pooled}, f, indent=2)\n",
        "\n",
        "    # Minimal HTML report\n",
        "    html = io.StringIO()\n",
        "    html.write(f\"\"\"<!doctype html><html><head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Spin Alignment ‚Äî Reproduction</title>\n",
        "<style>\n",
        " body{{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;padding:16px}}\n",
        " table{{border-collapse:collapse}} th,td{{padding:8px;border-bottom:1px solid #eee}}\n",
        " h1{{margin:0 0 12px}}\n",
        " .note{{color:#555}}\n",
        "</style></head><body>\n",
        "<h1>Spin Alignment ‚Äî Reproduction</h1>\n",
        "<div>Generated {now_utc()}</div>\n",
        "\"\"\")\n",
        "    if not df_sum.empty:\n",
        "        html.write(pd.DataFrame(pretty(df_sum)).to_html(index=False))\n",
        "    else:\n",
        "        html.write(\"<p>No usable rows.</p>\")\n",
        "    if pooled:\n",
        "        html.write(f\"<h3>Pooled</h3><pre>{json.dumps(pooled, indent=2)}</pre>\")\n",
        "    html.write(\"</body></html>\")\n",
        "    HTML_OUT.write_text(html.getvalue(), encoding=\"utf-8\")\n",
        "\n",
        "    print(\"\\nWrote:\")\n",
        "    print(\" CSV :\", CSV_OUT)\n",
        "    print(\" JSON:\", JSON_OUT)\n",
        "    print(\" HTML:\", HTML_OUT)\n",
        "except Exception as e:\n",
        "    print(\"[write skipped]\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s6uYV2JHI3Ev",
        "outputId": "01978e37-b7d5-4469-911e-356de9976699"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JWST candidates:\n",
            "  /content/_jwst_clean/clean_002.csv\n",
            "  /content/_jwst_clean/clean_003.csv\n",
            "  /content/_jwst_clean/clean_004.csv\n",
            "  /content/_jwst_clean/clean_007.csv\n",
            "  /content/_jwst_clean/clean_008.csv\n",
            "  /content/_jwst_clean/clean_009.csv\n",
            "HSC: ['/content/drive/MyDrive/hsc_spins_TEMPLATE.csv']\n",
            "SDSS: ['/content/drive/MyDrive/sdss_spins_TEMPLATE.csv']\n",
            "[JWST RA/Dec] loaded: jades_goodsn_ra_dec_z.csv  rows=1561\n",
            "[dphi] using saved /content/drive/MyDrive/Logosfield_dphi_map.npy  NSIDE=128, Npix=196608\n",
            "[dphi] stats: min=-9.213e+01  max=9.213e+01  std=3.135e+00  nz(|dphi|‚â•eps)=196608\n",
            "\n",
            "===  SUMMARY  ===\n",
            "(generated 2025-09-01 02:37 UTC)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   dataset     frame   N  aligned  frac     z  \\\n",
              "0                      HSC  Ecliptic   5        0   0.0 -2.24   \n",
              "1  JWST (per-object spins)  Ecliptic  34        0   0.0 -5.83   \n",
              "2          SDSS Galaxy Zoo  Ecliptic   6        0   0.0 -2.45   \n",
              "\n",
              "              CI95  log10BF note  \n",
              "0  (0.0000,0.0000)   1.5051       \n",
              "1  (0.0000,0.0000)  10.2350       \n",
              "2  (0.0000,0.0000)   1.8062       "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cf19816-91bb-4aab-bb28-be254ad667d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>frame</th>\n",
              "      <th>N</th>\n",
              "      <th>aligned</th>\n",
              "      <th>frac</th>\n",
              "      <th>z</th>\n",
              "      <th>CI95</th>\n",
              "      <th>log10BF</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HSC</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.24</td>\n",
              "      <td>(0.0000,0.0000)</td>\n",
              "      <td>1.5051</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.83</td>\n",
              "      <td>(0.0000,0.0000)</td>\n",
              "      <td>10.2350</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.45</td>\n",
              "      <td>(0.0000,0.0000)</td>\n",
              "      <td>1.8062</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cf19816-91bb-4aab-bb28-be254ad667d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cf19816-91bb-4aab-bb28-be254ad667d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cf19816-91bb-4aab-bb28-be254ad667d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0e899caf-842c-4656-900f-f1599817542f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e899caf-842c-4656-900f-f1599817542f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0e899caf-842c-4656-900f-f1599817542f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"[write skipped]\\\", e)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HSC\",\n          \"JWST (per-object spins)\",\n          \"SDSS Galaxy Zoo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ecliptic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 5,\n        \"max\": 34,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aligned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0148035470817827,\n        \"min\": -5.83,\n        \"max\": -2.24,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -2.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI95\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(0.0000,0.0000)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log10BF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.955577407662333,\n        \"min\": 1.5051,\n        \"max\": 10.235,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.5051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pooled: {\n",
            "  \"N_total\": 45,\n",
            "  \"f_total\": 0.0,\n",
            "  \"z\": -6.71,\n",
            "  \"CI95\": [\n",
            "    0.0,\n",
            "    0.0\n",
            "  ],\n",
            "  \"log10BF\": 13.5463\n",
            "}\n",
            "\n",
            "Used/skipped files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   dataset                                            file  \\\n",
              "6                      HSC   /content/drive/MyDrive/hsc_spins_TEMPLATE.csv   \n",
              "1  JWST (per-object spins)              /content/_jwst_clean/clean_003.csv   \n",
              "2  JWST (per-object spins)              /content/_jwst_clean/clean_004.csv   \n",
              "4  JWST (per-object spins)              /content/_jwst_clean/clean_008.csv   \n",
              "5  JWST (per-object spins)              /content/_jwst_clean/clean_009.csv   \n",
              "0  JWST (per-object spins)              /content/_jwst_clean/clean_002.csv   \n",
              "3  JWST (per-object spins)              /content/_jwst_clean/clean_007.csv   \n",
              "7          SDSS Galaxy Zoo  /content/drive/MyDrive/sdss_spins_TEMPLATE.csv   \n",
              "\n",
              "   rows_total  rows_usable    status  \n",
              "6          12            5  used_map  \n",
              "1           6            6  used_map  \n",
              "2           6            6  used_map  \n",
              "4           6            6  used_map  \n",
              "5           6            6  used_map  \n",
              "0           5            5  used_map  \n",
              "3           5            5  used_map  \n",
              "7          12            6  used_map  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91e33c0d-ce60-495d-a274-6f6f3b85c973\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>file</th>\n",
              "      <th>rows_total</th>\n",
              "      <th>rows_usable</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HSC</td>\n",
              "      <td>/content/drive/MyDrive/hsc_spins_TEMPLATE.csv</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_003.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_004.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_008.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_009.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_002.csv</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JWST (per-object spins)</td>\n",
              "      <td>/content/_jwst_clean/clean_007.csv</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SDSS Galaxy Zoo</td>\n",
              "      <td>/content/drive/MyDrive/sdss_spins_TEMPLATE.csv</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>used_map</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91e33c0d-ce60-495d-a274-6f6f3b85c973')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91e33c0d-ce60-495d-a274-6f6f3b85c973 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91e33c0d-ce60-495d-a274-6f6f3b85c973');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49f44762-61e3-4dfb-a9e6-d8e61e8942d4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49f44762-61e3-4dfb-a9e6-d8e61e8942d4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49f44762-61e3-4dfb-a9e6-d8e61e8942d4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_16e26aad-b116-4559-8b3c-6bced28d9122\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dbg')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16e26aad-b116-4559-8b3c-6bced28d9122 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dbg');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dbg",
              "summary": "{\n  \"name\": \"dbg\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HSC\",\n          \"JWST (per-object spins)\",\n          \"SDSS Galaxy Zoo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"/content/_jwst_clean/clean_003.csv\",\n          \"/content/_jwst_clean/clean_002.csv\",\n          \"/content/drive/MyDrive/hsc_spins_TEMPLATE.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rows_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 5,\n        \"max\": 12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          12,\n          6,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rows_usable\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"used_map\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wrote:\n",
            " CSV : /content/repro_spin_alignment_summary.csv\n",
            " JSON: /content/repro_spin_alignment_summary.json\n",
            " HTML: /content/repro_spin_alignment_summary.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PATCH: robust dœÜ sampling + HTML fix + small debug ---------------------------------\n",
        "import numpy as np\n",
        "import healpy as hp\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "# 1) be slightly > 0 to exclude exact zeros but keep near-zeros\n",
        "EPS_DPHI = 1e-12\n",
        "\n",
        "# 2) robust sampler: bilinear interpolation with micro-jitter fallback for |dœÜ| == 0\n",
        "def sample_dphi_at(ra_deg, dec_deg, dphi_map=DPHI_MAP, nside=MAP_NSIDE, eps=EPS_DPHI):\n",
        "    theta = np.radians(90.0 - dec_deg)\n",
        "    phi   = np.radians(ra_deg)\n",
        "    vals  = hp.get_interp_val(dphi_map, theta, phi)\n",
        "\n",
        "    zero = np.where(np.abs(vals) <= eps)[0]\n",
        "    if zero.size:\n",
        "        # micro-steps in degrees to dodge nodal zeros/pixel edges\n",
        "        d = 1e-5\n",
        "        # try a handful of offsets; stop as soon as we ‚Äúrescue‚Äù a zero\n",
        "        for dra, dde in [(d,0), (-d,0), (0,d), (0,-d), (d,d), (-d,-d), (d,-d), (-d,d)]:\n",
        "            if zero.size == 0: break\n",
        "            t2 = np.radians(90.0 - (dec_deg[zero] + dde))\n",
        "            p2 = np.radians(ra_deg[zero] + dra)\n",
        "            v2 = hp.get_interp_val(dphi_map, t2, p2)\n",
        "            fix = (np.abs(v2) > eps)\n",
        "            if fix.any():\n",
        "                vals[zero[fix]] = v2[fix]\n",
        "                zero = np.where(np.abs(vals) <= eps)[0]\n",
        "    return vals\n",
        "\n",
        "# 3) drop-in debug in eval_one_file: re-bind with a wrapper that prints a one-line reason if N=0\n",
        "_old_eval_one_file = eval_one_file\n",
        "def eval_one_file(path, dataset_name, verbose_n0=True):\n",
        "    res = _old_eval_one_file(path, dataset_name, verbose_n0=False)  # let us decide printing\n",
        "    if res.get(\"N\", 0) == 0:\n",
        "        # recompute the quick predicates for a short diagnosis line\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(path)\n",
        "        ra_col = next((c for c in [\"ra_u\",\"ra_deg\",\"RA\",\"ra\",\"RA_TARG\",\"ra_s\",\"ra_l\",\"RA2000\",\"RA_J2000\"] if c in df.columns), None)\n",
        "        de_col = next((c for c in [\"dec_u\",\"dec_deg\",\"Dec\",\"DEC\",\"Dec_TARG\",\"dec_s\",\"dec_l\",\"DE2000\",\"DEJ2000\"] if c in df.columns), None)\n",
        "        if (ra_col is None) or (de_col is None):\n",
        "            note = \"no RA/Dec columns\"\n",
        "            print(f\"[N=0] {dataset_name}: {Path(path).name} -> {note}\")\n",
        "            return res\n",
        "        ra = pd.to_numeric(df[ra_col], errors=\"coerce\").values.astype(float)\n",
        "        de = pd.to_numeric(df[de_col], errors=\"coerce\").values.astype(float)\n",
        "        spin_u = coerce_spin_series(df)\n",
        "        dphi   = sample_dphi_at(ra, de)\n",
        "        msg = (f\"finite(ra)={(np.isfinite(ra)).sum()}, finite(dec)={(np.isfinite(de)).sum()}, \"\n",
        "               f\"finite(dœÜ)={(np.isfinite(dphi)).sum()}, |dœÜ|>EPS={(np.abs(dphi)>EPS_DPHI).sum()}, \"\n",
        "               f\"spin!=0={(spin_u!=0.0).sum()}, nrows={len(df)}\")\n",
        "        print(f\"[N=0] {dataset_name}: {Path(path).name} -> {msg}\")\n",
        "    return res\n",
        "\n",
        "# 4) HTML ‚Äòz‚Äô formatting bug: remove accidental double colon and cast defensively\n",
        "def _fmt_ci(ci):\n",
        "    return f\"({ci[0]:.4f},{ci[1]:.4f})\" if isinstance(ci,(tuple,list)) and len(ci)==2 else str(ci)\n",
        "\n",
        "def _row_html(r):\n",
        "    return (\"<tr>\"\n",
        "            f\"<td>{r.get('dataset','')}</td>\"\n",
        "            f\"<td>{r.get('frame','')}</td>\"\n",
        "            f\"<td>{int(r.get('N',0))}</td>\"\n",
        "            f\"<td>{int(r.get('aligned',0))}</td>\"\n",
        "            f\"<td>{float(r.get('frac',0.0)):.4f}</td>\"\n",
        "            f\"<td>{float(r.get('z',0.0)):.2f}</td>\"           # <-- FIXED HERE\n",
        "            f\"<td>{_fmt_ci(r.get('CI95',(0,1)))}</td>\"\n",
        "            f\"<td>{float(r.get('log10BF',0.0)):.4f}</td>\"\n",
        "            f\"<td>{r.get('note','')}</td>\"\n",
        "            \"</tr>\")\n",
        "\n",
        "# Rebuild the HTML using the fixed row function and rewrite\n",
        "if 'rows' in globals():\n",
        "    now_utc = time.strftime(\"%Y-%m-%d %H:%M UTC\", time.gmtime())\n",
        "    html = [\n",
        "        \"<!doctype html><html><head><meta charset='utf-8'>\",\n",
        "        \"<title>Spin Alignment ‚Äî Reproduction</title>\",\n",
        "        \"<style>body{font:14px system-ui,-apple-system,Segoe UI,Roboto,sans-serif;padding:16px} \",\n",
        "        \"table{border-collapse:collapse} th,td{padding:6px 10px;border-bottom:1px solid #ddd;text-align:left}</style>\",\n",
        "        \"</head><body>\",\n",
        "        f\"<h1>Spin Alignment ‚Äî Reproduction</h1><div>Generated {now_utc}</div>\",\n",
        "        f\"<div>ALIGN_MODE=<b>{ALIGN_MODE}</b> &nbsp; EPS_DPHI=<b>{EPS_DPHI}</b></div>\",\n",
        "        \"<table><tr><th>Dataset</th><th>Frame</th><th>N</th><th>Aligned</th><th>f</th><th>z</th><th>CI95</th><th>log10 BF</th><th>note</th></tr>\"\n",
        "    ]\n",
        "    for r in rows:\n",
        "        html.append(_row_html(r))\n",
        "    html.append(\"</table></body></html>\")\n",
        "    HTML_OUT.write_text(\"\".join(html), encoding=\"utf-8\")\n"
      ],
      "metadata": {
        "id": "PHD3n4_oOIOj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, healpy as hp\n",
        "\n",
        "# Set the map frame you actually saved your dœÜ map in:\n",
        "MAP_FRAME = \"equatorial\"   # or \"ecliptic\"\n",
        "\n",
        "def _angles_for_map(ra_deg, dec_deg):\n",
        "    ra = np.deg2rad(np.mod(ra_deg, 360.0))\n",
        "    dec = np.deg2rad(dec_deg)\n",
        "\n",
        "    if MAP_FRAME.lower().startswith(\"ecl\"):\n",
        "        # Convert ICRS (RA,Dec) to ecliptic (Œª, Œ≤)\n",
        "        # (Needs astropy; if you don't have it, keep MAP_FRAME=\"equatorial\".)\n",
        "        from astropy.coordinates import SkyCoord\n",
        "        from astropy import units as u\n",
        "        c = SkyCoord(ra=ra_deg*u.deg, dec=dec_deg*u.deg, frame=\"icrs\")\n",
        "        lam = c.barycentrictrueecliptic.lon.rad\n",
        "        bet = c.barycentrictrueecliptic.lat.rad\n",
        "        theta = 0.5*np.pi - bet        # healpy: Œ∏ = colatitude\n",
        "        phi   = np.mod(lam, 2*np.pi)   # healpy: œÜ = longitude\n",
        "        return theta, phi\n",
        "    else:\n",
        "        # Equatorial map (this is what we used in the successful run)\n",
        "        theta = 0.5*np.pi - dec        # Œ∏ = colatitude\n",
        "        phi   = ra                     # œÜ = RA\n",
        "        return theta, phi\n",
        "\n",
        "def sample_dphi_at(ra_deg, dec_deg, dphi_map, nside=128, seed=123):\n",
        "    \"\"\"Robust sampler that almost never returns exact zeros.\"\"\"\n",
        "    ra_deg = np.asarray(ra_deg, float)\n",
        "    dec_deg = np.asarray(dec_deg, float)\n",
        "    theta, phi = _angles_for_map(ra_deg, dec_deg)\n",
        "\n",
        "    # 1) bilinear interpolation\n",
        "    vals = hp.get_interp_val(dphi_map, theta, phi)\n",
        "\n",
        "    # 2) if zero-ish, take the largest-magnitude neighbor from 8-neighbour stencil\n",
        "    zeroish = ~np.isfinite(vals) | (np.abs(vals) < 1e-20)\n",
        "    if np.any(zeroish):\n",
        "        ip = hp.ang2pix(nside, theta[zeroish], phi[zeroish], nest=False)\n",
        "        ngh = hp.get_all_neighbours(nside, ip)          # shape (8, M)\n",
        "        # center + neighbors (9, M)\n",
        "        allpix = np.vstack([ip[None, :], ngh])\n",
        "        # mask invalid indices\n",
        "        mask = allpix >= 0\n",
        "        # pull values\n",
        "        block = np.full_like(allpix, np.nan, dtype=float)\n",
        "        block[mask] = dphi_map[allpix[mask]]\n",
        "        # pick neighbor with the largest |value|\n",
        "        argmax = np.nanargmax(np.abs(block), axis=0)\n",
        "        pick   = block[argmax, np.arange(block.shape[1])]\n",
        "        vals[zeroish] = pick\n",
        "\n",
        "    # 3) still zero-ish? jitter inside pixel and average\n",
        "    if np.all((~np.isfinite(vals)) | (np.abs(vals) < 1e-20)):\n",
        "        rng    = np.random.default_rng(seed)\n",
        "        pixrad = hp.nside2resol(nside)           # ~ pixel radius [rad]\n",
        "        K      = 64\n",
        "        acc    = np.zeros_like(vals)\n",
        "        for _ in range(K):\n",
        "            dth = rng.normal(0.0, pixrad*0.2, size=theta.size)  # ~5 arcmin for NSIDE=128\n",
        "            dph = rng.normal(0.0, pixrad*0.2, size=phi.size)\n",
        "            acc += hp.get_interp_val(dphi_map, theta+dth, phi+dph)\n",
        "        vals = acc / K\n",
        "\n",
        "    return vals\n"
      ],
      "metadata": {
        "id": "67oSEps4PaDA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import healpy as hp\n",
        "\n",
        "def sample_dphi_at(ra_deg, dec_deg, dphi_map, nside, seed=12345):\n",
        "    \"\"\"\n",
        "    Sample the Logosfield dphi map at (RA, Dec) with robust fallbacks:\n",
        "      1) direct interpolation,\n",
        "      2) neighbor pick with max |dphi|,\n",
        "      3) small random jitter inside the pixel for any still ~zero entries.\n",
        "    Returns array of dphi values (float64).\n",
        "    \"\"\"\n",
        "    # --- convert to theta, phi (healpy uses theta=colatitude) ---\n",
        "    theta = np.deg2rad(90.0 - np.asarray(dec_deg, dtype=float))\n",
        "    phi   = np.deg2rad(np.asarray(ra_deg, dtype=float))\n",
        "\n",
        "    # --- direct sample ---\n",
        "    vals = hp.get_interp_val(dphi_map, theta, phi).astype(float)\n",
        "\n",
        "    # --- neighbor fallback: fill any non-finite or ~0 entries with max-|dphi| neighbor ---\n",
        "    zeroish = (~np.isfinite(vals)) | (np.abs(vals) < 1e-20)\n",
        "    if np.any(zeroish):\n",
        "        ip = hp.ang2pix(nside, theta, phi)                  # base pixels\n",
        "        ngh = hp.get_all_neighbours(nside, ip)              # shape (8, N)\n",
        "        allpix = np.vstack([ip[None, :], ngh])              # shape (9, N) center+8 neighbors\n",
        "\n",
        "        # mask invalid indices and pull values\n",
        "        mask = allpix >= 0\n",
        "        block = np.full_like(allpix, np.nan, dtype=float)\n",
        "        block[mask] = dphi_map[allpix[mask]]\n",
        "\n",
        "        # choose neighbor with largest |value|\n",
        "        argmax = np.nanargmax(np.abs(block), axis=0)\n",
        "        pick = block[argmax, np.arange(block.shape[1])]\n",
        "\n",
        "        # only write back where we actually need a fallback\n",
        "        vals[zeroish] = pick[zeroish]\n",
        "\n",
        "    # --- pixel jitter: only for those still zero-ish after neighbor fill ---\n",
        "    still = (~np.isfinite(vals)) | (np.abs(vals) < 1e-20)\n",
        "    if np.any(still):\n",
        "        rng    = np.random.default_rng(seed)\n",
        "        pixrad = hp.nside2resol(nside)          # ~ pixel radius [rad]\n",
        "        K      = 64                              # number of jitter samples\n",
        "\n",
        "        acc = np.zeros(still.sum(), dtype=float)\n",
        "        ths = theta[still]\n",
        "        phs = phi[still]\n",
        "        for _ in range(K):\n",
        "            dth = rng.normal(0.0, pixrad*0.2, size=ths.size)   # ~5 arcmin at NSIDE=128\n",
        "            dph = rng.normal(0.0, pixrad*0.2, size=phs.size)\n",
        "            acc += hp.get_interp_val(dphi_map, ths + dth, phs + dph)\n",
        "        vals[still] = acc / K\n",
        "\n",
        "    return vals\n"
      ],
      "metadata": {
        "id": "pxCFV29MSR-l"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Spin Alignment ‚Äî Reproduction (all-in-one, robust columns)\n",
        "# =========================\n",
        "\n",
        "# --- Imports\n",
        "import os, json, math, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import healpy as hp\n",
        "from astropy import units as u\n",
        "from astropy.coordinates import SkyCoord\n",
        "from astropy.coordinates import BarycentricTrueEcliptic\n",
        "\n",
        "# --- CONFIG: update paths if needed\n",
        "DPHI_PATH = Path(\"/content/drive/MyDrive/Logosfield_dphi_map.npy\")\n",
        "\n",
        "JWST_CLEAN_DIR = Path(\"/content/_jwst_clean\")  # directory with clean_00X.csv\n",
        "JWST_CLEAN_FILES = [\n",
        "    JWST_CLEAN_DIR/\"clean_002.csv\",\n",
        "    JWST_CLEAN_DIR/\"clean_003.csv\",\n",
        "    JWST_CLEAN_DIR/\"clean_004.csv\",\n",
        "    JWST_CLEAN_DIR/\"clean_007.csv\",\n",
        "    JWST_CLEAN_DIR/\"clean_008.csv\",\n",
        "    JWST_CLEAN_DIR/\"clean_009.csv\",\n",
        "]\n",
        "\n",
        "HSC_FILE  = Path(\"/content/drive/MyDrive/hsc_spins_TEMPLATE.csv\")\n",
        "SDSS_FILE = Path(\"/content/drive/MyDrive/sdss_spins_TEMPLATE.csv\")\n",
        "\n",
        "# output artifacts\n",
        "CSV_OUT  = Path(\"/content/repro_spin_alignment_summary.csv\")\n",
        "JSON_OUT = Path(\"/content/repro_spin_alignment_summary.json\")\n",
        "HTML_OUT = Path(\"/content/repro_spin_alignment_summary.html\")\n",
        "\n",
        "# analysis knobs\n",
        "ALIGN_MODE = \"Ecliptic\"   # display label only (we convert ICRS->ecliptic long/lat)\n",
        "EPS_DPHI   = 0.0          # require |dphi|>EPS_DPHI (0 keeps all)\n",
        "SEED       = 42           # for the small jitter in healpix sampling\n",
        "\n",
        "# --------------------------\n",
        "# Utilities\n",
        "# --------------------------\n",
        "def now_utc():\n",
        "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "def write_text(path, s, encoding=\"utf-8\"):\n",
        "    path = Path(path)\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\", encoding=encoding) as f:\n",
        "        f.write(s)\n",
        "\n",
        "# ---- Robust column resolver\n",
        "def find_col(df, *candidates):\n",
        "    \"\"\"\n",
        "    Find a column in df by trying candidates, with case/space-insensitive matching.\n",
        "    Returns the actual df column name. Raises KeyError if none are found.\n",
        "    \"\"\"\n",
        "    cols = list(df.columns)\n",
        "    # direct match first\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    # case/space-insensitive map\n",
        "    norm = {str(c).strip().lower(): c for c in df.columns}\n",
        "    for c in candidates:\n",
        "        key = str(c).strip().lower()\n",
        "        if key in norm:\n",
        "            return norm[key]\n",
        "    raise KeyError(f\"None of {candidates} found in columns: {cols[:20]}{'...' if len(cols)>20 else ''}\")\n",
        "\n",
        "# --------------------------\n",
        "# Ecliptic conversion (patched for older Astropy)\n",
        "# --------------------------\n",
        "def icrs_to_ecliptic_lonlat(ra_deg, dec_deg):\n",
        "    \"\"\"\n",
        "    Convert ICRS RA/Dec [deg] to ecliptic lon/lat [deg].\n",
        "    Robust to Astropy version differences:\n",
        "    - try BarycentricTrueEcliptic() with no kwargs (older astropy)\n",
        "    - fall back to GeocentricTrueEcliptic() or HeliocentricTrueEcliptic()\n",
        "    \"\"\"\n",
        "    ra  = np.asarray(ra_deg)\n",
        "    dec = np.asarray(dec_deg)\n",
        "    c_icrs = SkyCoord(ra=ra*u.deg, dec=dec*u.deg, frame=\"icrs\")\n",
        "\n",
        "    c_ecl = None\n",
        "    try:\n",
        "        c_ecl = c_icrs.transform_to(BarycentricTrueEcliptic())\n",
        "    except Exception:\n",
        "        try:\n",
        "            c_ecl = c_icrs.transform_to(BarycentricTrueEcliptic(equinox='J2000'))\n",
        "        except Exception:\n",
        "            try:\n",
        "                from astropy.coordinates import GeocentricTrueEcliptic\n",
        "                c_ecl = c_icrs.transform_to(GeocentricTrueEcliptic())\n",
        "            except Exception:\n",
        "                from astropy.coordinates import HeliocentricTrueEcliptic\n",
        "                c_ecl = c_icrs.transform_to(HeliocentricTrueEcliptic())\n",
        "\n",
        "    lon_attr = 'lon' if hasattr(c_ecl, 'lon') else 'longitude'\n",
        "    lat_attr = 'lat' if hasattr(c_ecl, 'lat') else 'latitude'\n",
        "    lon = (getattr(c_ecl, lon_attr).to(u.deg).value) % 360.0\n",
        "    lat = getattr(c_ecl, lat_attr).to(u.deg).value\n",
        "    return lon, lat\n",
        "\n",
        "# --------------------------\n",
        "# Healpix dphi sampling (robust)\n",
        "# --------------------------\n",
        "def _get_all_neighbours(nside, ip):\n",
        "    # center + neighbours (8), ignoring -1 (invalid)\n",
        "    ng = hp.get_all_neighbours(nside, ip)  # shape (8,) -1 for invalid\n",
        "    return ng\n",
        "\n",
        "def sample_dphi_at(dphi_map, ra_deg, dec_deg, seed=SEED):\n",
        "    \"\"\"\n",
        "    Sample dphi map at ICRS RA/Dec by:\n",
        "    (1) convert to ecliptic lon/lat\n",
        "    (2) use nearest-pixel, then take the neighbor with max |dphi|\n",
        "    (3) if still ~0, jitter theta/phi within ~20% of pixel radius, average K draws\n",
        "    Returns vector of dphi values (float64)\n",
        "    \"\"\"\n",
        "    nside = hp.get_nside(dphi_map)\n",
        "\n",
        "    lon, lat = icrs_to_ecliptic_lonlat(ra_deg, dec_deg)  # deg\n",
        "    # convert to healpix theta, phi (radians)\n",
        "    theta = np.radians(90.0 - lat)  # colatitude\n",
        "    phi   = np.radians(lon)         # 0..2œÄ\n",
        "\n",
        "    ip = hp.ang2pix(nside, theta, phi, nest=False)\n",
        "\n",
        "    # center + neighbors block\n",
        "    allpix = np.concatenate([ip[:, None], _get_all_neighbours(nside, ip).T], axis=1)  # (N,9)\n",
        "    mask_invalid = allpix < 0\n",
        "    block_vals = np.full_like(allpix, np.nan, dtype=float)\n",
        "    block_vals[~mask_invalid] = dphi_map[allpix[~mask_invalid]]\n",
        "\n",
        "    argmax = np.nanargmax(np.abs(block_vals), axis=1)\n",
        "    pick = block_vals[np.arange(block_vals.shape[0]), argmax]  # (N,)\n",
        "    vals = pick.copy()\n",
        "\n",
        "    still = (~np.isfinite(vals)) | (np.abs(vals) < 1e-20)\n",
        "    if np.any(still):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        pixrad = hp.nside2resol(nside)   # radians ~ pixel scale\n",
        "        K = 64\n",
        "        acc = np.zeros(still.sum(), dtype=float)\n",
        "        ths = theta[still]\n",
        "        phs = phi[still]\n",
        "        for _ in range(K):\n",
        "            dth = rng.normal(0.0, pixrad*0.2, size=ths.size)   # ~5 arcmin at NSIDE=128\n",
        "            dph = rng.normal(0.0, pixrad*0.2, size=phs.size)\n",
        "            thj = ths + dth\n",
        "            phj = phs + dph\n",
        "            acc += hp.get_interp_val(dphi_map, thj, phj)\n",
        "        vals[still] = acc / K\n",
        "\n",
        "    return vals\n",
        "\n",
        "# --------------------------\n",
        "# Spin coercion\n",
        "# --------------------------\n",
        "def coerce_spin_series(df, colname=\"spin\"):\n",
        "    \"\"\"\n",
        "    Map various spin encodings to {-1,0, +1}\n",
        "    \"\"\"\n",
        "    if colname not in df.columns:\n",
        "        return pd.Series(np.zeros(len(df), dtype=int), index=df.index)\n",
        "\n",
        "    s = df[colname]\n",
        "    if pd.api.types.is_string_dtype(s):\n",
        "        m = s.astype(str).str.strip().str.upper().map({\n",
        "            \"CW\": +1, \"CLOCKWISE\": +1,\n",
        "            \"CCW\": -1, \"ACW\": -1, \"ANTICLOCKWISE\": -1,\n",
        "            \"+1\": +1, \"-1\": -1, \"1\": +1\n",
        "        })\n",
        "        out = pd.to_numeric(m, errors=\"coerce\")\n",
        "    else:\n",
        "        out = pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "    out = out.fillna(0.0).clip(-1, +1).round().astype(int)\n",
        "    return out\n",
        "\n",
        "# --------------------------\n",
        "# One dataset evaluation (robust column selection)\n",
        "# --------------------------\n",
        "def evaluate_table(name, df, ra_col, dec_col, spin_col, dphi_map, eps_dphi=EPS_DPHI):\n",
        "    \"\"\"\n",
        "    Return dict with summary or note ‚Äúno comparable spins‚Äù.\n",
        "    Column names are resolved robustly (synonyms + case-insensitive).\n",
        "    \"\"\"\n",
        "    # resolve columns robustly\n",
        "    ra_name  = find_col(df, ra_col,  \"RA_TARG\", \"RA\", \"ra\", \"ra_deg\", \"raj2000\", \"alpha\")\n",
        "    dec_name = find_col(df, dec_col, \"DEC_TARG\",\"DEC\",\"dec\",\"dec_deg\",\"dej2000\", \"delta\")\n",
        "    spin_name = find_col(df, spin_col, \"spin\",\"Spin\",\"SPIN\",\"label\",\"rotation\",\"rot\")\n",
        "\n",
        "    # coerce to arrays\n",
        "    ra  = pd.to_numeric(df[ra_name],  errors=\"coerce\").to_numpy(dtype=float)\n",
        "    dec = pd.to_numeric(df[dec_name], errors=\"coerce\").to_numpy(dtype=float)\n",
        "    spin_u = coerce_spin_series(df, spin_name).to_numpy(dtype=int)\n",
        "\n",
        "    # length check\n",
        "    n = len(df)\n",
        "    if not (len(ra)==len(dec)==len(spin_u)==n):\n",
        "        raise ValueError(f\"Column length mismatch in {name}: len(ra)={len(ra)} len(dec)={len(dec)} len(spin)={len(spin_u)} n={n}\")\n",
        "\n",
        "    # sample dphi\n",
        "    dphi = sample_dphi_at(dphi_map, ra, dec)\n",
        "\n",
        "    finite_mask = np.isfinite(ra) & np.isfinite(dec) & np.isfinite(dphi)\n",
        "    nonzero_spin = (spin_u != 0)\n",
        "    strong = (np.abs(dphi) > eps_dphi)\n",
        "\n",
        "    good = finite_mask & nonzero_spin & strong\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        return dict(dataset=name, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0, z=0.0,\n",
        "                    CI95=(0.0,1.0), log10BF=0.0, note=\"no comparable spins\")\n",
        "\n",
        "    sign_dphi = np.sign(dphi[good])\n",
        "    sign_spin = np.sign(spin_u[good])\n",
        "\n",
        "    aligned = int(np.sum(sign_dphi == sign_spin))\n",
        "    p = aligned / N\n",
        "    se = math.sqrt(p*(1-p)/N) if 0 < p < 1 else 0.0\n",
        "    z = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "\n",
        "    # Jeffreys/Binomial approximation for Bayes factor against 0.5\n",
        "    log10BF = N*math.log10(2) if p in (0.0, 1.0) else (aligned*math.log10(p) + (N-aligned)*math.log10(1-p) + N*math.log10(2))\n",
        "\n",
        "    lo = max(0.0, p - 1.96*se)\n",
        "    hi = min(1.0, p + 1.96*se)\n",
        "\n",
        "    return dict(dataset=name, frame=ALIGN_MODE, N=N, aligned=aligned, frac=round(p,4),\n",
        "                z=round(z, 2), CI95=(round(lo,4), round(hi,4)), log10BF=round(log10BF,4), note=\"\")\n",
        "\n",
        "# --------------------------\n",
        "# Run\n",
        "# --------------------------\n",
        "def main():\n",
        "    # Load Logosfield dphi map\n",
        "    if not DPHI_PATH.exists():\n",
        "        raise FileNotFoundError(f\"dphi map not found at {DPHI_PATH}\")\n",
        "    dphi = np.load(DPHI_PATH)\n",
        "    nside = hp.get_nside(dphi)\n",
        "\n",
        "    print(f\"[dphi] loaded {DPHI_PATH}   NSIDE={nside}  Npix={dphi.size}\")\n",
        "    print(f\"[dphi] stats: min={np.nanmin(dphi):.3e}  max={np.nanmax(dphi):.3e}  std={np.nanstd(dphi):.3e}\")\n",
        "\n",
        "    results = []\n",
        "    dbg_rows = []\n",
        "\n",
        "    # JWST per-object spins\n",
        "    print(\"\\nJWST candidates:\")\n",
        "    kept_any = False\n",
        "    for f in JWST_CLEAN_FILES:\n",
        "        if not f.exists():\n",
        "            print(\"  (missing)\", f)\n",
        "            continue\n",
        "        df = pd.read_csv(f)\n",
        "        try:\n",
        "            res = evaluate_table(\"JWST (per-object spins)\", df,\n",
        "                                 ra_col=\"RA_TARG\", dec_col=\"Dec_TARG\", spin_col=\"spin\",\n",
        "                                 dphi_map=dphi, eps_dphi=EPS_DPHI)\n",
        "        except KeyError as e:\n",
        "            # show columns to make debugging trivial\n",
        "            print(f\"  '{f.name}': {e}\")\n",
        "            res = dict(dataset=\"JWST (per-object spins)\", frame=ALIGN_MODE, N=0, aligned=0, frac=0.0, z=0.0,\n",
        "                       CI95=(0.0,1.0), log10BF=0.0, note=\"column(s) missing\")\n",
        "        kept = res[\"N\"] > 0\n",
        "        kept_any |= kept\n",
        "        status = \"used\" if kept else res.get(\"note\",\"no comparable spins\")\n",
        "        print(f\"  '{f.name}', usable rows after normalize = {res['N']}  -> {status}\")\n",
        "        if kept: results.append(res)\n",
        "        dbg_rows.append(dict(dataset=\"JWST (per-object spins)\", file=str(f), rows_total=len(df), rows_usable=res[\"N\"], status=\"used_map\" if kept else \"empty\"))\n",
        "    if not kept_any:\n",
        "        results.append(dict(dataset=\"JWST (per-object spins)\", frame=ALIGN_MODE, N=0, aligned=0, frac=0.0, z=0.0,\n",
        "                            CI95=(0.0,1.0), log10BF=0.0, note=\"no comparable spins\"))\n",
        "\n",
        "    # HSC template\n",
        "    if HSC_FILE.exists():\n",
        "        df_h = pd.read_csv(HSC_FILE)\n",
        "        try:\n",
        "            res_h = evaluate_table(\"HSC\", df_h, ra_col=\"ra_deg\", dec_col=\"dec_deg\", spin_col=\"spin\", dphi_map=dphi)\n",
        "        except KeyError as e:\n",
        "            print(f\"  HSC: {e}\")\n",
        "            res_h = dict(dataset=\"HSC\", frame=ALIGN_MODE, N=0, aligned=0, frac=0.0, z=0.0,\n",
        "                         CI95=(0.0,1.0), log10BF=0.0, note=\"column(s) missing\")\n",
        "        results.append(res_h)\n",
        "        dbg_rows.append(dict(dataset=\"HSC\", file=str(HSC_FILE), rows_total=len(df_h), rows_usable=res_h[\"N\"], status=\"used_map\" if res_h[\"N\"]>0 else \"empty\"))\n",
        "    else:\n",
        "        print(\"HSC missing:\", HSC_FILE)\n",
        "\n",
        "    # SDSS template\n",
        "    if SDSS_FILE.exists():\n",
        "        df_s = pd.read_csv(SDSS_FILE)\n",
        "        try:\n",
        "            res_s = evaluate_table(\"SDSS Galaxy Zoo\", df_s, ra_col=\"ra_deg\", dec_col=\"dec_deg\", spin_col=\"spin\", dphi_map=dphi)\n",
        "        except KeyError as e:\n",
        "            print(f\"  SDSS: {e}\")\n",
        "            res_s = dict(dataset=\"SDSS Galaxy Zoo\", frame=ALIGN_MODE, N=0, aligned=0, frac=0.0, z=0.0,\n",
        "                         CI95=(0.0,1.0), log10BF=0.0, note=\"column(s) missing\")\n",
        "        results.append(res_s)\n",
        "        dbg_rows.append(dict(dataset=\"SDSS Galaxy Zoo\", file=str(SDSS_FILE), rows_total=len(df_s), rows_usable=res_s[\"N\"], status=\"used_map\" if res_s[\"N\"]>0 else \"empty\"))\n",
        "    else:\n",
        "        print(\"SDSS missing:\", SDSS_FILE)\n",
        "\n",
        "    # ---- Summary table (print)\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    print(f\"(generated {now_utc()})\")\n",
        "    cols = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]\n",
        "    df_sum = pd.DataFrame(results, columns=cols)\n",
        "\n",
        "    with pd.option_context(\"display.max_rows\", 50, \"display.width\", 140):\n",
        "        print(df_sum[cols].to_string(index=False))\n",
        "\n",
        "    # ---- Pooled binomial\n",
        "    N_total = int(pd.to_numeric(df_sum[\"N\"], errors=\"coerce\").fillna(0).sum())\n",
        "    K_total = int(pd.to_numeric(df_sum[\"aligned\"], errors=\"coerce\").fillna(0).sum())\n",
        "    if N_total > 0:\n",
        "        p = K_total / N_total\n",
        "        se = math.sqrt(p*(1-p)/N_total) if 0 < p < 1 else 0.0\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N_total))\n",
        "        lo = max(0.0, p - 1.96*se)\n",
        "        hi = min(1.0, p + 1.96*se)\n",
        "        log10BF = N_total*math.log10(2) if p in (0.0, 1.0) else (K_total*math.log10(p) + (N_total-K_total)*math.log10(1-p) + N_total*math.log10(2))\n",
        "        pooled = dict(N_total=N_total, f_total=round(p,4), z=round(z,2), CI95=(round(lo,4), round(hi,4)), log10BF=round(log10BF,4))\n",
        "    else:\n",
        "        pooled = None\n",
        "\n",
        "    print(\"\\nPooled:\", pooled if pooled else \"no usable rows\")\n",
        "\n",
        "    # ---- Write CSV/JSON/HTML\n",
        "    df_sum.to_csv(CSV_OUT, index=False)\n",
        "    write_text(JSON_OUT, json.dumps({\"generated\": now_utc(), \"results\": results, \"pooled\": pooled}, indent=2))\n",
        "\n",
        "    # simple HTML\n",
        "    def _fmt_ci(ci):\n",
        "        try:\n",
        "            a,b = ci\n",
        "            return f\"({a:.4f}, {b:.4f})\"\n",
        "        except Exception:\n",
        "            return \"(0.0000, 1.0000)\"\n",
        "\n",
        "    def _row_html(r):\n",
        "        return (\n",
        "            f\"<tr>\"\n",
        "            f\"<td>{r.get('dataset','')}</td>\"\n",
        "            f\"<td>{r.get('frame','')}</td>\"\n",
        "            f\"<td>{int(r.get('N',0))}</td>\"\n",
        "            f\"<td>{int(r.get('aligned',0))}</td>\"\n",
        "            f\"<td>{float(r.get('frac',0.0)):.4f}</td>\"\n",
        "            f\"<td>{float(r.get('z',0.0)):.2f}</td>\"\n",
        "            f\"<td>{_fmt_ci(r.get('CI95',(0.0,1.0)))}</td>\"\n",
        "            f\"<td>{float(r.get('log10BF',0.0)):.4f}</td>\"\n",
        "            f\"<td>{r.get('note','')}</td>\"\n",
        "            f\"</tr>\"\n",
        "        )\n",
        "\n",
        "    html = [\n",
        "        \"<!doctype html><html><head><meta charset='utf-8'>\",\n",
        "        \"<title>Spin Alignment ‚Äî Repro</title>\",\n",
        "        \"<style>body{font:14px system-ui,Segoe UI,Roboto,sans-serif;padding:16px}\"\n",
        "        \"table{border-collapse:collapse;width:100%;margin-top:10px}\"\n",
        "        \"th,td{padding:6px 10px;border-bottom:1px solid #ddd;text-align:left}</style>\",\n",
        "        \"</head><body>\",\n",
        "        f\"<h1>Spin Alignment ‚Äî Reproduction</h1><div>Generated {now_utc()}</div>\",\n",
        "        f\"<div>ALIGN_MODE=<b>{ALIGN_MODE}</b> &nbsp; EPS_DPHI=<b>{EPS_DPHI}</b></div>\",\n",
        "        \"<table><tr><th>Dataset</th><th>Frame</th><th>N</th><th>Aligned</th><th>f</th><th>z</th><th>CI95</th><th>log10 BF</th><th>note</th></tr>\"\n",
        "    ]\n",
        "    for r in results:\n",
        "        html.append(_row_html(r))\n",
        "    html.append(\"</table>\")\n",
        "\n",
        "    if pooled:\n",
        "        html.append(\"<h3>Pooled</h3>\")\n",
        "        html.append(\n",
        "            f\"<div>N={pooled['N_total']} &nbsp; f={pooled['f_total']:.4f} &nbsp; \"\n",
        "            f\"z={pooled['z']:.2f} &nbsp; CI95={_fmt_ci(pooled['CI95'])} &nbsp; \"\n",
        "            f\"log10 BF={pooled['log10BF']:.4f}</div>\"\n",
        "        )\n",
        "\n",
        "    html.append(\"</body></html>\")\n",
        "    write_text(HTML_OUT, \"\".join(html))\n",
        "\n",
        "    print(\"\\nWrote:\")\n",
        "    print(\" CSV :\", CSV_OUT)\n",
        "    print(\" JSON:\", JSON_OUT)\n",
        "    print(\" HTML:\", HTML_OUT)\n",
        "\n",
        "# Run\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01osmMAjYkpq",
        "outputId": "b23ea115-9e98-4b13-a59a-b6d2d0773a8f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dphi] loaded /content/drive/MyDrive/Logosfield_dphi_map.npy   NSIDE=128  Npix=196608\n",
            "[dphi] stats: min=-9.213e+01  max=9.213e+01  std=3.135e+00\n",
            "\n",
            "JWST candidates:\n",
            "  'clean_002.csv', usable rows after normalize = 1  -> used\n",
            "  'clean_003.csv', usable rows after normalize = 0  -> no comparable spins\n",
            "  'clean_004.csv', usable rows after normalize = 1  -> used\n",
            "  'clean_007.csv', usable rows after normalize = 1  -> used\n",
            "  'clean_008.csv', usable rows after normalize = 0  -> no comparable spins\n",
            "  'clean_009.csv', usable rows after normalize = 1  -> used\n",
            "\n",
            "=== SUMMARY ===\n",
            "(generated 2025-09-01 03:46 UTC)\n",
            "                dataset    frame  N  aligned  frac   z       CI95  log10BF note\n",
            "JWST (per-object spins) Ecliptic  1        1   1.0 1.0 (1.0, 1.0)    0.301     \n",
            "JWST (per-object spins) Ecliptic  1        1   1.0 1.0 (1.0, 1.0)    0.301     \n",
            "JWST (per-object spins) Ecliptic  1        1   1.0 1.0 (1.0, 1.0)    0.301     \n",
            "JWST (per-object spins) Ecliptic  1        1   1.0 1.0 (1.0, 1.0)    0.301     \n",
            "                    HSC Ecliptic  1        1   1.0 1.0 (1.0, 1.0)    0.301     \n",
            "        SDSS Galaxy Zoo Ecliptic  2        1   0.5 0.0 (0.0, 1.0)    0.000     \n",
            "\n",
            "Pooled: {'N_total': 7, 'f_total': 0.8571, 'z': 1.89, 'CI95': (0.5979, 1.0), 'log10BF': 0.8604}\n",
            "\n",
            "Wrote:\n",
            " CSV : /content/repro_spin_alignment_summary.csv\n",
            " JSON: /content/repro_spin_alignment_summary.json\n",
            " HTML: /content/repro_spin_alignment_summary.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CATALOG PROFILES + SINGLE-CATALOG RUNNER\n",
        "# =========================\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "VERBOSE = True\n",
        "CONFIRM_ONLY = False          # set True to only confirm mappings (no alignment computation)\n",
        "RUN_ONLY_PROFILES = None      # e.g. [\"HSC template\"] or [\"JWST per-object\"] to run just one kind\n",
        "\n",
        "def _norm(s):  # normalize a column name for matching\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
        "\n",
        "# Strict spin tokens to avoid false positives (keep in sync with earlier strict set)\n",
        "STRICT_SPIN_TOKENS = {\"spin\",\"spinu\",\"spindirection\",\"spinlabel\",\"rotation\"}\n",
        "\n",
        "# Column synonym libraries\n",
        "RA_SYNS   = [\"RA_TARG\",\"RA_u\",\"RA\",\"ra\",\"ra_u\",\"ra_deg\",\"raj2000\",\"alpha\",\"ra_deg_J2000\",\"RAJ2000\"]\n",
        "DEC_SYNS  = [\"DEC_TARG\",\"Dec_u\",\"DEC\",\"Dec\",\"dec\",\"dec_u\",\"dec_deg\",\"dej2000\",\"delta\",\"DEJ2000\"]\n",
        "CW_SYNS   = [\"CW_count\",\"cw_count\",\"CW\",\"cw\",\"n_cw\",\"nCW\",\"CWCOUNT\"]\n",
        "CCW_SYNS  = [\"CCW_count\",\"ccw_count\",\"CCW\",\"ccw\",\"n_ccw\",\"nCCW\",\"CCWCOUNT\"]\n",
        "# For spin we do strict matching on normalized tokens, so we keep an explicit list per profile if needed.\n",
        "\n",
        "def find_first(df, candidates, strict_normalized_set=None):\n",
        "    \"\"\"\n",
        "    Return the first matching column name from df.columns.\n",
        "    - If strict_normalized_set is provided: only columns whose normalized form is in that set.\n",
        "    - Otherwise: try exact case-insensitive, then startswith/contains.\n",
        "    \"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if strict_normalized_set is not None:\n",
        "        for c in cols:\n",
        "            if _norm(c) in strict_normalized_set:\n",
        "                return c\n",
        "        return None\n",
        "\n",
        "    lower = {c.lower(): c for c in cols}\n",
        "    for cand in candidates:\n",
        "        key = cand.lower()\n",
        "        if key in lower:\n",
        "            return lower[key]\n",
        "    # fallback: startswith or contains\n",
        "    for cand in candidates:\n",
        "        key = cand.lower()\n",
        "        for lc, orig in lower.items():\n",
        "            if lc.startswith(key) or key in lc:\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "# ---- Profiles ----\n",
        "CATALOG_PROFILES = [\n",
        "    dict(\n",
        "        name = \"JWST per-object\",\n",
        "        mode = \"per_object\",\n",
        "        filename_hints = [\"clean_\", \"jwst\"],\n",
        "        required = (\"ra\",\"dec\",\"spin\"),\n",
        "        synonyms = {\n",
        "            \"ra\"  : RA_SYNS,\n",
        "            \"dec\" : DEC_SYNS,\n",
        "            \"spin\": None,   # strict below\n",
        "        },\n",
        "        strict_spin_tokens = STRICT_SPIN_TOKENS\n",
        "    ),\n",
        "    dict(\n",
        "        name = \"JWST binned\",\n",
        "        mode = \"used_map\",\n",
        "        filename_hints = [\"clean_\", \"jwst\"],\n",
        "        required = (\"ra\",\"dec\",\"cw\",\"ccw\"),\n",
        "        synonyms = {\n",
        "            \"ra\"  : RA_SYNS,\n",
        "            \"dec\" : DEC_SYNS,\n",
        "            \"cw\"  : CW_SYNS,\n",
        "            \"ccw\" : CCW_SYNS,\n",
        "        },\n",
        "        strict_spin_tokens = None\n",
        "    ),\n",
        "    dict(\n",
        "        name = \"HSC template\",\n",
        "        mode = \"used_map\",\n",
        "        filename_hints = [\"hsc\",\"template\"],\n",
        "        required = (\"ra\",\"dec\",\"cw\",\"ccw\"),\n",
        "        synonyms = {\n",
        "            \"ra\"  : RA_SYNS,\n",
        "            \"dec\" : DEC_SYNS,\n",
        "            \"cw\"  : CW_SYNS,\n",
        "            \"ccw\" : CCW_SYNS,\n",
        "        },\n",
        "        strict_spin_tokens = None\n",
        "    ),\n",
        "    dict(\n",
        "        name = \"SDSS template\",\n",
        "        mode = \"used_map\",\n",
        "        filename_hints = [\"sdss\",\"template\",\"galaxy\",\"zoo\"],\n",
        "        required = (\"ra\",\"dec\",\"cw\",\"ccw\"),\n",
        "        synonyms = {\n",
        "            \"ra\"  : RA_SYNS,\n",
        "            \"dec\" : DEC_SYNS,\n",
        "            \"cw\"  : CW_SYNS,\n",
        "            \"ccw\" : CCW_SYNS,\n",
        "        },\n",
        "        strict_spin_tokens = None\n",
        "    ),\n",
        "]\n",
        "\n",
        "def score_profile(path, df, prof):\n",
        "    \"\"\"Score how well a profile matches a file (filename + columns). Higher is better.\"\"\"\n",
        "    score = 0\n",
        "    fname = Path(path).name.lower()\n",
        "\n",
        "    # filename hints\n",
        "    for h in prof.get(\"filename_hints\", []):\n",
        "        if h in fname:\n",
        "            score += 1\n",
        "\n",
        "    # required columns\n",
        "    syns = prof[\"synonyms\"]\n",
        "    strict = prof.get(\"strict_spin_tokens\")\n",
        "    found = {}\n",
        "    for req in prof[\"required\"]:\n",
        "        if req == \"spin\":\n",
        "            c = find_first(df, [], strict_normalized_set=strict) if strict else None\n",
        "        else:\n",
        "            c = find_first(df, syns.get(req, []))\n",
        "        if c is not None:\n",
        "            score += 2  # strong signal\n",
        "            found[req] = c\n",
        "        else:\n",
        "            found[req] = None\n",
        "\n",
        "    return score, found\n",
        "\n",
        "def choose_profile(path, df):\n",
        "    \"\"\"Pick the best profile by score; return (profile, mapping).\"\"\"\n",
        "    best = None\n",
        "    best_score = -1\n",
        "    best_found = None\n",
        "    for prof in CATALOG_PROFILES:\n",
        "        sc, found = score_profile(path, df, prof)\n",
        "        if sc > best_score:\n",
        "            best = prof\n",
        "            best_score = sc\n",
        "            best_found = found\n",
        "    return best, best_found, best_score\n",
        "\n",
        "def canonicalize(df, found, prof, verbose=True):\n",
        "    \"\"\"\n",
        "    Rename columns in df to standard names: RA, DEC, SPIN, CW, CCW (if present).\n",
        "    Returns df2, mapping dict.\n",
        "    \"\"\"\n",
        "    rename = {}\n",
        "    for key, col in found.items():\n",
        "        if col is None:\n",
        "            continue\n",
        "        if key == \"ra\":  rename[col] = \"RA\"\n",
        "        if key == \"dec\": rename[col] = \"DEC\"\n",
        "        if key == \"spin\":rename[col] = \"SPIN\"\n",
        "        if key == \"cw\":  rename[col] = \"CW\"\n",
        "        if key == \"ccw\": rename[col] = \"CCW\"\n",
        "\n",
        "    df2 = df.rename(columns=rename, errors=\"ignore\").copy()\n",
        "    if verbose:\n",
        "        pretty = {k:v for k,v in rename.items()}\n",
        "        if pretty:\n",
        "            print(\"  column mapping:\", pretty)\n",
        "        else:\n",
        "            print(\"  column mapping: (none)\")\n",
        "\n",
        "    return df2, rename\n",
        "\n",
        "# ---- Hook into the earlier pipeline ----\n",
        "def eval_with_profiles(path, label, dphi_map, eps=EPS_DPHI):\n",
        "    df = pd.read_csv(path)\n",
        "    prof, found, score = choose_profile(path, df)\n",
        "\n",
        "    if RUN_ONLY_PROFILES and (prof[\"name\"] not in RUN_ONLY_PROFILES):\n",
        "        if VERBOSE:\n",
        "            print(f\"{Path(path).name}: profile '{prof['name']}' not in RUN_ONLY_PROFILES -> skipped\")\n",
        "        return None, dict(dataset=label, file=path, status=\"skipped (profile filtered)\")\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"{Path(path).name}: chose profile = {prof['name']} (score {score})\")\n",
        "        print(f\"  required found: {found}\")\n",
        "\n",
        "    df2, _ = canonicalize(df, found, prof, verbose=VERBOSE)\n",
        "\n",
        "    # Confirm-only mode: just show which columns will be used, plus a tiny preview.\n",
        "    if CONFIRM_ONLY:\n",
        "        prev = df2.head(3)\n",
        "        print(prev.to_string(index=False))\n",
        "        return None, dict(dataset=label, file=path, status=f\"confirm-only: {prof['name']}\")\n",
        "\n",
        "    mode = prof[\"mode\"]\n",
        "    if mode == \"per_object\":\n",
        "        ra_col, dec_col, spin_col = \"RA\", \"DEC\", \"SPIN\"\n",
        "        if any(df2.get(c) is None for c in [ra_col, dec_col, spin_col]) or \\\n",
        "           any(c not in df2.columns for c in [ra_col, dec_col, spin_col]):\n",
        "            # fallback: show zeros diagnostic\n",
        "            print(\"  (missing columns for per_object) -> no comparable spins\")\n",
        "            res = dict(dataset=label, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "                       z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"profile mismatch\")\n",
        "            dbg = dict(raw_n=len(df2), n_finite=0, n_nonzero=0, n_nonaxisym=0, n_used=0, mode=mode)\n",
        "            return res, dbg\n",
        "\n",
        "        res, dbg = evaluate_per_object(label, df2, ra_col, dec_col, spin_col, dphi_map, eps)\n",
        "        # If N=0 but counts exist, drop to used_map as a safety valve\n",
        "        if dbg.get(\"n_used\", 0) == 0:\n",
        "            cw_col = find_first(df2, CW_SYNS)\n",
        "            ccw_col = find_first(df2, CCW_SYNS)\n",
        "            if (cw_col in df2.columns) and (ccw_col in df2.columns):\n",
        "                res2, dbg2 = evaluate_binned_used_map(label, df2, ra_col, dec_col, cw_col, ccw_col, dphi_map, eps)\n",
        "                dbg2[\"mode\"] = \"used_map_fallback\"\n",
        "                return res2, dbg2\n",
        "        dbg[\"mode\"] = mode\n",
        "        return res, dbg\n",
        "\n",
        "    if mode == \"used_map\":\n",
        "        ra_col, dec_col, cw_col, ccw_col = \"RA\", \"DEC\", \"CW\", \"CCW\"\n",
        "        if any(c not in df2.columns for c in [ra_col, dec_col, cw_col, ccw_col]):\n",
        "            print(\"  (missing columns for used_map) -> no comparable spins\")\n",
        "            res = dict(dataset=label, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "                       z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"profile mismatch\")\n",
        "            dbg = dict(raw_n=len(df2), n_finite=0, n_nonzero=0, n_nonaxisym=0, n_used=0, mode=mode)\n",
        "            return res, dbg\n",
        "        res, dbg = evaluate_binned_used_map(label, df2, ra_col, dec_col, cw_col, ccw_col, dphi_map, eps)\n",
        "        dbg[\"mode\"] = mode\n",
        "        return res, dbg\n",
        "\n",
        "    # Unknown mode\n",
        "    res = dict(dataset=label, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "               z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"unknown profile\")\n",
        "    dbg = dict(raw_n=len(df), n_finite=0, n_nonzero=0, n_nonaxisym=0, n_used=0, mode=\"unknown\")\n",
        "    return res, dbg\n",
        "\n",
        "# ====== Example: use eval_with_profiles inside your main loop ======\n",
        "# Replace the call to evaluate_file(...) with eval_with_profiles(...)\n",
        "\n",
        "def main_profiles():\n",
        "    dphi = load_dphi(DPHI_PATH)\n",
        "    print(f\"[dphi] loaded {DPHI_PATH}  NSIDE={NSIDE}  Npix={len(dphi)}\")\n",
        "    print(f\"[dphi] stats: min={np.nanmin(dphi):.3e} max={np.nanmax(dphi):.3e} std={np.nanstd(dphi):.3e}\")\n",
        "\n",
        "    jwst_files = sorted(glob.glob(os.path.join(JWST_CLEAN_DIR, \"clean_*.csv\")))\n",
        "    sources = [\n",
        "        (\"JWST\", jwst_files),\n",
        "        (\"HSC\",  [HSC_FILE]),\n",
        "        (\"SDSS Galaxy Zoo\", [SDSS_FILE]),\n",
        "    ]\n",
        "\n",
        "    results, dbg_rows = [], []\n",
        "    P_N = 0.0\n",
        "    P_K = 0.0\n",
        "\n",
        "    for label, files in sources:\n",
        "        for f in files:\n",
        "            res, dbg = eval_with_profiles(f, label, dphi, eps=EPS_DPHI)\n",
        "            if res is None:\n",
        "                # confirm-only or filtered; dbg already printed\n",
        "                dbg_rows.append(dbg)\n",
        "                continue\n",
        "            used = res.get(\"N\", 0) > 0\n",
        "            print(f\"{Path(f).name}: {dbg.get('mode','?')}  N={res['N']}  note={res.get('note','')}\")\n",
        "            results.append(res)\n",
        "            dbg_rows.append(dict(dataset=label, file=f, **dbg, status=(\"used\" if used else \"skipped\")))\n",
        "            P_N += float(res[\"N\"])\n",
        "            P_K += float(res[\"aligned\"])\n",
        "\n",
        "    if CONFIRM_ONLY:\n",
        "        print(\"\\n(confirm-only mode: not computing pooled or writing outputs)\")\n",
        "        return\n",
        "\n",
        "    if P_N > 0:\n",
        "        p  = P_K/P_N\n",
        "        se = math.sqrt(max(p*(1-p)/P_N, 0.0))\n",
        "        z  = (p - 0.5) / (0.5/math.sqrt(P_N))\n",
        "        lo = max(0.0, p - 1.96*se)\n",
        "        hi = min(1.0, p + 1.96*se)\n",
        "        log10BF = (P_K*math.log10(p) + (P_N-P_K)*math.log10(1-p)) if (0 < p < 1) else P_N*math.log10(2)\n",
        "        pooled = dict(N_total=int(round(P_N)), f_total=p, z=z, CI95=(lo,hi), log10BF=log10BF)\n",
        "    else:\n",
        "        pooled = dict(N_total=0, f_total=float(\"nan\"), z=0.0, CI95=(float(\"nan\"), float(\"nan\")), log10BF=float(\"nan\"))\n",
        "\n",
        "    print(\"\\n=== SUMMARY (profile runner) ===\\n\")\n",
        "    df_print = pd.DataFrame(results)[[\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]]\n",
        "    print(df_print.to_string(index=False))\n",
        "    print(\"\\nPooled:\", pooled)\n",
        "\n",
        "    write_outputs(results, pooled, dbg_rows)\n",
        "\n",
        "# Example switches:\n",
        "# RUN_ONLY_PROFILES = [\"JWST per-object\"]   # run only this\n",
        "# CONFIRM_ONLY = True                       # just show mapping and a preview\n",
        "\n",
        "# main_profiles()   # <- call this instead of main() when you want profile-aware routing\n"
      ],
      "metadata": {
        "id": "BOuUSX2Ydhjm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- PATH RESOLUTION + PROFILE RUNNER (all-in-one) ----------------\n",
        "import numpy as np, pandas as pd, healpy as hp\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# === knobs ===\n",
        "ALIGN_MODE          = \"Ecliptic\"\n",
        "EPS_DPHI            = 0.0\n",
        "REQUIRE_ABS_DPHI    = False\n",
        "# pick which to run (you can include several)\n",
        "RUN_ONLY_PROFILES   = [\"JWST per-object\"]  # e.g. [\"JWST per-object\",\"HSC template\",\"SDSS template\"]\n",
        "CONFIRM_ONLY        = False\n",
        "\n",
        "# where to search for files (order matters)\n",
        "SEARCH_DIRS = [\n",
        "    \".\",  # current\n",
        "    \"/content/_jwst_clean\",\n",
        "    \"/content/drive/MyDrive\",\n",
        "    \"/content/drive/MyDrive/_jwst_clean\",\n",
        "    \"/content/drive/MyDrive/jwst_clean\",\n",
        "    \"/content\",   # last resort\n",
        "]\n",
        "\n",
        "def _find_first(name_or_path: str):\n",
        "    \"\"\"Return Path if exists; otherwise search in SEARCH_DIRS; else None.\"\"\"\n",
        "    p = Path(name_or_path)\n",
        "    if p.exists():\n",
        "        return p.resolve()\n",
        "    for d in SEARCH_DIRS:\n",
        "        q = Path(d) / name_or_path\n",
        "        if q.exists():\n",
        "            return q.resolve()\n",
        "    return None\n",
        "\n",
        "def _glob_in_dirs(pattern: str):\n",
        "    \"\"\"Return sorted list of Paths matching `*pattern*` in SEARCH_DIRS.\"\"\"\n",
        "    hits = []\n",
        "    for d in SEARCH_DIRS:\n",
        "        for g in glob.glob(str(Path(d) / pattern)):\n",
        "            p = Path(g)\n",
        "            if p.exists():\n",
        "                hits.append(p.resolve())\n",
        "    # de-dup & sort\n",
        "    uniq = sorted({str(p): p for p in hits}.values(), key=lambda x: x.name)\n",
        "    return uniq\n",
        "\n",
        "def coerce_spin_series(df, col):\n",
        "    s = df.get(col)\n",
        "    if s is None:\n",
        "        return np.zeros(len(df), dtype=int)\n",
        "    if s.dtype == object:\n",
        "        m = (s.astype(str).str.strip().str.upper()\n",
        "               .map({\"CW\":+1, \"CCW\":-1, \"ACW\":-1, \"CLOCKWISE\":+1, \"ANTICLOCKWISE\":-1}))\n",
        "        return pd.to_numeric(m, errors=\"coerce\").fillna(0).astype(int).values\n",
        "    return pd.to_numeric(s, errors=\"coerce\").fillna(0).clip(-1,1).astype(int).values\n",
        "\n",
        "def sample_dphi_at(ra_deg, dec_deg, dphi_map, nside=128, seed=0):\n",
        "    theta = np.deg2rad(90.0 - dec_deg)\n",
        "    phi   = np.deg2rad(ra_deg % 360.0)\n",
        "    vals  = hp.get_interp_val(dphi_map, theta, phi)\n",
        "    zeroish = (~np.isfinite(vals)) | (np.abs(vals) < 1e-20)\n",
        "    if np.any(zeroish):\n",
        "        pix  = hp.ang2pix(nside, theta, phi)\n",
        "        ngh  = hp.get_all_neighbours(nside, pix)\n",
        "        allp = np.vstack([pix, ngh])\n",
        "        mask = allp >= 0\n",
        "        block = np.full_like(allp, np.nan, dtype=float)\n",
        "        block[mask] = dphi_map[allp[mask]]\n",
        "        pick = block[np.nanargmax(np.abs(block), axis=0), np.arange(block.shape[1])]\n",
        "        vals[zeroish] = pick[zeroish]\n",
        "        still = (~np.isfinite(vals)) | (np.abs(vals) < 1e-20)\n",
        "        if np.any(still):\n",
        "            rng    = np.random.default_rng(seed)\n",
        "            pixrad = hp.nside2resol(nside)\n",
        "            ths, phs = theta[still], phi[still]\n",
        "            acc = np.zeros_like(ths, dtype=float)\n",
        "            for _ in range(64):\n",
        "                acc += hp.get_interp_val(\n",
        "                    dphi_map,\n",
        "                    ths + rng.normal(0.0, pixrad*0.2, ths.size),\n",
        "                    phs + rng.normal(0.0, pixrad*0.2, phs.size),\n",
        "                )\n",
        "            vals[still] = acc / 64.0\n",
        "    return vals\n",
        "\n",
        "def evaluate_table(dataset_name, df, ra_col, dec_col, spin_col, dphi_map, eps_dphi):\n",
        "    ra   = pd.to_numeric(df.get(ra_col), errors=\"coerce\").values.astype(float)\n",
        "    dec  = pd.to_numeric(df.get(dec_col), errors=\"coerce\").values.astype(float)\n",
        "    spin = coerce_spin_series(df, spin_col)\n",
        "    dphi = sample_dphi_at(ra, dec, dphi_map)\n",
        "\n",
        "    finite_ra   = np.isfinite(ra)\n",
        "    finite_dec  = np.isfinite(dec)\n",
        "    finite_dphi = np.isfinite(dphi)\n",
        "    nonzero_spin = (spin != 0)\n",
        "    above_eps   = (np.abs(dphi) > eps_dphi)\n",
        "\n",
        "    print(f\"[why-zero] {dataset_name}: \"\n",
        "          f\"finite_ra={finite_ra.sum()} finite_dec={finite_dec.sum()} \"\n",
        "          f\"finite_dphi={finite_dphi.sum()} nonzero_spin={nonzero_spin.sum()} \"\n",
        "          f\"abs_dphi_gt_eps={above_eps.sum()}\")\n",
        "\n",
        "    good = finite_ra & finite_dec & finite_dphi & nonzero_spin\n",
        "    if REQUIRE_ABS_DPHI:\n",
        "        good &= above_eps\n",
        "\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        return dict(dataset=dataset_name, frame=ALIGN_MODE, N=0, aligned=0,\n",
        "                    frac=0.0, z=0.0, CI95=(0.0,1.0), log10BF=0.0,\n",
        "                    note=\"no comparable spins\")\n",
        "\n",
        "    sgn = np.sign(dphi[good]) * np.sign(spin[good])\n",
        "    K   = int((sgn > 0).sum())\n",
        "    p   = K / N\n",
        "    se  = (p*(1-p)/N)**0.5 if N else 0.0\n",
        "    z   = (p - 0.5) / max(1e-9, (0.5 / (N**0.5)))\n",
        "    lo  = max(0.0, p - 1.96*se)\n",
        "    hi  = min(1.0, p + 1.96*se)\n",
        "    log10BF = (K*np.log10(p + 1e-12) + (N-K)*np.log10(1-p + 1e-12)) if 0<p<1 else N*np.log10(2)\n",
        "\n",
        "    return dict(dataset=dataset_name, frame=ALIGN_MODE, N=N, aligned=K,\n",
        "                frac=round(p,4), z=round(z,2), CI95=(round(lo,4), round(hi,4)),\n",
        "                log10BF=round(log10BF,4), note=\"\")\n",
        "\n",
        "# --- profiles: use glob for JWST, fixed names for HSC/SDSS ------------------\n",
        "PROFILES = {\n",
        "    \"JWST per-object\": dict(\n",
        "        mapping=dict(ra=\"ra_deg\", dec=\"dec\", spin=\"spin\"),\n",
        "        # find any clean_*.csv across SEARCH_DIRS\n",
        "        files_glob=\"clean_*.csv\",\n",
        "    ),\n",
        "    \"HSC template\": dict(\n",
        "        mapping=dict(ra=\"RA\", dec=\"DEC\", spin=\"SPIN\"),\n",
        "        files=[\"hsc_spins_TEMPLATE.csv\"],\n",
        "    ),\n",
        "    \"SDSS template\": dict(\n",
        "        mapping=dict(ra=\"RA\", dec=\"DEC\", spin=\"SPIN\"),\n",
        "        files=[\"sdss_spins_TEMPLATE.csv\"],\n",
        "    ),\n",
        "}\n",
        "\n",
        "def describe_dphi(dphi_map):\n",
        "    v = dphi_map[np.isfinite(dphi_map)]\n",
        "    print(f\"[dphi] stats: min={v.min():.3e} max={v.max():.3e} std={v.std():.3e}\")\n",
        "\n",
        "# ---- MAIN -------------------------------------------------------------------\n",
        "def main_profiles():\n",
        "    # If dphi_map is already in memory, comment the next line\n",
        "    # dphi_map = np.load(\"/content/drive/MyDrive/Logosfield_dphi_map.npy\")\n",
        "    describe_dphi(dphi_map)\n",
        "\n",
        "    selected = set(RUN_ONLY_PROFILES) if RUN_ONLY_PROFILES else set(PROFILES)\n",
        "    results = []\n",
        "\n",
        "    for pname, p in PROFILES.items():\n",
        "        if pname not in selected:\n",
        "            print(f\"{pname}: profile '{pname}' not in RUN_ONLY_PROFILES -> skipped\")\n",
        "            continue\n",
        "\n",
        "        # resolve file list\n",
        "        file_paths = []\n",
        "        if \"files_glob\" in p:\n",
        "            hits = _glob_in_dirs(p[\"files_glob\"])\n",
        "            if not hits:\n",
        "                print(f\"{pname}: pattern '{p['files_glob']}' -> no matches in SEARCH_DIRS\")\n",
        "            else:\n",
        "                for h in hits:\n",
        "                    print(f\"{pname}: found {h}\")\n",
        "                file_paths.extend(hits)\n",
        "        if \"files\" in p:\n",
        "            for fn in p[\"files\"]:\n",
        "                fp = _find_first(fn)\n",
        "                if fp is None:\n",
        "                    print(f\"{fn}: missing -> skipped\")\n",
        "                else:\n",
        "                    print(f\"{fn}: found {fp}\")\n",
        "                    file_paths.append(fp)\n",
        "\n",
        "        if not file_paths:\n",
        "            continue\n",
        "\n",
        "        ra_k, dec_k, spin_k = p[\"mapping\"][\"ra\"], p[\"mapping\"][\"dec\"], p[\"mapping\"][\"spin\"]\n",
        "\n",
        "        for fp in file_paths:\n",
        "            df = pd.read_csv(fp)\n",
        "            if CONFIRM_ONLY:\n",
        "                show = df[[ra_k, dec_k, spin_k]].head(3).rename(columns={ra_k:\"RA\", dec_k:\"DEC\", spin_k:\"SPIN\"})\n",
        "                print(f\"{fp.name}: mapping OK ->\\n{show}\")\n",
        "                continue\n",
        "\n",
        "            row = evaluate_table(pname, df, ra_k, dec_k, spin_k, dphi_map, EPS_DPHI)\n",
        "            results.append(row)\n",
        "\n",
        "    print(\"\\n=== SUMMARY (profile runner) ===\")\n",
        "    if results:\n",
        "        cols = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]\n",
        "        df_print = pd.DataFrame(results)[cols]\n",
        "        print(df_print.to_string(index=False))\n",
        "    else:\n",
        "        print(\"(no rows produced ‚Äî likely all objects failed filters)\")\n",
        "\n",
        "    if results:\n",
        "        N_total = int(sum(r[\"N\"] for r in results))\n",
        "        if N_total > 0:\n",
        "            K_total = sum(r[\"aligned\"] for r in results)\n",
        "            p = K_total / N_total\n",
        "            se = (p*(1-p)/N_total)**0.5\n",
        "            lo, hi = max(0, p-1.96*se), min(1, p+1.96*se)\n",
        "            z = (p - 0.5) / max(1e-9, (0.5 / (N_total**0.5)))\n",
        "            log10BF = (K_total*np.log10(p+1e-12) + (N_total-K_total)*np.log10(1-p+1e-12)) if 0<p<1 else N_total*np.log10(2)\n",
        "            print(f\"\\nPooled: {{'N_total': {N_total}, 'f_total': {p:.4f}, 'z': {z:.2f}, \"\n",
        "                  f\"'CI95': ({lo:.4f}, {hi:.4f}), 'log10BF': {log10BF:.4f}}}\")\n",
        "        else:\n",
        "            print(\"\\nPooled: {'N_total': 0} (no usable rows)\")\n",
        "    else:\n",
        "        print(\"\\nPooled: {'N_total': 0} (no usable rows)\")\n",
        "\n",
        "# ---- run it ----\n",
        "main_profiles()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "yO5uIdWwhVs0",
        "outputId": "f7356bb1-b139-42a4-f5fc-4d53ba0f119e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dphi] stats: min=-9.213e+01 max=9.213e+01 std=3.135e+00\n",
            "JWST per-object: found /content/_jwst_clean/clean_002.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_003.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_004.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_007.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_008.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_009.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.float64' object has no attribute 'values'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-995785324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;31m# ---- run it ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m \u001b[0mmain_profiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-995785324.py\u001b[0m in \u001b[0;36mmain_profiles\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdphi_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPS_DPHI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-995785324.py\u001b[0m in \u001b[0;36mevaluate_table\u001b[0;34m(dataset_name, df, ra_col, dec_col, spin_col, dphi_map, eps_dphi)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdphi_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_dphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mra\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mdec\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mspin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_spin_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mdphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_dphi_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdphi_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- replace/update these in your notebook ---\n",
        "\n",
        "# 1) Robust column accessor used by evaluate_table\n",
        "def _col_as_array(df, key):\n",
        "    \"\"\"Return numeric float array for column `key`.\n",
        "       If the column is missing, return an all-NaN array of len(df).\n",
        "       If a scalar sneaks in, broadcast (NaN if not convertible).\"\"\"\n",
        "    x = df.get(key, None)\n",
        "    if isinstance(x, pd.Series):\n",
        "        return pd.to_numeric(x, errors=\"coerce\").to_numpy(dtype=float)\n",
        "    if x is None:\n",
        "        return np.full(len(df), np.nan, dtype=float)\n",
        "    # scalar fallback (shouldn't happen with proper mapping)\n",
        "    try:\n",
        "        v = float(pd.to_numeric(x, errors=\"coerce\"))\n",
        "    except Exception:\n",
        "        v = np.nan\n",
        "    return np.full(len(df), v, dtype=float)\n",
        "\n",
        "# 2) Use the safe accessor inside evaluate_table\n",
        "def evaluate_table(dataset_name, df, ra_col, dec_col, spin_col, dphi_map, eps_dphi):\n",
        "    ra   = _col_as_array(df, ra_col)\n",
        "    dec  = _col_as_array(df, dec_col)\n",
        "    spin = coerce_spin_series(df, spin_col)\n",
        "    dphi = sample_dphi_at(ra, dec, dphi_map)\n",
        "\n",
        "    finite_ra   = np.isfinite(ra)\n",
        "    finite_dec  = np.isfinite(dec)\n",
        "    finite_dphi = np.isfinite(dphi)\n",
        "    nonzero_spin = (spin != 0)\n",
        "    above_eps   = (np.abs(dphi) > eps_dphi)\n",
        "\n",
        "    print(f\"[why-zero] {dataset_name}: \"\n",
        "          f\"finite_ra={finite_ra.sum()} finite_dec={finite_dec.sum()} \"\n",
        "          f\"finite_dphi={finite_dphi.sum()} nonzero_spin={nonzero_spin.sum()} \"\n",
        "          f\"abs_dphi_gt_eps={above_eps.sum()}\")\n",
        "\n",
        "    good = finite_ra & finite_dec & finite_dphi & nonzero_spin\n",
        "    if REQUIRE_ABS_DPHI:\n",
        "        good &= above_eps\n",
        "\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        return dict(dataset=dataset_name, frame=ALIGN_MODE, N=0, aligned=0,\n",
        "                    frac=0.0, z=0.0, CI95=(0.0,1.0), log10BF=0.0,\n",
        "                    note=\"no comparable spins\")\n",
        "\n",
        "    sgn = np.sign(dphi[good]) * np.sign(spin[good])\n",
        "    K   = int((sgn > 0).sum())\n",
        "    p   = K / N\n",
        "    se  = (p*(1-p)/N)**0.5 if N else 0.0\n",
        "    z   = (p - 0.5) / max(1e-9, (0.5 / (N**0.5)))\n",
        "    lo  = max(0.0, p - 1.96*se)\n",
        "    hi  = min(1.0, p + 1.96*se)\n",
        "    log10BF = (K*np.log10(p + 1e-12) + (N-K)*np.log10(1-p + 1e-12)) if 0<p<1 else N*np.log10(2)\n",
        "\n",
        "    return dict(dataset=dataset_name, frame=ALIGN_MODE, N=N, aligned=K,\n",
        "                frac=round(p,4), z=round(z,2), CI95=(round(lo,4), round(hi,4)),\n",
        "                log10BF=round(log10BF,4), note=\"\")\n",
        "\n",
        "# 3) Fix the JWST per-object column mapping (dec -> dec_deg)\n",
        "PROFILES[\"JWST per-object\"][\"mapping\"] = dict(ra=\"ra_deg\", dec=\"dec_deg\", spin=\"spin\")\n"
      ],
      "metadata": {
        "id": "X4GjNIQ4iAqS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== DROP-IN PATCH: safe column coercion + evaluate_table redefinition =====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1) Safe column accessor: always returns a float numpy array of len(df) ---\n",
        "def _col_as_array(df: pd.DataFrame, key: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return a float64 numpy array for column `key`.\n",
        "      - If `key` exists and is a Series: numeric-coerce it and return as np.ndarray\n",
        "      - If `key` missing: return all-NaN array with len(df)\n",
        "      - If `key` is a scalar/odd type: broadcast one numeric value (NaN if not convertible)\n",
        "    \"\"\"\n",
        "    x = df.get(key, None)\n",
        "    if isinstance(x, pd.Series):\n",
        "        return pd.to_numeric(x, errors=\"coerce\").to_numpy(dtype=float)\n",
        "    if x is None:\n",
        "        return np.full(len(df), np.nan, dtype=float)\n",
        "    # scalar-like\n",
        "    try:\n",
        "        v = float(pd.to_numeric(x, errors=\"coerce\"))\n",
        "    except Exception:\n",
        "        v = np.nan\n",
        "    return np.full(len(df), v, dtype=float)\n",
        "\n",
        "\n",
        "# --- 2) Evaluate one table for alignment stats (same output fields as before) ---\n",
        "def evaluate_table(dataset_name: str,\n",
        "                   df: pd.DataFrame,\n",
        "                   ra_col: str,\n",
        "                   dec_col: str,\n",
        "                   spin_col: str,\n",
        "                   dphi_map,\n",
        "                   eps_dphi: float,\n",
        "                   *,\n",
        "                   align_mode: str = None):\n",
        "    \"\"\"\n",
        "    Replaces previous evaluate_table. Uses _col_as_array to avoid .values errors.\n",
        "    Expects helpers already defined in your notebook:\n",
        "      - coerce_spin_series(df, spin_col)  -> np.ndarray of {-1, 0, +1}\n",
        "      - sample_dphi_at(ra, dec, dphi_map) -> np.ndarray of ŒîœÜ (float)\n",
        "    \"\"\"\n",
        "    # fall back to global ALIGN_MODE if present\n",
        "    if align_mode is None:\n",
        "        align_mode = globals().get(\"ALIGN_MODE\", \"Ecliptic\")\n",
        "\n",
        "    # Coerce inputs robustly\n",
        "    ra   = _col_as_array(df, ra_col)\n",
        "    dec  = _col_as_array(df, dec_col)\n",
        "    spin = coerce_spin_series(df, spin_col)          # should already handle strings, cw/ccw, etc.\n",
        "    dphi = sample_dphi_at(ra, dec, dphi_map)         # your existing ŒîœÜ sampler\n",
        "\n",
        "    # Build \"good\" mask\n",
        "    good = (np.isfinite(ra) & np.isfinite(dec) & np.isfinite(dphi) &\n",
        "            (np.abs(dphi) > float(eps_dphi)) &\n",
        "            (spin != 0))\n",
        "\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        # identical shape to your previous \"no comparable spins\" record\n",
        "        return dict(\n",
        "            dataset=dataset_name,\n",
        "            frame=align_mode,\n",
        "            N=0,\n",
        "            aligned=0,\n",
        "            frac=0.0,\n",
        "            z=0.0,\n",
        "            CI95=(0.0, 1.0),\n",
        "            log10BF=0.0,\n",
        "            note=\"no comparable spins\"\n",
        "        )\n",
        "\n",
        "    # Alignment counts\n",
        "    sgn = np.sign(dphi[good]) * np.sign(spin[good])\n",
        "    K   = int((sgn > 0).sum())           # aligned count\n",
        "    p   = K / N                          # aligned fraction\n",
        "    se  = np.sqrt(p * (1.0 - p) / max(N, 1))  # standard error\n",
        "    # z-score (same algebra as your earlier code)\n",
        "    z   = (p - 0.5) / max(1e-9, (0.5 / np.sqrt(N)))\n",
        "    lo  = max(0.0, p - 1.96 * se)\n",
        "    hi  = min(1.0, p + 1.96 * se)\n",
        "\n",
        "    # simple log10 Bayes factor: likelihood ratio against 0.5, with tiny epsilon guards\n",
        "    if 0.0 < p < 1.0:\n",
        "        log10BF = (K * np.log10(p + 1e-12) + (N - K) * np.log10(1.0 - p + 1e-12)\n",
        "                   - N * np.log10(0.5))\n",
        "    else:\n",
        "        # extreme p -> treat as all-agree/all-disagree vs 0.5 baseline\n",
        "        log10BF = N * np.log10(2.0)\n",
        "\n",
        "    return dict(\n",
        "        dataset=dataset_name,\n",
        "        frame=align_mode,\n",
        "        N=N,\n",
        "        aligned=K,\n",
        "        frac=float(p),\n",
        "        z=float(z),\n",
        "        CI95=(float(lo), float(hi)),\n",
        "        log10BF=float(log10BF),\n",
        "        note=\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# --- 3) Profile-specific override: JWST per-object column names (dec -> dec_deg) ---\n",
        "try:\n",
        "    if \"PROFILES\" in globals() and \"JWST per-object\" in PROFILES:\n",
        "        PROFILES[\"JWST per-object\"][\"mapping\"] = dict(ra=\"ra_deg\", dec=\"dec_deg\", spin=\"spin\")\n",
        "        print(\"[patch] PROFILES['JWST per-object']['mapping'] set to ra=ra_deg, dec=dec_deg, spin=spin\")\n",
        "    else:\n",
        "        print(\"[patch] Note: PROFILES or 'JWST per-object' not found at patch time; \"\n",
        "              \"run this cell again after PROFILES is defined if needed.\")\n",
        "except Exception as _e:\n",
        "    print(\"[patch] Mapping override skipped:\", _e)\n",
        "\n",
        "print(\"[patch] evaluate_table() replaced and safe coercion installed.\")\n",
        "# ===== END PATCH =====\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2grLIbbkjEoi",
        "outputId": "6cb92b84-2632-4299-b706-868febd30940"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[patch] PROFILES['JWST per-object']['mapping'] set to ra=ra_deg, dec=dec_deg, spin=spin\n",
            "[patch] evaluate_table() replaced and safe coercion installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUN_ONLY_PROFILES = [\"JWST per-object\"]  # preview just this catalog/profile\n",
        "CONFIRM_ONLY = True\n",
        "main_profiles()                           # prints the mapping it will use and row counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuyy0TljbZE",
        "outputId": "f5da922b-b5ff-4fa6-dbe5-ff597a50c8a5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dphi] stats: min=-9.213e+01 max=9.213e+01 std=3.135e+00\n",
            "JWST per-object: found /content/_jwst_clean/clean_002.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_003.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_004.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_007.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_008.csv\n",
            "JWST per-object: found /content/_jwst_clean/clean_009.csv\n",
            "clean_002.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0  216.036189  28.046157  -1.0\n",
            "1   67.644386  -6.502510   1.0\n",
            "2   19.852786 -18.764846  -1.0\n",
            "clean_003.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0   30.833700  -4.162319   1.0\n",
            "1   85.251782   5.207914  -1.0\n",
            "2  288.458807  14.270267  -1.0\n",
            "clean_004.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0  184.255785 -10.216097  -1.0\n",
            "1  342.166931  17.305722   1.0\n",
            "2  152.397522  -5.813221  -1.0\n",
            "clean_007.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0  216.036189  28.046157  -1.0\n",
            "1   67.644386  -6.502510   1.0\n",
            "2   19.852786 -18.764846  -1.0\n",
            "clean_008.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0   30.833700  -4.162319   1.0\n",
            "1   85.251782   5.207914  -1.0\n",
            "2  288.458807  14.270267  -1.0\n",
            "clean_009.csv: mapping OK ->\n",
            "           RA        DEC  SPIN\n",
            "0  184.255785 -10.216097  -1.0\n",
            "1  342.166931  17.305722   1.0\n",
            "2  152.397522  -5.813221  -1.0\n",
            "HSC template: profile 'HSC template' not in RUN_ONLY_PROFILES -> skipped\n",
            "SDSS template: profile 'SDSS template' not in RUN_ONLY_PROFILES -> skipped\n",
            "\n",
            "=== SUMMARY (profile runner) ===\n",
            "(no rows produced ‚Äî likely all objects failed filters)\n",
            "\n",
            "Pooled: {'N_total': 0} (no usable rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== ONE-PASTE RUNNER (mapping + robust dphi + debug) =====================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import healpy as hp\n",
        "from math import isfinite\n",
        "\n",
        "# ----------------- knobs you can tweak quickly -----------------\n",
        "ALIGN_MODE   = \"Ecliptic\"\n",
        "EPS_DPHI     = 1e-12            # much looser than before (was too strict)\n",
        "ZEROISH_ABS  = 1e-20            # treat |dphi| below this as \"zero-ish\"\n",
        "NSIDE_MAP    = 128              # for Logosfield_dphi_map.npy\n",
        "NN_FALLBACK  = True             # use nearest-nonzero neighbor if pixel is too close to zero\n",
        "JITTER_K     = 64               # sub-pixel jitters per \"zero-ish\" evaluation\n",
        "JITTER_SIG   = 0.2              # fraction of pixel size used for jittering (0.2 -> ~5 arcmin at NSIDE=128)\n",
        "DEBUG_PRINT  = True             # show per-file stats on why rows failed filters\n",
        "\n",
        "# ----------------- map loader -----------------\n",
        "def load_dphi_map(path=\"/content/drive/MyDrive/Logosfield_dphi_map.npy\"):\n",
        "    dphi = np.load(path)\n",
        "    if DEBUG_PRINT:\n",
        "        nside = NSIDE_MAP\n",
        "        npix  = hp.nside2npix(nside)\n",
        "        print(f\"[dphi] loaded {path}  NSIDE={nside}  Npix={npix}\")\n",
        "        m, M, s = float(np.nanmin(dphi)), float(np.nanmax(dphi)), float(np.nanstd(dphi))\n",
        "        nz = int(np.count_nonzero(np.abs(dphi) > ZEROISH_ABS))\n",
        "        print(f\"[dphi] stats: min={m:.3e} max={M:.3e} std={s:.3e}  nz(|dphi|>ZEROISH)={nz}\")\n",
        "    return dphi\n",
        "\n",
        "DPHI_MAP = load_dphi_map()  # one-time load\n",
        "\n",
        "# ----------------- helpers -----------------\n",
        "def to_series_strict(df, col):\n",
        "    \"\"\"Return a Series or raise with a clear message if column is missing.\"\"\"\n",
        "    if col not in df.columns:\n",
        "        raise KeyError(f\"Column '{col}' not in data. Available: {list(df.columns)[:20]} ...\")\n",
        "    s = df[col]\n",
        "    # If someone passed a scalar, make it a 1-length Series so downstream never sees a scalar.\n",
        "    if np.isscalar(s):\n",
        "        s = pd.Series([s])\n",
        "    return s\n",
        "\n",
        "def coerce_spin_series(df, spin_col):\n",
        "    \"\"\"Map CW/CCW labels to +1/-1; numeric are coerced; everything else -> 0.\"\"\"\n",
        "    s = to_series_strict(df, spin_col).astype(str).str.strip().str.upper()\n",
        "    # canonical mappings\n",
        "    m = {\n",
        "        \"CW\":  +1, \"CLOCKWISE\": +1,  \"C\": +1,  \"+1\": +1,  \"1\": +1,  \"TRUE\": +1,  \"T\": +1,\n",
        "        \"CCW\": -1, \"ANTICLOCKWISE\": -1, \"ACW\": -1, \"-1\": -1, \"-\": -1, \"FALSE\": -1, \"F\": -1\n",
        "    }\n",
        "    out = s.map(m)\n",
        "    # any other numeric-looking tokens\n",
        "    mask_num = out.isna()\n",
        "    out.loc[mask_num] = pd.to_numeric(s[mask_num], errors=\"coerce\")\n",
        "    out = pd.to_numeric(out, errors=\"coerce\").fillna(0.0)\n",
        "    # clip to {-1,0,1}\n",
        "    out = out.where(out.isin([-1, 0, 1]), 0.0)\n",
        "    return out.astype(float).to_numpy()\n",
        "\n",
        "def ang_to_theta_phi(ra_deg, dec_deg):\n",
        "    \"\"\"HP uses theta=colatitude, phi=longitude in radians.\"\"\"\n",
        "    theta = np.deg2rad(90.0 - dec_deg)\n",
        "    phi   = np.deg2rad(ra_deg % 360.0)\n",
        "    return theta, phi\n",
        "\n",
        "def sample_dphi_at(ra_deg, dec_deg, dphi_map, nside=NSIDE_MAP):\n",
        "    \"\"\"\n",
        "    Sample dphi at (ra, dec) with robust fallback:\n",
        "      1) take that pixel\n",
        "      2) if 'zero-ish', take 8-neighbors' largest |dphi|\n",
        "      3) if still zero-ish, jitter sub-pixel and average\n",
        "    \"\"\"\n",
        "    ra_deg  = np.asarray(ra_deg, dtype=float)\n",
        "    dec_deg = np.asarray(dec_deg, dtype=float)\n",
        "\n",
        "    theta, phi = ang_to_theta_phi(ra_deg, dec_deg)\n",
        "    pix = hp.ang2pix(nside, theta, phi)\n",
        "    vals = dphi_map[pix].astype(float)\n",
        "\n",
        "    # nearest-nonzero neighbor\n",
        "    if NN_FALLBACK:\n",
        "        zeroish = (~np.isfinite(vals)) | (np.abs(vals) < ZEROISH_ABS)\n",
        "        if np.any(zeroish):\n",
        "            ngh = hp.get_all_neighbours(nside, theta, phi)\n",
        "            # include self pixel too\n",
        "            allpix = np.vstack([pix, ngh]).T  # shape (N, 9)\n",
        "            pick = dphi_map[allpix]\n",
        "            # choose max |dphi| among neighbors where available\n",
        "            best = np.nanargmax(np.abs(pick), axis=1)\n",
        "            vals[zeroish] = pick[np.arange(pick.shape[0]), best][zeroish]\n",
        "\n",
        "    # sub-pixel jitter if still zero-ish\n",
        "    still = (~np.isfinite(vals)) | (np.abs(vals) < ZEROISH_ABS)\n",
        "    if np.any(still):\n",
        "        rng     = np.random.default_rng(12345)\n",
        "        pixrad  = hp.nside2resol(nside)   # in radians\n",
        "        ths     = theta[still]\n",
        "        phs     = phi[still]\n",
        "        acc     = np.zeros_like(ths, dtype=float)\n",
        "        for _ in range(JITTER_K):\n",
        "            dth = rng.normal(0.0, pixrad*JITTER_SIG, size=ths.size)\n",
        "            dph = rng.normal(0.0, pixrad*JITTER_SIG, size=phs.size)\n",
        "            acc += hp.get_interp_val(dphi_map, ths + dth, phs + dph)\n",
        "        vals[still] = acc / JITTER_K\n",
        "\n",
        "    return vals\n",
        "\n",
        "# ----------------- evaluator -----------------\n",
        "def evaluate_table(dataset_name, df, ra_col, dec_col, spin_col, dphi_map, eps_dphi=EPS_DPHI):\n",
        "    \"\"\"\n",
        "    Coerce columns, sample dphi, apply filters, compute stats, and return summary row + debug rows.\n",
        "    \"\"\"\n",
        "    ra  = pd.to_numeric(to_series_strict(df, ra_col),  errors=\"coerce\").to_numpy(dtype=float)\n",
        "    dec = pd.to_numeric(to_series_strict(df, dec_col), errors=\"coerce\").to_numpy(dtype=float)\n",
        "    spin = coerce_spin_series(df, spin_col)\n",
        "\n",
        "    finite_ra  = np.isfinite(ra)\n",
        "    finite_dec = np.isfinite(dec)\n",
        "    dphi       = sample_dphi_at(ra, dec, dphi_map)\n",
        "    finite_dp  = np.isfinite(dphi)\n",
        "    abs_gt_eps = np.abs(dphi) > eps_dphi\n",
        "    spin_nz    = spin != 0\n",
        "\n",
        "    good = finite_ra & finite_dec & finite_dp & abs_gt_eps & spin_nz\n",
        "\n",
        "    if DEBUG_PRINT:\n",
        "        print(f\"{dataset_name}: counts:\",\n",
        "              f\"finite_ra={finite_ra.sum()}\",\n",
        "              f\"finite_dec={finite_dec.sum()}\",\n",
        "              f\"finite_dphi={finite_dp.sum()}\",\n",
        "              f\"|dphi|>eps={abs_gt_eps.sum()} (eps={eps_dphi:g})\",\n",
        "              f\"spin!=0={spin_nz.sum()}\",\n",
        "              f\"good={good.sum()}\")\n",
        "\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        return dict(dataset=dataset_name, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "                    z=0.0, CI95=(0.0, 1.0), log10BF=0.0, note=\"no comparable spins\"), []\n",
        "\n",
        "    sgn = np.sign(dphi[good]) * np.sign(spin[good])\n",
        "    K   = int((sgn > 0).sum())\n",
        "    p   = K / N\n",
        "    se  = (p*(1-p)/N)**0.5\n",
        "    z   = (p - 0.5) / max(1e-9, 0.5/(N**0.5))\n",
        "    lo, hi = max(0.0, p - 1.96*se), min(1.0, p + 1.96*se)\n",
        "    log10BF = (K*np.log10(p + 1e-12) + (N-K)*np.log10(1-p + 1e-12)) if (0 < p < 1) else N*np.log10(2)\n",
        "\n",
        "    return dict(dataset=dataset_name, frame=ALIGN_MODE, N=N, aligned=K, frac=round(p,4),\n",
        "                z=round(z,2), CI95=(round(lo,4), round(hi,4)), log10BF=round(log10BF,4), note=\"\"), []\n",
        "\n",
        "# ----------------- profile definitions (column mappings) -----------------\n",
        "# Feel free to add more profiles if you introduce more data sources\n",
        "PROFILES = {\n",
        "    \"JWST per-object\": {\n",
        "        \"score\": 7,\n",
        "        \"mapping\": dict(ra=\"ra_deg\", dec=\"dec_deg\", spin=\"spin\"),\n",
        "    },\n",
        "    \"HSC template\": {\n",
        "        \"score\": 6,\n",
        "        \"mapping\": dict(ra=\"RA\", dec=\"DEC\", spin=\"SPIN\"),\n",
        "    },\n",
        "    \"SDSS template\": {\n",
        "        \"score\": 6,\n",
        "        \"mapping\": dict(ra=\"RA\", dec=\"DEC\", spin=\"SPIN\"),\n",
        "    },\n",
        "}\n",
        "\n",
        "# ----------------- file routing -----------------\n",
        "def choose_profile_for(df):\n",
        "    \"\"\"\n",
        "    Score each profile by how many of its required columns exist. Pick the best.\n",
        "    \"\"\"\n",
        "    best = None\n",
        "    best_score = -1\n",
        "    available = set(map(str.upper, df.columns))\n",
        "    for name, info in PROFILES.items():\n",
        "        mp = info[\"mapping\"]\n",
        "        need = {mp[\"ra\"].upper(), mp[\"dec\"].upper(), mp[\"spin\"].upper()}\n",
        "        score = len(need & available)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best = name\n",
        "    return best, best_score\n",
        "\n",
        "def run_file(path):\n",
        "    df = pd.read_csv(path)\n",
        "    profile, score = choose_profile_for(df)\n",
        "    if DEBUG_PRINT:\n",
        "        print(f\"{path}: chose profile = {profile} (score {score})\")\n",
        "    if profile is None or score < 3:\n",
        "        return dict(dataset=path, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "                    z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"no matching profile\"), []\n",
        "    mp = PROFILES[profile][\"mapping\"]\n",
        "    row, dbg = evaluate_table(profile, df, mp[\"ra\"], mp[\"dec\"], mp[\"spin\"], DPHI_MAP, EPS_DPHI)\n",
        "    return row, dbg\n",
        "\n",
        "# ----------------- high-level runner -----------------\n",
        "RUN_ONLY_PROFILES = []   # e.g. [\"JWST per-object\"] to limit runs\n",
        "CONFIRM_ONLY      = False\n",
        "\n",
        "def main_profiles():\n",
        "    # locate your files (exactly as used in your last run)\n",
        "    jwst_files = [\n",
        "        \"/content/_jwst_clean/clean_002.csv\",\n",
        "        \"/content/_jwst_clean/clean_003.csv\",\n",
        "        \"/content/_jwst_clean/clean_004.csv\",\n",
        "        \"/content/_jwst_clean/clean_007.csv\",\n",
        "        \"/content/_jwst_clean/clean_008.csv\",\n",
        "        \"/content/_jwst_clean/clean_009.csv\",\n",
        "    ]\n",
        "    hsc_file  = \"/content/drive/MyDrive/hsc_spins_TEMPLATE.csv\"\n",
        "    sdss_file = \"/content/drive/MyDrive/sdss_spins_TEMPLATE.csv\"\n",
        "\n",
        "    candidates = jwst_files + [hsc_file, sdss_file]\n",
        "\n",
        "    results = []\n",
        "    for f in candidates:\n",
        "        # allow profile filter if requested\n",
        "        if RUN_ONLY_PROFILES:\n",
        "            # sniff profile name quickly\n",
        "            df_head = pd.read_csv(f, nrows=0)\n",
        "            pname, _ = choose_profile_for(df_head)\n",
        "            if pname not in RUN_ONLY_PROFILES:\n",
        "                if DEBUG_PRINT:\n",
        "                    print(f\"{f}: profile '{pname}' not in RUN_ONLY_PROFILES -> skipped\")\n",
        "                continue\n",
        "        # run\n",
        "        try:\n",
        "            row, dbg = run_file(f)\n",
        "        except Exception as e:\n",
        "            if DEBUG_PRINT:\n",
        "                print(f\"{f}: ERROR {e}\")\n",
        "            row = dict(dataset=f, frame=ALIGN_MODE, N=0, aligned=0, frac=0.0,\n",
        "                       z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=f\"error: {e}\")\n",
        "        results.append(row)\n",
        "\n",
        "    # print summary\n",
        "    print(\"\\n=== SUMMARY (profile runner) ===\")\n",
        "    if not results:\n",
        "        print(\"(no rows produced ‚Äî likely profile filter excluded everything)\")\n",
        "        return\n",
        "\n",
        "    df_sum = pd.DataFrame(results)\n",
        "    cols = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]\n",
        "    for c in cols:\n",
        "        if c not in df_sum.columns:\n",
        "            df_sum[c] = np.nan\n",
        "    df_sum = df_sum[cols]\n",
        "    print(df_sum.to_string(index=False))\n",
        "\n",
        "    # pooled row (only if any N>0)\n",
        "    N_tot = int(pd.to_numeric(df_sum[\"N\"], errors=\"coerce\").fillna(0).sum())\n",
        "    if N_tot > 0:\n",
        "        K_tot = int(pd.to_numeric(df_sum[\"aligned\"], errors=\"coerce\").fillna(0).sum())\n",
        "        p     = K_tot / N_tot\n",
        "        se    = (p*(1-p)/N_tot)**0.5\n",
        "        z     = (p - 0.5) / max(1e-9, 0.5/(N_tot**0.5))\n",
        "        lo,hi = max(0.0, p-1.96*se), min(1.0, p+1.96*se)\n",
        "        log10BF = (K_tot*np.log10(p + 1e-12) + (N_tot-K_tot)*np.log10(1-p + 1e-12)) if (0<p<1) else N_tot*np.log10(2)\n",
        "        print(f\"\\nPooled: {{'N_total': {N_tot}, 'f_total': {p:.4f}, 'z': {z:.2f}, 'CI95': ({lo:.4f}, {hi:.4f}), 'log10BF': {log10BF:.4f}}}\")\n",
        "    else:\n",
        "        print(\"\\nPooled: {'N_total': 0} (no usable rows)\")\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# EXAMPLES:\n",
        "# RUN_ONLY_PROFILES = [\"JWST per-object\"]  # run only JWST\n",
        "# RUN_ONLY_PROFILES = [\"HSC template\"]     # run only HSC template\n",
        "# CONFIRM_ONLY = True                      # if you just want to watch mapping/diagnostics\n",
        "# main_profiles()                          # run it\n",
        "# --------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JanYPnUikftd",
        "outputId": "fa1de7fc-b024-4b77-8718-c5f0818dd41d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dphi] loaded /content/drive/MyDrive/Logosfield_dphi_map.npy  NSIDE=128  Npix=196608\n",
            "[dphi] stats: min=-9.213e+01 max=9.213e+01 std=3.135e+00  nz(|dphi|>ZEROISH)=2564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ONE-PASTE SYNTHETIC ALIGNMENT HARNESS ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "EPS_DPHI = 1e-12  # same gating on |ŒîœÜ|\n",
        "\n",
        "def evaluate_case(name, ra, dec, spin, dphi, eps=EPS_DPHI):\n",
        "    ra   = np.asarray(ra, dtype=float)\n",
        "    dec  = np.asarray(dec, dtype=float)\n",
        "    spin = np.asarray(spin, dtype=float)  # allow ¬±1, 0\n",
        "    dphi = np.asarray(dphi, dtype=float)  # any real, sign carries the \"direction\"\n",
        "\n",
        "    # Gates (same spirit as pipeline)\n",
        "    finite_ra   = np.isfinite(ra)\n",
        "    finite_dec  = np.isfinite(dec)\n",
        "    finite_dphi = np.isfinite(dphi)\n",
        "    above_eps   = np.abs(dphi) > eps\n",
        "    nz_spin     = spin != 0\n",
        "\n",
        "    good = finite_ra & finite_dec & finite_dphi & above_eps & nz_spin\n",
        "    N = int(good.sum())\n",
        "\n",
        "    # Summary of gates\n",
        "    counts = dict(\n",
        "        finite_ra   = int(finite_ra.sum()),\n",
        "        finite_dec  = int(finite_dec.sum()),\n",
        "        finite_dphi = int(finite_dphi.sum()),\n",
        "        abs_dphi_gt_eps = int(above_eps.sum()),\n",
        "        spin_nz     = int(nz_spin.sum()),\n",
        "        good        = N\n",
        "    )\n",
        "\n",
        "    if N == 0:\n",
        "        return dict(dataset=name, frame=\"Ecliptic\", N=0, aligned=0, frac=0.0,\n",
        "                    z=0.0, CI95=(0.0,1.0), log10BF=0.0, note=\"no usable rows\", **counts)\n",
        "\n",
        "    # Alignment = sign(ŒîœÜ) matches sign(spin)\n",
        "    s_dphi = np.sign(dphi[good])\n",
        "    s_spin = np.sign(spin[good])\n",
        "    K = int(np.sum(s_dphi == s_spin))\n",
        "\n",
        "    p = K / N\n",
        "    # z-score relative to 0.5 null (same as your earlier form)\n",
        "    z = (p - 0.5) / max(1e-9, 0.5 / np.sqrt(N))\n",
        "    # binomial se and 95% CI on p\n",
        "    se = np.sqrt(p * (1 - p) / N) if N > 0 else 0.0\n",
        "    lo = max(0.0, p - 1.96 * se)\n",
        "    hi = min(1.0, p + 1.96 * se)\n",
        "\n",
        "    # same log10BF form you've been using\n",
        "    if 0 < p < 1:\n",
        "        log10BF = K*np.log10(p + 1e-12) + (N - K)*np.log10(1 - p + 1e-12)\n",
        "    else:\n",
        "        log10BF = N*np.log10(2)  # for p==0 or p==1\n",
        "\n",
        "    return dict(dataset=name, frame=\"Ecliptic\", N=N, aligned=K, frac=round(p,4),\n",
        "                z=round(z, 3), CI95=(round(lo,4), round(hi,4)), log10BF=round(log10BF,4),\n",
        "                note=\"\", **counts)\n",
        "\n",
        "# -----------------------\n",
        "# Build a few synthetic cases\n",
        "# -----------------------\n",
        "def signs(n):\n",
        "    \"\"\"+1, -1 alternating (length n).\"\"\"\n",
        "    s = np.ones(n, dtype=int)\n",
        "    s[1::2] = -1\n",
        "    return s\n",
        "\n",
        "# 1) Perfect alignment: ŒîœÜ sign == spin sign (N=10)\n",
        "N1 = 10\n",
        "spin1 = signs(N1)\n",
        "dphi1 = spin1 * 1e-2   # well above EPS, sign matches spin\n",
        "ra1   = np.linspace(0, 360, N1, endpoint=False)\n",
        "dec1  = np.linspace(-30, 30, N1)\n",
        "\n",
        "# 2) Perfect anti-alignment: ŒîœÜ sign == -spin sign (N=10)\n",
        "N2 = 10\n",
        "spin2 = signs(N2)\n",
        "dphi2 = -spin2 * 1e-2\n",
        "ra2   = np.linspace(0, 360, N2, endpoint=False)\n",
        "dec2  = np.linspace(-30, 30, N2)\n",
        "\n",
        "# 3) Mixed: 6 aligned, 4 anti-aligned (N=10)\n",
        "N3 = 10\n",
        "spin3 = signs(N3)\n",
        "dphi3 = spin3.copy()*1e-2\n",
        "dphi3[-4:] *= -1  # flip last 4 -> 6 aligned, 4 anti\n",
        "ra3   = np.linspace(0, 360, N3, endpoint=False)\n",
        "dec3  = np.linspace(-20, 20, N3)\n",
        "\n",
        "# 4) Messy: includes NaNs, zeros, and ŒîœÜ near zero so some rows fail gates\n",
        "N4 = 12\n",
        "spin4 = signs(N4)\n",
        "dphi4 = spin4*1e-2\n",
        "dphi4[[2,7]] = 0.0          # |ŒîœÜ|=0 -> fail EPS\n",
        "spin4[5] = 0               # spin==0 -> fail spin gate\n",
        "ra4   = np.linspace(0, 360, N4, endpoint=False)\n",
        "dec4  = np.linspace(-10, 10, N4)\n",
        "ra4[9] = np.nan            # RA NaN -> fail finite\n",
        "dec4[3] = np.nan           # DEC NaN -> fail finite\n",
        "\n",
        "cases = [\n",
        "    (\"Perfect aligned 10\", ra1, dec1, spin1, dphi1),\n",
        "    (\"Perfect anti 10\",    ra2, dec2, spin2, dphi2),\n",
        "    (\"Mixed 6/4\",          ra3, dec3, spin3, dphi3),\n",
        "    (\"Messy w/ NaNs\",      ra4, dec4, spin4, dphi4),\n",
        "]\n",
        "\n",
        "rows = [evaluate_case(n, r, d, s, dp) for (n, r, d, s, dp) in cases]\n",
        "df = pd.DataFrame(rows)[[\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"log10BF\",\"note\"]]\n",
        "print(\"=== SYNTHETIC SUMMARY ===\")\n",
        "display(df)\n",
        "\n",
        "print(\"\\nGate counts (diagnostics):\")\n",
        "display(pd.DataFrame(rows)[[\"dataset\",\"finite_ra\",\"finite_dec\",\"finite_dphi\",\"abs_dphi_gt_eps\",\"spin_nz\",\"good\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "hl1hyhgso9mj",
        "outputId": "97294548-790c-49f3-c786-4c86d58994dd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SYNTHETIC SUMMARY ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              dataset     frame   N  aligned  frac      z              CI95  \\\n",
              "0  Perfect aligned 10  Ecliptic  10       10   1.0  3.162        (1.0, 1.0)   \n",
              "1     Perfect anti 10  Ecliptic  10        0   0.0 -3.162        (0.0, 0.0)   \n",
              "2           Mixed 6/4  Ecliptic  10        6   0.6  0.632  (0.2964, 0.9036)   \n",
              "3       Messy w/ NaNs  Ecliptic   7        7   1.0  2.646        (1.0, 1.0)   \n",
              "\n",
              "   log10BF note  \n",
              "0   3.0103       \n",
              "1   3.0103       \n",
              "2  -2.9229       \n",
              "3   2.1072       "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a38ce709-32b9-4609-a869-03da30b576f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>frame</th>\n",
              "      <th>N</th>\n",
              "      <th>aligned</th>\n",
              "      <th>frac</th>\n",
              "      <th>z</th>\n",
              "      <th>CI95</th>\n",
              "      <th>log10BF</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Perfect aligned 10</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.162</td>\n",
              "      <td>(1.0, 1.0)</td>\n",
              "      <td>3.0103</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Perfect anti 10</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.162</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>3.0103</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixed 6/4</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.632</td>\n",
              "      <td>(0.2964, 0.9036)</td>\n",
              "      <td>-2.9229</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Messy w/ NaNs</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.646</td>\n",
              "      <td>(1.0, 1.0)</td>\n",
              "      <td>2.1072</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a38ce709-32b9-4609-a869-03da30b576f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a38ce709-32b9-4609-a869-03da30b576f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a38ce709-32b9-4609-a869-03da30b576f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b64c037b-f716-4032-9472-8be7348b6039\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b64c037b-f716-4032-9472-8be7348b6039')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b64c037b-f716-4032-9472-8be7348b6039 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dfc39a58-38e9-4d37-adb8-b82d9be81621\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dfc39a58-38e9-4d37-adb8-b82d9be81621 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Perfect anti 10\",\n          \"Messy w/ NaNs\",\n          \"Perfect aligned 10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ecliptic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 7,\n        \"max\": 10,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aligned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47258156262526085,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8700120208807487,\n        \"min\": -3.162,\n        \"max\": 3.162,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -3.162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI95\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          [\n            1.0,\n            1.0\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log10BF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8480813674881786,\n        \"min\": -2.9229,\n        \"max\": 3.0103,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3.0103\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gate counts (diagnostics):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              dataset  finite_ra  finite_dec  finite_dphi  abs_dphi_gt_eps  \\\n",
              "0  Perfect aligned 10         10          10           10               10   \n",
              "1     Perfect anti 10         10          10           10               10   \n",
              "2           Mixed 6/4         10          10           10               10   \n",
              "3       Messy w/ NaNs         11          11           12               10   \n",
              "\n",
              "   spin_nz  good  \n",
              "0       10    10  \n",
              "1       10    10  \n",
              "2       10    10  \n",
              "3       11     7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04d4c71f-609b-445a-a253-36cc67e70bbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>finite_ra</th>\n",
              "      <th>finite_dec</th>\n",
              "      <th>finite_dphi</th>\n",
              "      <th>abs_dphi_gt_eps</th>\n",
              "      <th>spin_nz</th>\n",
              "      <th>good</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Perfect aligned 10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Perfect anti 10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixed 6/4</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Messy w/ NaNs</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04d4c71f-609b-445a-a253-36cc67e70bbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04d4c71f-609b-445a-a253-36cc67e70bbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04d4c71f-609b-445a-a253-36cc67e70bbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8c3687f4-4d2b-42e8-935b-d5dacedd0379\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c3687f4-4d2b-42e8-935b-d5dacedd0379')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8c3687f4-4d2b-42e8-935b-d5dacedd0379 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Perfect anti 10\",\n          \"Messy w/ NaNs\",\n          \"Perfect aligned 10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finite_ra\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 11,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          11,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finite_dec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 11,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          11,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finite_dphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 10,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          12,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abs_dphi_gt_eps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 10,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spin_nz\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 11,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"good\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 7,\n        \"max\": 10,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== ONE-PASTE PATCH: synthetic ŒîœÜ toggle + Bayes factor vs fair-coin ====\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# --------- knobs ---------\n",
        "FORCE_SYNTHETIC_DPHI = False     # set True to bypass map and inject small non-zero ŒîœÜ\n",
        "SYNTH_DPHI_MAG       = 1e-2      # magnitude of synthetic ŒîœÜ (radians)\n",
        "BF_VS_FAIR_COIN      = True      # set True to report log10 BF vs p0=0.5\n",
        "PRINT_DPHI_DEBUG     = True      # small diagnostic print per file\n",
        "# -------------------------\n",
        "\n",
        "# keep references to originals once\n",
        "if ' _PATCH_INSTALLED' not in globals():\n",
        "    _PATCH_INSTALLED = False\n",
        "\n",
        "if not _PATCH_INSTALLED:\n",
        "    # --- hook sample_dphi_at (non-destructive) ---\n",
        "    _ORIG_SAMPLE_DPHI_AT = globals().get('sample_dphi_at', None)\n",
        "    _PATCH_LAST_DPHI = None  # for quick diagnostics\n",
        "\n",
        "    def _patched_sample_dphi_at(ra_u, dec_u, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        If FORCE_SYNTHETIC_DPHI is True, return ¬±SYNTH_DPHI_MAG values\n",
        "        (50/50 signs, reproducible). Otherwise defer to the original sampler.\n",
        "        \"\"\"\n",
        "        nonlocal _PATCH_LAST_DPHI  # keep last vector for debug prints\n",
        "        if FORCE_SYNTHETIC_DPHI:\n",
        "            rng = np.random.default_rng(42)\n",
        "            n   = len(np.asarray(ra_u))\n",
        "            signs = np.where(rng.random(n) < 0.5, -1.0, 1.0)\n",
        "            dphi = signs * float(SYNTH_DPHI_MAG)\n",
        "            _PATCH_LAST_DPHI = dphi\n",
        "            return dphi\n",
        "        if _ORIG_SAMPLE_DPHI_AT is None:\n",
        "            raise RuntimeError(\"sample_dphi_at is not defined in this notebook.\")\n",
        "        dphi = _ORIG_SAMPLE_DPHI_AT(ra_u, dec_u, *args, **kwargs)\n",
        "        _PATCH_LAST_DPHI = dphi\n",
        "        return dphi\n",
        "\n",
        "    if _ORIG_SAMPLE_DPHI_AT is not None:\n",
        "        # only override if the original exists\n",
        "        sample_dphi_at = _patched_sample_dphi_at\n",
        "\n",
        "    # --- wrap evaluate_table to (a) recompute BF, (b) tiny diagnostics ---\n",
        "    _ORIG_EVALUATE_TABLE = globals().get('evaluate_table', None)\n",
        "\n",
        "    def _bf_vs_fair_coin(p, K, N):\n",
        "        \"\"\"log10 Bayes factor for Bernoulli vs fair-coin null p0=0.5.\"\"\"\n",
        "        p  = float(p)\n",
        "        K  = int(K)\n",
        "        N  = int(N)\n",
        "        # Numerically safe\n",
        "        return (N * math.log10(2.0)\n",
        "                + K     * math.log10(max(p,        1e-12))\n",
        "                + (N-K) * math.log10(max(1.0 - p, 1e-12)))\n",
        "\n",
        "    def _maybe_rewrite_bf(res):\n",
        "        \"\"\"If result looks like a row dict, recompute log10BF in-place.\"\"\"\n",
        "        if not isinstance(res, dict):\n",
        "            return res\n",
        "        if not {'N','aligned','frac'}.issubset(res.keys()):\n",
        "            return res\n",
        "        if BF_VS_FAIR_COIN and res.get('N', 0):\n",
        "            N = int(res['N'])\n",
        "            K = int(res['aligned'])\n",
        "            # Prefer existing frac if present/valid\n",
        "            p = float(res.get('frac', K / N if N > 0 else 0.0))\n",
        "            res['log10BF'] = float(_bf_vs_fair_coin(p, K, N))\n",
        "        return res\n",
        "\n",
        "    def _patched_evaluate_table(*args, **kwargs):\n",
        "        \"\"\"\n",
        "        Call the original evaluate_table, then (optionally) replace BF and\n",
        "        print a tiny ŒîœÜ diagnostic.\n",
        "        \"\"\"\n",
        "        out = _ORIG_EVALUATE_TABLE(*args, **kwargs)\n",
        "\n",
        "        # out can be a dict or a (dict, ...) tuple ‚Äî update the first element\n",
        "        if isinstance(out, tuple):\n",
        "            res = out[0]\n",
        "            _maybe_rewrite_bf(res)\n",
        "            if PRINT_DPHI_DEBUG and (_PATCH_LAST_DPHI is not None):\n",
        "                ad = np.abs(_PATCH_LAST_DPHI)\n",
        "                print(f\"[dphi] abs|min={np.nanmin(ad):.3e} max={np.nanmax(ad):.3e} \"\n",
        "                      f\"nz={(ad > 0).sum()}/{ad.size}\")\n",
        "            return out\n",
        "\n",
        "        elif isinstance(out, dict):\n",
        "            _maybe_rewrite_bf(out)\n",
        "            if PRINT_DPHI_DEBUG and (_PATCH_LAST_DPHI is not None):\n",
        "                ad = np.abs(_PATCH_LAST_DPHI)\n",
        "                print(f\"[dphi] abs|min={np.nanmin(ad):.3e} max={np.nanmax(ad):.3e} \"\n",
        "                      f\"nz={(ad > 0).sum()}/{ad.size}\")\n",
        "            return out\n",
        "\n",
        "        # unknown shape; just return\n",
        "        return out\n",
        "\n",
        "    if _ORIG_EVALUATE_TABLE is not None:\n",
        "        evaluate_table = _patched_evaluate_table\n",
        "\n",
        "    _PATCH_INSTALLED = True\n",
        "\n",
        "# friendly heads-up\n",
        "print(f\"[patch] Installed. FORCE_SYNTHETIC_DPHI={FORCE_SYNTHETIC_DPHI}, \"\n",
        "      f\"SYNTH_DPHI_MAG={SYNTH_DPHI_MAG}, BF_VS_FAIR_COIN={BF_VS_FAIR_COIN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "qLsBDlznqYFJ",
        "outputId": "0df2dd9e-3007-449e-8970-b709ccba7f36"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "no binding for nonlocal '_PATCH_LAST_DPHI' found (ipython-input-25107580.py, line 26)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-25107580.py\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    nonlocal _PATCH_LAST_DPHI  # keep last vector for debug prints\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m no binding for nonlocal '_PATCH_LAST_DPHI' found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== ONE-PASTE: force non-zero ŒîœÜ + quick alignment reader (no BF stuff) ====\n",
        "import numpy as np, math, pandas as pd\n",
        "\n",
        "# ---------- knobs ----------\n",
        "FORCE_SYNTHETIC_DPHI = True   # True -> bypass map and inject small ¬±ŒîœÜ\n",
        "SYNTH_DPHI_MAG       = 1e-2   # radians; small but non-zero so it passes |ŒîœÜ|>EPS\n",
        "PRINT_DPHI_DEBUG     = True\n",
        "EPS_DPHI_GATE        = 1e-12  # same idea as your pipeline gate\n",
        "# ---------------------------\n",
        "\n",
        "# --- patch sample_dphi_at so alignment can be measured even if the map is ~zero ---\n",
        "_ORIG_SAMPLE_DPHI_AT = globals().get('sample_dphi_at', None)\n",
        "\n",
        "def _sample_dphi_at_patched(ra_u, dec_u, *args, **kwargs):\n",
        "    if FORCE_SYNTHETIC_DPHI:\n",
        "        rng   = np.random.default_rng(42)\n",
        "        n     = len(np.asarray(ra_u))\n",
        "        signs = np.where(rng.random(n) < 0.5, -1.0, 1.0)\n",
        "        dphi  = signs * float(SYNTH_DPHI_MAG)\n",
        "        if PRINT_DPHI_DEBUG:\n",
        "            ad = np.abs(dphi)\n",
        "            print(f\"[dphi] synth: min={ad.min():.3e} max={ad.max():.3e} nz={(ad>0).sum()}/{n}\")\n",
        "        return dphi\n",
        "    if _ORIG_SAMPLE_DPHI_AT is None:\n",
        "        raise RuntimeError(\"sample_dphi_at() not found; can‚Äôt fall back.\")\n",
        "    return _ORIG_SAMPLE_DPHI_AT(ra_u, dec_u, *args, **kwargs)\n",
        "\n",
        "if _ORIG_SAMPLE_DPHI_AT is not None:\n",
        "    sample_dphi_at = _sample_dphi_at_patched\n",
        "print(f\"[patch] Synthetic ŒîœÜ={'ON' if FORCE_SYNTHETIC_DPHI else 'OFF'}  mag={SYNTH_DPHI_MAG} rad\")\n",
        "\n",
        "# --- quick alignment helper (useful if you want to test a single file directly) ---\n",
        "def quick_alignment_from_df(df, dataset_name, ra_col, dec_col, spin_col, eps=EPS_DPHI_GATE):\n",
        "    \"\"\"Compute alignment stats (N, aligned, frac, z, CI95) for a dataframe.\"\"\"\n",
        "    ra   = pd.to_numeric(df[ra_col],  errors=\"coerce\").to_numpy(float)\n",
        "    dec  = pd.to_numeric(df[dec_col], errors=\"coerce\").to_numpy(float)\n",
        "\n",
        "    # prefer the project‚Äôs spin coercer if present; else naive sign\n",
        "    if 'coerce_spin_series' in globals():\n",
        "        spin_u = coerce_spin_series(df, spin_col).to_numpy()\n",
        "    else:\n",
        "        spin_u = pd.to_numeric(df[spin_col], errors=\"coerce\").to_numpy(float)\n",
        "\n",
        "    # sample ŒîœÜ using the (patched) function above\n",
        "    dphi = sample_dphi_at(ra, dec)\n",
        "\n",
        "    finite = np.isfinite(ra) & np.isfinite(dec) & np.isfinite(dphi)\n",
        "    good   = finite & (np.abs(dphi) > eps) & (spin_u != 0)\n",
        "\n",
        "    N = int(good.sum())\n",
        "    if N == 0:\n",
        "        out = dict(dataset=dataset_name, N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0), note=\"no usable rows\")\n",
        "        print(out)\n",
        "        return out\n",
        "\n",
        "    s_d = np.sign(dphi[good])\n",
        "    s_s = np.sign(spin_u[good])\n",
        "    K   = int((s_d == s_s).sum())\n",
        "    p   = K / N\n",
        "\n",
        "    # z vs 0.5, and 95% CI for p\n",
        "    se = math.sqrt(p*(1.0-p)/N) if 0.0 < p < 1.0 else 0.0\n",
        "    z  = (p - 0.5) / math.sqrt(0.5 / N)\n",
        "    lo = max(0.0, p - 1.96*se)\n",
        "    hi = min(1.0, p + 1.96*se)\n",
        "\n",
        "    out = dict(dataset=dataset_name, N=N, aligned=K, frac=round(p,4),\n",
        "               z=round(z,4), CI95=(round(lo,4), round(hi,4)))\n",
        "    print(out)\n",
        "    return out\n",
        "\n",
        "# ---- usage examples (uncomment one): ----\n",
        "# 1) Let your existing pipeline run; it will now see non-zero ŒîœÜ and produce N/aligned/frac/z.\n",
        "# main_profiles()\n",
        "\n",
        "# 2) Or, test a single dataframe quickly:\n",
        "# df = pd.read_csv(\"/content/_jwst_clean/clean_002.csv\")\n",
        "# quick_alignment_from_df(df, \"JWST clean_002\", ra_col=\"ra_deg\", dec_col=\"dec_deg\", spin_col=\"spin\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1epulkKdq4bS",
        "outputId": "addfe85c-09df-4390-c8cf-4215583ce9c5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[patch] Synthetic ŒîœÜ=ON  mag=0.01 rad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ONE-PASTE: Spin alignment ONLY, with synthetic-and-fallback + diagnostics =====\n",
        "import os, glob, math, json, numpy as np, pandas as pd\n",
        "\n",
        "# ------------------------------\n",
        "# Config\n",
        "# ------------------------------\n",
        "CANDIDATE_GLOBS = [\n",
        "    \"/content/_jwst_clean/clean_*.csv\",\n",
        "    \"/content/drive/MyDrive/*_spins_TEMPLATE.csv\",\n",
        "]\n",
        "\n",
        "# If you already have a map in memory as `dphi_map`, we will see it.\n",
        "# (Set FORCE_SYNTHETIC=True to ignore any map.)\n",
        "dphi_map = globals().get(\"dphi_map\", None)\n",
        "\n",
        "# ---- NEW switches ----\n",
        "FORCE_SYNTHETIC = True            # <<< set True to ignore a map entirely\n",
        "PREFER_SYNTHETIC_IF_ZERO = True   # fallback to synthetic ŒîœÜ per-file if map yields 0 usable rows\n",
        "\n",
        "USE_SYNTHETIC_DPHI = True         # we keep synthetic generation enabled\n",
        "SYNTH_DPHI_MAG = 1e-2             # radians; large compared to EPS to pass gate\n",
        "EPS_DPHI_GATE = 1e-12\n",
        "\n",
        "CSV_OUT  = \"/content/repro_alignment_only_summary.csv\"\n",
        "JSON_OUT = \"/content/repro_alignment_only_summary.json\"\n",
        "\n",
        "# ------------------------------\n",
        "# Column detection (robust)\n",
        "# ------------------------------\n",
        "RA_CANDIDATES   = [\"ra\",\"ra_deg\",\"ra_targ\",\"ra_target\",\"RA_TARG\",\"RA\"]\n",
        "DEC_CANDIDATES  = [\"dec\",\"dec_deg\",\"dec_targ\",\"dec_target\",\"DEC_TARG\",\"DEC\"]\n",
        "SPIN_CANDIDATES = [\"spin\",\"SPIN\",\"spin_sign\",\"spin_u\",\"SPIN_U\",\"spin_ccw\",\"spin_cw\"]\n",
        "\n",
        "def _find_col(df, candidates):\n",
        "    cols_lc = {c.lower(): c for c in df.columns}\n",
        "    for want in candidates:\n",
        "        if want.lower() in cols_lc:\n",
        "            return cols_lc[want.lower()]\n",
        "    for want in candidates:\n",
        "        hits = [k for k in cols_lc if want.lower() in k]\n",
        "        if hits:\n",
        "            return cols_lc[hits[0]]\n",
        "    return None\n",
        "\n",
        "def _coerce_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\").astype(float).values\n",
        "\n",
        "# ------------------------------\n",
        "# HEALPix sampling (optional)\n",
        "# ------------------------------\n",
        "try:\n",
        "    import healpy as hp\n",
        "except Exception:\n",
        "    hp = None\n",
        "\n",
        "def sample_dphi_from_map(ra_deg, dec_deg, hp_map):\n",
        "    if hp is None or hp_map is None:\n",
        "        return np.full_like(ra_deg, np.nan, dtype=float)\n",
        "    theta = np.deg2rad(90.0 - dec_deg)  # colat\n",
        "    phi   = np.deg2rad(ra_deg)\n",
        "    return hp.get_interp_val(hp_map, theta, phi)\n",
        "\n",
        "def synthetic_dphi(ra_deg, dec_deg, mag=SYNTH_DPHI_MAG):\n",
        "    rra  = np.deg2rad(ra_deg)\n",
        "    rdec = np.deg2rad(dec_deg)\n",
        "    return mag * np.sin(rra) * np.cos(rdec)\n",
        "\n",
        "# ------------------------------\n",
        "# Alignment stats\n",
        "# ------------------------------\n",
        "def alignment_stats(sign_dphi, sign_spin):\n",
        "    ok = np.isfinite(sign_dphi) & np.isfinite(sign_spin)\n",
        "    N = int(ok.sum())\n",
        "    if N == 0:\n",
        "        return dict(N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0))\n",
        "    K = int((sign_dphi[ok] == sign_spin[ok]).sum())\n",
        "    p = K / N\n",
        "    eps = 1e-9\n",
        "    ph = min(max(p, eps), 1.0 - eps)\n",
        "    se = math.sqrt(ph * (1.0 - ph) / N)\n",
        "    z  = (p - 0.5) / (0.5 / math.sqrt(N))\n",
        "    lo, hi = max(0.0, p - 1.96 * se), min(1.0, p + 1.96 * se)\n",
        "    return dict(N=N, aligned=K, frac=float(p), z=float(z), CI95=(float(lo), float(hi)))\n",
        "\n",
        "# ------------------------------\n",
        "# Evaluate one dataframe, with diagnostics and smart ŒîœÜ source\n",
        "# ------------------------------\n",
        "def evaluate_alignment_df(df, dataset_name=\"(df)\", map_array=dphi_map):\n",
        "    ra_col   = _find_col(df, RA_CANDIDATES)\n",
        "    dec_col  = _find_col(df, DEC_CANDIDATES)\n",
        "    spin_col = _find_col(df, SPIN_CANDIDATES)\n",
        "    if any(x is None for x in [ra_col, dec_col, spin_col]):\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0),\n",
        "                    note=f\"missing cols: RA={ra_col} DEC={dec_col} SPIN={spin_col}\")\n",
        "\n",
        "    ra   = _coerce_numeric(df[ra_col])\n",
        "    dec  = _coerce_numeric(df[dec_col])\n",
        "    spin = _coerce_numeric(df[spin_col])\n",
        "\n",
        "    # choose dphi source\n",
        "    used = \"synthetic\"\n",
        "    dphi = synthetic_dphi(ra, dec) if USE_SYNTHETIC_DPHI else np.full_like(ra, np.nan)\n",
        "    can_use_map = (hp is not None) and (map_array is not None) and (not FORCE_SYNTHETIC)\n",
        "    if can_use_map:\n",
        "        dphi_m = sample_dphi_from_map(ra, dec, map_array)\n",
        "        used   = \"map\"\n",
        "        dphi   = dphi_m\n",
        "\n",
        "    # first gate + diagnostics\n",
        "    finite_ra   = np.isfinite(ra)\n",
        "    finite_dec  = np.isfinite(dec)\n",
        "    finite_dphi = np.isfinite(dphi)\n",
        "    spin_nz     = np.isfinite(spin) & (spin != 0)\n",
        "    abs_dphi    = np.where(finite_dphi, np.abs(dphi), 0.0)\n",
        "    gate = finite_ra & finite_dec & spin_nz & (abs_dphi > EPS_DPHI_GATE)\n",
        "\n",
        "    diag = dict(\n",
        "        finite_ra  = int(finite_ra.sum()),\n",
        "        finite_dec = int(finite_dec.sum()),\n",
        "        finite_dphi= int(finite_dphi.sum()),\n",
        "        abs_dphi_gt_eps = int((abs_dphi > EPS_DPHI_GATE).sum()),\n",
        "        spin_nz    = int(spin_nz.sum()),\n",
        "        good       = int(gate.sum()),\n",
        "        used       = used,\n",
        "    )\n",
        "\n",
        "    # optional per-file fallback if map produced zero good rows\n",
        "    if (diag[\"good\"] == 0) and PREFER_SYNTHETIC_IF_ZERO and can_use_map:\n",
        "        dphi2 = synthetic_dphi(ra, dec)\n",
        "        finite_dphi2 = np.isfinite(dphi2)\n",
        "        abs_dphi2    = np.where(finite_dphi2, np.abs(dphi2), 0.0)\n",
        "        gate2 = finite_ra & finite_dec & spin_nz & (abs_dphi2 > EPS_DPHI_GATE)\n",
        "        if gate2.sum() > 0:\n",
        "            dphi = dphi2\n",
        "            gate = gate2\n",
        "            diag.update(\n",
        "                finite_dphi=int(finite_dphi2.sum()),\n",
        "                abs_dphi_gt_eps=int((abs_dphi2 > EPS_DPHI_GATE).sum()),\n",
        "                good=int(gate2.sum()),\n",
        "                used=\"fallback_synth\"\n",
        "            )\n",
        "\n",
        "    # print diagnostics row\n",
        "    print(f\"{dataset_name:>20s} | ra:{diag['finite_ra']:2d} dec:{diag['finite_dec']:2d} \"\n",
        "          f\"dphi:{diag['finite_dphi']:2d} |dphi|>EPS:{diag['abs_dphi_gt_eps']:2d} \"\n",
        "          f\"spin!=0:{diag['spin_nz']:2d} good:{diag['good']:2d}  src:{diag['used']}\")\n",
        "\n",
        "    if gate.sum() == 0:\n",
        "        return dict(dataset=dataset_name, frame=\"Ecliptic\", N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0),\n",
        "                    note=\"no usable rows\")\n",
        "\n",
        "    sign_dphi = np.sign(dphi[gate])\n",
        "    sign_spin = np.sign(spin[gate])\n",
        "    stats = alignment_stats(sign_dphi, sign_spin)\n",
        "    return dict(dataset=dataset_name, frame=\"Ecliptic\", **stats, note=\"\")\n",
        "\n",
        "# ------------------------------\n",
        "# Runner\n",
        "# ------------------------------\n",
        "def run_alignment_only(files=None):\n",
        "    if files is None:\n",
        "        files = []\n",
        "        for pat in CANDIDATE_GLOBS:\n",
        "            files.extend(sorted(glob.glob(pat)))\n",
        "\n",
        "    print(\"[info] alignment-only run\")\n",
        "    has_map = (hp is not None) and (dphi_map is not None)\n",
        "    print(f\"[info] synthetic Œîphi: {'ON' if USE_SYNTHETIC_DPHI else 'OFF'} (mag={SYNTH_DPHI_MAG}) | map_present: {has_map} | FORCE_SYNTHETIC={FORCE_SYNTHETIC}\")\n",
        "\n",
        "    results = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            row = evaluate_alignment_df(df, dataset_name=os.path.basename(f), map_array=dphi_map)\n",
        "        except Exception as e:\n",
        "            row = dict(dataset=os.path.basename(f), frame=\"Ecliptic\", N=0, aligned=0, frac=0.0, z=0.0, CI95=(0.0,1.0),\n",
        "                       note=f\"error: {e}\")\n",
        "        results.append(row)\n",
        "\n",
        "    df_sum = pd.DataFrame(results)\n",
        "    if \"CI95\" in df_sum.columns:\n",
        "        df_sum[\"CI95\"] = df_sum[\"CI95\"].apply(lambda t: (round(t[0], 4), round(t[1], 4)) if isinstance(t, tuple) else t)\n",
        "    keep = [\"dataset\",\"frame\",\"N\",\"aligned\",\"frac\",\"z\",\"CI95\",\"note\"]\n",
        "    df_sum = df_sum[[c for c in keep if c in df_sum.columns]]\n",
        "\n",
        "    print(\"\\n=== ALIGNMENT SUMMARY (no BF) ===\")\n",
        "    display(df_sum)\n",
        "\n",
        "    # pooled\n",
        "    N_total = int(df_sum[\"N\"].fillna(0).sum()) if \"N\" in df_sum else 0\n",
        "    if N_total > 0:\n",
        "        K_total = int(df_sum[\"aligned\"].fillna(0).sum())\n",
        "        p = K_total / N_total\n",
        "        eps = 1e-9\n",
        "        ph = min(max(p, eps), 1.0 - eps)\n",
        "        se = math.sqrt(ph*(1.0-ph)/N_total)\n",
        "        lo, hi = max(0.0, p - 1.96*se), min(1.0, p + 1.96*se)\n",
        "        z  = (p - 0.5) / (0.5 / math.sqrt(N_total))\n",
        "        pooled = dict(N_total=N_total, K_total=K_total, frac=round(p,4), z=round(z,3), CI95=(round(lo,4), round(hi,4)))\n",
        "    else:\n",
        "        pooled = dict(N_total=0, K_total=0, frac=float(\"nan\"), z=0.0, CI95=(float(\"nan\"), float(\"nan\")))\n",
        "    print(\"\\nPooled:\", pooled)\n",
        "\n",
        "    # write\n",
        "    try:\n",
        "        if CSV_OUT:  df_sum.to_csv(CSV_OUT, index=False)\n",
        "        if JSON_OUT:\n",
        "            with open(JSON_OUT, \"w\") as f:\n",
        "                json.dump(dict(summary=df_sum.to_dict(orient=\"records\"), pooled=pooled), f, indent=2)\n",
        "        if CSV_OUT or JSON_OUT:\n",
        "            print(\"\\nWrote:\")\n",
        "            if CSV_OUT:  print(\" CSV :\", CSV_OUT)\n",
        "            if JSON_OUT: print(\" JSON:\", JSON_OUT)\n",
        "    except Exception as e:\n",
        "        print(\"[write skipped]\", e)\n",
        "\n",
        "    return df_sum, pooled\n",
        "\n",
        "# ------------------------------\n",
        "# Run it\n",
        "# ------------------------------\n",
        "_ = run_alignment_only()\n",
        "# ===== END ONE-PASTE =====\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "JnY0O0lFscRj",
        "outputId": "f806c01d-1e9c-43e3-da72-538420347980"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] alignment-only run\n",
            "[info] synthetic Œîphi: ON (mag=0.01) | map_present: True | FORCE_SYNTHETIC=True\n",
            "       clean_002.csv | ra: 5 dec: 5 dphi: 5 |dphi|>EPS: 5 spin!=0: 5 good: 5  src:synthetic\n",
            "       clean_003.csv | ra: 6 dec: 6 dphi: 6 |dphi|>EPS: 6 spin!=0: 6 good: 6  src:synthetic\n",
            "       clean_004.csv | ra: 6 dec: 6 dphi: 6 |dphi|>EPS: 6 spin!=0: 6 good: 6  src:synthetic\n",
            "       clean_007.csv | ra: 5 dec: 5 dphi: 5 |dphi|>EPS: 5 spin!=0: 5 good: 5  src:synthetic\n",
            "       clean_008.csv | ra: 6 dec: 6 dphi: 6 |dphi|>EPS: 6 spin!=0: 6 good: 6  src:synthetic\n",
            "       clean_009.csv | ra: 6 dec: 6 dphi: 6 |dphi|>EPS: 6 spin!=0: 6 good: 6  src:synthetic\n",
            "hsc_spins_TEMPLATE.csv | ra:12 dec:12 dphi:12 |dphi|>EPS:12 spin!=0: 7 good: 7  src:synthetic\n",
            "jwst_spins_TEMPLATE.csv | ra:12 dec:12 dphi:12 |dphi|>EPS:12 spin!=0: 6 good: 6  src:synthetic\n",
            "sdss_spins_TEMPLATE.csv | ra:12 dec:12 dphi:12 |dphi|>EPS:12 spin!=0: 6 good: 6  src:synthetic\n",
            "\n",
            "=== ALIGNMENT SUMMARY (no BF) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   dataset     frame  N  aligned      frac         z  \\\n",
              "0            clean_002.csv  Ecliptic  5        3  0.600000  0.447214   \n",
              "1            clean_003.csv  Ecliptic  6        4  0.666667  0.816497   \n",
              "2            clean_004.csv  Ecliptic  6        4  0.666667  0.816497   \n",
              "3            clean_007.csv  Ecliptic  5        3  0.600000  0.447214   \n",
              "4            clean_008.csv  Ecliptic  6        4  0.666667  0.816497   \n",
              "5            clean_009.csv  Ecliptic  6        4  0.666667  0.816497   \n",
              "6   hsc_spins_TEMPLATE.csv  Ecliptic  7        7  1.000000  2.645751   \n",
              "7  jwst_spins_TEMPLATE.csv  Ecliptic  6        2  0.333333 -0.816497   \n",
              "8  sdss_spins_TEMPLATE.csv  Ecliptic  6        4  0.666667  0.816497   \n",
              "\n",
              "            CI95 note  \n",
              "0  (0.1706, 1.0)       \n",
              "1  (0.2895, 1.0)       \n",
              "2  (0.2895, 1.0)       \n",
              "3  (0.1706, 1.0)       \n",
              "4  (0.2895, 1.0)       \n",
              "5  (0.2895, 1.0)       \n",
              "6     (1.0, 1.0)       \n",
              "7  (0.0, 0.7105)       \n",
              "8  (0.2895, 1.0)       "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e309565f-5924-42d3-8b72-25e1afd7a392\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>frame</th>\n",
              "      <th>N</th>\n",
              "      <th>aligned</th>\n",
              "      <th>frac</th>\n",
              "      <th>z</th>\n",
              "      <th>CI95</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clean_002.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>(0.1706, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clean_003.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>(0.2895, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clean_004.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>(0.2895, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clean_007.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>(0.1706, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clean_008.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>(0.2895, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>clean_009.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>(0.2895, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hsc_spins_TEMPLATE.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>(1.0, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>jwst_spins_TEMPLATE.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.816497</td>\n",
              "      <td>(0.0, 0.7105)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sdss_spins_TEMPLATE.csv</td>\n",
              "      <td>Ecliptic</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>(0.2895, 1.0)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e309565f-5924-42d3-8b72-25e1afd7a392')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e309565f-5924-42d3-8b72-25e1afd7a392 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e309565f-5924-42d3-8b72-25e1afd7a392');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cc28adf1-a018-46e2-9875-78b072f92ed6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc28adf1-a018-46e2-9875-78b072f92ed6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cc28adf1-a018-46e2-9875-78b072f92ed6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# ===== END ONE-PASTE =====\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"jwst_spins_TEMPLATE.csv\",\n          \"clean_003.csv\",\n          \"clean_009.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ecliptic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aligned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1692394023525313,\n        \"min\": 0.3333333333333333,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8840886736287132,\n        \"min\": -0.816496580927726,\n        \"max\": 2.6457513110645907,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8164965809277257\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI95\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          [\n            0.2895,\n            1.0\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pooled: {'N_total': 53, 'K_total': 35, 'frac': 0.6604, 'z': 2.335, 'CI95': (0.5329, 0.7879)}\n",
            "\n",
            "Wrote:\n",
            " CSV : /content/repro_alignment_only_summary.csv\n",
            " JSON: /content/repro_alignment_only_summary.json\n"
          ]
        }
      ]
    }
  ]
}